[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Willkommen zum Modul Computer Vision mit Deep Learning",
    "section": "",
    "text": "Herzlich willkommen zum Modul Computer Vision mit Deep Learning (1. Teil)!\nHier finden Sie Unterlagen und aktuelle Informationen zum Modul.\nModul Computer Vision mit DL\nCAS Page",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#lernziele",
    "href": "index.html#lernziele",
    "title": "Willkommen zum Modul Computer Vision mit Deep Learning",
    "section": "Lernziele",
    "text": "Lernziele\n\nDie fundamentalen Herausforderungen beim Modellieren von Bilddaten verstehen\nConvolutional Neural Networks verstehen, implementieren und trainieren können\nFoundation-Models als Grundlage für viele Vision Tasks verstehen und einsetzten können\nBildklassifikation verstehen und systematisch umsetzen können\nMit Deep Learning Frameworks umgehen und Libraries verwenden können\nPraktische Anwendung umsetzen, vorstellen und erklären können",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#inhalte",
    "href": "index.html#inhalte",
    "title": "Willkommen zum Modul Computer Vision mit Deep Learning",
    "section": "Inhalte",
    "text": "Inhalte\nFolgendes Programm ist noch provisorisch.\n\nTag 1 - Grundlagen Convolutional Neural Networks\n\n\n\nZeit\nThema\n\n\n\n\n8:45 - 9:30\nEinführung Computer Vision mit Deep Learning\n\n\n9:30 - 10:30\nÜbung: Deep Learning mit PyTorch und Bildern\n\n\n10:30 - 10:45\nPause\n\n\n10:45 - 12:00\nConvolutional Neural Networks\n\n\n12:00 - 13:00\nMittagspause\n\n\n13:00 - 14:00\nÜbung: CNNs vs MLPs\n\n\n14:15 - 15:00\nTheorie: Bildklassifikation\n\n\n15:15 - 16:30\nÜbung: Bildklassifikation\n\n\n\n\n\nTag 2 - Bildklassifikation und Anwendungen\n\n\n\nZeit\nThema\n\n\n\n\n8:45 - 10:00\nTheorie: Foundation Models & Representation Learning\n\n\n10:15 - 11:15\nÜbung: Foundation Models\n\n\n11:30 - 12:00\nTheorie: Praktische Tipps\n\n\n12:00 - 13:00\nMittagspause\n\n\n13:00 - 15:30\nÜbung: End-To-End Beispiel\n\n\n15:30 - 15:45\nPause\n\n\n15:45 - 16:30\nQ&A / Buffer",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "pages/misc/notation.html",
    "href": "pages/misc/notation.html",
    "title": "Mathematical Notation",
    "section": "",
    "text": "Syntax\nDescription\n\n\n\n\n\\(a\\)\nA scalar (integer or real)\n\n\n\\(\\mathbf{a}\\)\nA vector\n\n\n\\(\\mathbf{A}\\)\nA matrix\n\n\n\\(\\mathbf{\\mathsf{A}}\\)\nA tensor\n\n\n\\(\\mathbf{I}_n\\)\nIdentity matrix with \\(n\\) rows and \\(n\\) columns\n\n\n\\(\\mathbf{I}\\)\nIdentity matrix with dimensionality implied by context\n\n\n\\(\\mathbf{e}^{(i)}\\)\nStandard basis vector \\([0,\\dots,0,1,0,\\dots,0]\\) with a 1 at position \\(i\\)\n\n\n\\(\\text{diag}(\\mathbf{a})\\)\nA square, diagonal matrix with diagonal entries given by \\(\\mathbf{a}\\)\n\n\n\\(\\textnormal{a}\\)\nA scalar random variable\n\n\n\\(\\mathbf{a}\\)\nA vector-valued random variable\n\n\n\\(\\mathbf{A}\\)\nA matrix-valued random variable\n\n\n\\(\\theta\\)\nParameters of a model\n\n\n\\(f(\\theta, \\mathbf{x})\\)\nA function (model) with paramters \\(\\theta\\) and data \\(\\mathbf{x}\\)\n\n\n\\(\\mathbf{A} \\odot \\mathbf{B}\\)\nElement-wise (Hadamard) product of \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\)",
    "crumbs": [
      "Resources",
      "Mathematical Notation"
    ]
  },
  {
    "objectID": "pages/misc/notation.html#numbers-and-arrays",
    "href": "pages/misc/notation.html#numbers-and-arrays",
    "title": "Mathematical Notation",
    "section": "",
    "text": "Syntax\nDescription\n\n\n\n\n\\(a\\)\nA scalar (integer or real)\n\n\n\\(\\mathbf{a}\\)\nA vector\n\n\n\\(\\mathbf{A}\\)\nA matrix\n\n\n\\(\\mathbf{\\mathsf{A}}\\)\nA tensor\n\n\n\\(\\mathbf{I}_n\\)\nIdentity matrix with \\(n\\) rows and \\(n\\) columns\n\n\n\\(\\mathbf{I}\\)\nIdentity matrix with dimensionality implied by context\n\n\n\\(\\mathbf{e}^{(i)}\\)\nStandard basis vector \\([0,\\dots,0,1,0,\\dots,0]\\) with a 1 at position \\(i\\)\n\n\n\\(\\text{diag}(\\mathbf{a})\\)\nA square, diagonal matrix with diagonal entries given by \\(\\mathbf{a}\\)\n\n\n\\(\\textnormal{a}\\)\nA scalar random variable\n\n\n\\(\\mathbf{a}\\)\nA vector-valued random variable\n\n\n\\(\\mathbf{A}\\)\nA matrix-valued random variable\n\n\n\\(\\theta\\)\nParameters of a model\n\n\n\\(f(\\theta, \\mathbf{x})\\)\nA function (model) with paramters \\(\\theta\\) and data \\(\\mathbf{x}\\)\n\n\n\\(\\mathbf{A} \\odot \\mathbf{B}\\)\nElement-wise (Hadamard) product of \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\)",
    "crumbs": [
      "Resources",
      "Mathematical Notation"
    ]
  },
  {
    "objectID": "pages/misc/notation.html#indexing",
    "href": "pages/misc/notation.html#indexing",
    "title": "Mathematical Notation",
    "section": "Indexing",
    "text": "Indexing\n\n\n\n\n\n\n\nSyntax\nDescription\n\n\n\n\n\\(a_i\\)\nElement \\(i\\) of vector \\(\\mathbf{a}\\), with indexing starting at 1\n\n\n\\(A_{i,j}\\)\nElement \\(i, j\\) of matrix \\(\\mathbf{A}\\)",
    "crumbs": [
      "Resources",
      "Mathematical Notation"
    ]
  },
  {
    "objectID": "pages/misc/notation.html#datasets-and-distributions",
    "href": "pages/misc/notation.html#datasets-and-distributions",
    "title": "Mathematical Notation",
    "section": "Datasets and Distributions",
    "text": "Datasets and Distributions\n\n\n\n\n\n\n\nSyntax\nDescription\n\n\n\n\n\\(\\mathbf{X}\\)\nThe design matrix with dimensionality \\(nxp\\) with \\(n\\) samples with \\(p\\) features.\n\n\n\\(\\mathbf{x}^{(i)}\\)\nThe i-th training example.\n\n\n\\(\\mathbf{y}^{(i)}\\)\nThe label-vector for the i-th training example.\n\n\n\\(y^{(i)}\\)\nThe label for the i-th training example.",
    "crumbs": [
      "Resources",
      "Mathematical Notation"
    ]
  },
  {
    "objectID": "pages/misc/notation.html#probability-theory",
    "href": "pages/misc/notation.html#probability-theory",
    "title": "Mathematical Notation",
    "section": "Probability Theory",
    "text": "Probability Theory\n\n\n\n\n\n\n\nSyntax\nDescription\n\n\n\n\n\\(P(x)\\)\nA probability distribution over a discrete variable.\n\n\n\\(p(x)\\)\nA probability distribution over a contiuous variable or over a variable whose type has not been specified.\n\n\n\\(\\mathbb{E}_{x \\sim P} [ f(x) ]\\text{ or } \\mathbb{E} f(x)\\)\nExpectation of \\(f(x)\\) with respect to \\(P(x)\\)\n\n\n\\(\\mathcal{N} ( \\mathbf{x} ; \\mu , \\Sigma)\\)\nGaussian distribution over \\(\\mathbf{x}\\) with mean \\(\\mu\\) and covariance \\(\\Sigma\\)\n\n\n\\(x \\sim \\mathcal{N} (\\mu , \\sigma)\\)\nGaussian distribution over \\(x\\) with mean \\(\\mu\\) and variance \\(\\sigma\\)",
    "crumbs": [
      "Resources",
      "Mathematical Notation"
    ]
  },
  {
    "objectID": "pages/misc/notation.html#calculus",
    "href": "pages/misc/notation.html#calculus",
    "title": "Mathematical Notation",
    "section": "Calculus",
    "text": "Calculus\n\n\n\n\n\n\n\nSyntax\nDescription\n\n\n\n\n\\(\\nabla_{\\mathbf{w}} J\\)\nGradient of \\(J\\) with respect to \\(\\mathbf{w}\\)\n\n\n\\(\\frac{\\partial J}{\\partial w}\\)\nPartial derivative of \\(J\\) with respect to \\(w\\)",
    "crumbs": [
      "Resources",
      "Mathematical Notation"
    ]
  },
  {
    "objectID": "pages/misc/notation.html#functions",
    "href": "pages/misc/notation.html#functions",
    "title": "Mathematical Notation",
    "section": "Functions",
    "text": "Functions\n\n\n\nSyntax\nDescription\n\n\n\n\n\\(\\log x\\)\nThe natural logarithm of \\(x\\).\n\n\n\\(\\lVert \\mathbf{x} \\rVert_p\\)\n\\(L^p\\) norm of \\(\\mathbf{x}\\)\n\n\n\\(\\lVert \\mathbf{x} \\rVert\\)\n\\(L^2\\) norm of \\(\\mathbf{x}\\)",
    "crumbs": [
      "Resources",
      "Mathematical Notation"
    ]
  },
  {
    "objectID": "pages/misc/notation.html#deep-learning",
    "href": "pages/misc/notation.html#deep-learning",
    "title": "Mathematical Notation",
    "section": "Deep Learning",
    "text": "Deep Learning\n\n\n\n\n\n\n\nSyntax\nDescription\n\n\n\n\nNCHW\nThe input format of images and activations in PyTorch. N: number of images (batch size), C: number of channels, H: height, W: width",
    "crumbs": [
      "Resources",
      "Mathematical Notation"
    ]
  },
  {
    "objectID": "pages/misc/links.html",
    "href": "pages/misc/links.html",
    "title": "Helpful Links & Resources",
    "section": "",
    "text": "Links and ressources to different topics related to Machine Learning, Deep Learning, and Images.",
    "crumbs": [
      "Resources",
      "Helpful Links & Resources"
    ]
  },
  {
    "objectID": "pages/misc/links.html#theory",
    "href": "pages/misc/links.html#theory",
    "title": "Helpful Links & Resources",
    "section": "Theory",
    "text": "Theory\n\nPyTorch\nPyTorch internals - Blog Post\n\n\nDeep Learning and Computer Vision\nUniversity of Michigan - Deep Learning for Computer Vision\n\nSehr gute Vorlesung zum Thema\n\nUniversity of California, Berkeley - Modern Computer Vision and Deep Learning\n\nSehr gute Vorlesung zum Thema\n\n\n\nNeuronale Netzwerke - Basics\nPerceptron Learning Rule S. Raschka\nCS229 Stanford MLP Backpropagation\nNotes on Backpropagation\n3Blue1Brown Gradient Descent\n3Blue1Brown Backpropagation Calculus\nAndrew Ng Backprop\nAndrej Karpathy - Backpropagation from the ground up\n\n\nModel Selection\nPaper von S.Raschka: “Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning”",
    "crumbs": [
      "Resources",
      "Helpful Links & Resources"
    ]
  },
  {
    "objectID": "pages/misc/links.html#practical",
    "href": "pages/misc/links.html#practical",
    "title": "Helpful Links & Resources",
    "section": "Practical",
    "text": "Practical\nAndrej Karpathy - A Recipe for Training Neural Networks\n\nML Best Practices Videos\nMartin Zinkevich - Best Practices for ML Engineering\nAndrew Ng - Advice For Applying Machine Learning | Deciding What To Try Next\nAndrew Ng - Advice For Applying Machine Learning | Learning Curves\nAndrew Ng - Advice For Applying Machine Learning | Deciding What To Do Next (Revisited)\nAndrew Ng - Machine Learning System Design | Prioritizing What To Work On\nAndrew Ng - Machine Learning System Design | Error Analysis\nAndrew Ng - Machine Learning System Design | Data For Machine Learning",
    "crumbs": [
      "Resources",
      "Helpful Links & Resources"
    ]
  },
  {
    "objectID": "pages/misc/links.html#tools",
    "href": "pages/misc/links.html#tools",
    "title": "Helpful Links & Resources",
    "section": "Tools",
    "text": "Tools\n\nData Science Repository\nBuild a Reproducible and Maintainable Data Science Project\n\ngreat jupyter book to learen about how to structure a repository and more\n\nLightning-Hydra-Template\n\ntemplate to strcuture a repository based on experiment configuration with Hydra and Pytorch-Lightning\n\n\n\nData Handling\ndatasets\n\nGreat package to create and manage (large) image datasets\n\nimg2dataset\n\nPackage to download large image datasets from urls\n\nDVC\n\nPackage for data version control\n\n\n\nPyTorch\nLightning\n\nboilerplate code to easily train models and use gpu, etc.",
    "crumbs": [
      "Resources",
      "Helpful Links & Resources"
    ]
  },
  {
    "objectID": "pages/misc/demos.html",
    "href": "pages/misc/demos.html",
    "title": "Demos",
    "section": "",
    "text": "CNN Filters Visualization\nVisualize filters and their effect of a pre-trained ResNet-18.\n\n  \n\n\n\nCLIP Demo\nThis model can calculate similarities between and among images and texts. It can be used for zero-shot (no labels) image classification.\n\n  \n\n\n\nVisual Question Answering\nTest a model that can answer questions given an image. The notebook contains a small model which can be run on cpu and a much larger model which ideally is run on GPU."
  },
  {
    "objectID": "pages/background/neural_networks.html",
    "href": "pages/background/neural_networks.html",
    "title": "Neural Networks",
    "section": "",
    "text": "TipLearning Objectives\n\n\n\n\n\nAfter this lecture you should be able to:\n\nExplain the relationship between linear models and multilayer perceptrons.\nDescribe why activation functions enable non-linear function approximation.\nInterpret the role of depth vs width (efficiency of representation, hierarchical features).\nImplement and configure simple MLP architectures in PyTorch.",
    "crumbs": [
      "Background & Preparation",
      "Neural Networks"
    ]
  },
  {
    "objectID": "pages/background/neural_networks.html#biological-neural-networks",
    "href": "pages/background/neural_networks.html#biological-neural-networks",
    "title": "Neural Networks",
    "section": "Biological Neural Networks",
    "text": "Biological Neural Networks\nA biological neural network is a part of the nervous system and consists of interconnected neurons. A neuron is connected to other neurons via dendrites (these are “weighted” input signals) and via the axon (output signal) (see Figure 1). If the input signals exceed a certain threshold, the neuron “fires” and sends a signal through the axon, which then serves as an input signal for other neurons. Humans have about 86 billion neurons, each connected to about 1000 others on average (source).\n\n\n\n\n\n\nFigure 1: Schematic representation of connected neurons. Phillips (2015)\n\n\n\nOptical signals are processed, among other things, in the visual cortex (Figure 2). Signals are processed hierarchically, with the first layers recognizing simple patterns and later layers recognizing shapes and objects. See also the work of Hubel and Wiesel Hubel and Wiesel (1959).\n\n\n\n\n\n\nFigure 2: Representation of transformations in the visual cortex. Kubilius (2017)\n\n\n\nThe question that arises is:\nCan we create artificial neural networks and reproduce the performance of biological neural networks?",
    "crumbs": [
      "Background & Preparation",
      "Neural Networks"
    ]
  },
  {
    "objectID": "pages/background/neural_networks.html#artificial-neural-networks",
    "href": "pages/background/neural_networks.html#artificial-neural-networks",
    "title": "Neural Networks",
    "section": "Artificial Neural Networks",
    "text": "Artificial Neural Networks\nArtificial neural networks are models of biological networks. Such models were created and implemented technically as early as the 1940s.\nNeural networks are often represented with a graph. The nodes are individual neurons in the network, and the edges are connections between the neurons (see Figure 3). The neurons are arranged in layers, with each neuron in a layer connected to every neuron in adjacent layers. The input layer represents the data, the output layer the (observable) outputs, and the hidden layers are within the network. The connections between the neurons are weighted.\n\n\n\n\n\n\nFigure 3: A neural network with two hidden layers. The lines show connections between neurons. Source: Li (2022).",
    "crumbs": [
      "Background & Preparation",
      "Neural Networks"
    ]
  },
  {
    "objectID": "pages/background/neural_networks.html#from-linear-models-to-neural-networks",
    "href": "pages/background/neural_networks.html#from-linear-models-to-neural-networks",
    "title": "Neural Networks",
    "section": "From Linear Models to Neural Networks",
    "text": "From Linear Models to Neural Networks\nIn the following, we will describe neural networks mathematically. We start with a linear model. A linear model has the following form:\n\\[\\begin{equation}\n   f(\\mathbf{x}^{(i)}) = \\mathbf{W} \\mathbf{x}^{(i)}  +  \\mathbf{b}\n\\end{equation}\\]\nThe data point \\(i\\) is:\n\\[\\begin{equation}\n    \\mathbf{x}^{(i)} \\in \\mathbb{R}^{p \\times 1}\n\\end{equation}\\]\nAnd model weights:\n\\[\\begin{equation}\n   \\mathbf{W} \\in \\mathbb{R}^{k \\times p}\n\\end{equation}\\]\nAs well as a bias term:\n\\[\\begin{equation}\n   \\mathbf{b} \\in \\mathbb{R}^{k \\times 1}\n\\end{equation}\\]\nThe following parameters must be learned from data using an optimization method: \\(\\mathbf{W}\\) and \\(\\mathbf{b}\\).\nIn neural networks, the linear model is extended with additional layers. The following equation defines a neural network with two layers.\n\\[\\begin{equation}\n   f(\\mathbf{x}^{(i)}) = \\mathbf{W}^{(2)} g\\big(\\mathbf{W}^{(1)} \\mathbf{x}^{(i)}  +  \\mathbf{b}^{(1)} \\big)  +  \\mathbf{b}^{(2)}\n\\end{equation}\\]\nWhere \\(g()\\) is a so-called activation function, such as the ReLU function:\n\\[\\begin{equation}\n\\text{ReLU}(x) = \\begin{cases}\nx, & \\text{if } x \\geq 0 \\\\\n0, & \\text{if } x &lt; 0\n\\end{cases}\n\\end{equation}\\]\nOnly due to the activation function are non-linear relationships modelable. Without the activation function, the model collapses to a simple linear model.\nEvery layer between the input and output layer is called a hidden layer.\nTypically, not just one data point is processed but a mini-batch of data, or even the entire dataset. The data points are arranged in a data matrix \\(\\mathbf{X} \\in \\mathbb{R}^{n \\times p}\\). The linear model is then defined as follows:\n\\[\\begin{equation}\n   f( \\mathbf{X}) = \\mathbf{X} \\mathbf{W}^T  +  \\mathbf{b}^T\n\\end{equation}\\]\nThe bias term \\(\\mathbf{b}\\) is broadcasted (details here Link), so it can be added.\n\nActivation Functions\nThe following code shows how activation functions are important for modeling non-linear relationships. The model has a hidden layer with several neurons but (left) no activation function and (right) with ReLU activation.\n\n\n\n\n\n\n\n\nFigure 4: Linear (left) vs non-linear (right) activation function.\n\n\n\n\n\nFigure 5 now shows a neural network including activation functions (ReLU). Sometimes the biases are also shown as nodes that feed into the next layer.\n\n\n\n\n\n\nFigure 5: A neural network with a hidden layer. The lines show connections between neurons and their weights \\(w_{i,j}\\).\n\n\n\n\n\n\n\n\n\nNoteActivation Function Cheat Sheet\n\n\n\nCommon choices:\n\nReLU: \\(\\max(0, x)\\) (sparse activations, mitigates vanishing gradients).\nLeakyReLU / GELU: Smoother or with negative slope; GELU often used in transformers.\nSigmoid: Saturates; mainly for probabilities/logits output.\nTanh: Zero-centered but still saturates; rarely preferred over ReLU-family now.\nSoftplus / Mish / Swish: Smooth alternatives; sometimes modest gains, higher compute.\n\nGuideline: Start with ReLU (or GELU for transformer-like blocks); change only if you have empirical evidence.\n\n\n\n\nUniversal Approximation Theorem\nWith a shallow neural network, any continuous function can be modeled with arbitrary accuracy (Universal Approximation Theorem). The following graphic illustrates that as the number of linear functions (and thus piecewise linear regions) increases, the approximation of the underlying function becomes more accurate.\n\n\n\n\n\n\nFigure 6: Approximation of a 1-D function with piecewise linear regions. The more regions, the more accurate the approximation. Source: Prince (2023)\n\n\n\nNeural networks are therefore a particularly powerful class of models!",
    "crumbs": [
      "Background & Preparation",
      "Neural Networks"
    ]
  },
  {
    "objectID": "pages/background/neural_networks.html#deep-learning",
    "href": "pages/background/neural_networks.html#deep-learning",
    "title": "Neural Networks",
    "section": "Deep Learning",
    "text": "Deep Learning\nWhen there are multiple hidden layers, it is called deep learning. Fig. Figure 7 illustrates such a model with 5 hidden layers.\n\n\n\n\n\n\nFigure 7: Illustration of a deep learning model with 5 hidden layers, from Johnson (2022)\n\n\n\nSuch a model is also called a multilayer perceptron (MLP). It consists of linear layers and activation functions.\nDeep neural networks have more than one hidden layer. Although shallow neural networks can theoretically model arbitrarily complex functions, the number of neurons required is often impractical. It can be shown that adding hidden layers (increasing the depth of a network) is much more efficient (requires fewer neurons) for modeling complex functions.\nIn practice, it has been shown that the first layers in a network learn simple features. These are combined in deeper layers to learn and detect increasingly abstract concepts. This is well illustrated with images. When a neural network is applied to images, the first layers learn to detect simple features, such as edges and\ncolors. Further layers then detect shapes and objects, leading to specific items or people (see Fig. Figure 8).\n\n\n\n\n\n\nFigure 8: Hierarchical features, from Lee et al. (2011)\n\n\n\n\n\n\n\n\n\nInfo\nTo directly observe the functioning of a neural network and try out the influence of various configurations, you can train networks directly in the browser using the following link: TensorFlow Playground.",
    "crumbs": [
      "Background & Preparation",
      "Neural Networks"
    ]
  },
  {
    "objectID": "pages/background/neural_networks.html#implementation-in-pytorch",
    "href": "pages/background/neural_networks.html#implementation-in-pytorch",
    "title": "Neural Networks",
    "section": "Implementation in PyTorch",
    "text": "Implementation in PyTorch\nThe following code shows how we can implement a configurable neural network.\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass MLP(nn.Module):\n    def __init__(self, input_size, hidden_layer_sizes, num_outputs):\n        super().__init__()\n\n        # Initialize submodules of your module - typically layers\n        # that your module needs - these can then be used in the\n        # forward pass\n\n        self.flatten = nn.Flatten()\n\n        # a ModuleList allows you to flexibly chain submodules\n        # in a list - depending e.g. on configuration parameters\n\n        self.hidden_layers = nn.ModuleList()\n        last_size = input_size\n        for size in hidden_layer_sizes:\n            self.hidden_layers.append(nn.Linear(last_size, size))\n            last_size = size\n\n        self.output_layer = nn.Linear(last_size, num_outputs)\n\n    def forward(self, x):\n        \"\"\"The forward pass of your module.\"\"\"\n        x = self.flatten(x)\n        for layer in self.hidden_layers:\n            x = F.relu(layer(x))\n        x = self.output_layer(x)\n        return x\n\n# Example usage:\n# Initialize the model with input size 784, one hidden layer of size 128, and 10 output units.\nmodel = MLP(784, [128], 10)\n\n# Example input vector (batch size of 32, input size of 784)\nx = torch.randn(32, 784)\n\n# Forward pass\noutput = model(x)\n\nWe can easily display the architecture details with torchinfo\n\n# Display the model architecture\nfrom torchinfo import summary\nsummary(model, input_size=(32, 784))\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMLP                                      [32, 10]                  --\n├─Flatten: 1-1                           [32, 784]                 --\n├─ModuleList: 1-2                        --                        --\n│    └─Linear: 2-1                       [32, 128]                 100,480\n├─Linear: 1-3                            [32, 10]                  1,290\n==========================================================================================\nTotal params: 101,770\nTrainable params: 101,770\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 3.26\n==========================================================================================\nInput size (MB): 0.10\nForward/backward pass size (MB): 0.04\nParams size (MB): 0.41\nEstimated Total Size (MB): 0.54\n==========================================================================================\n\n\n\n\n\n\n\n\nQuestion\nHow many parameters does this neural network have, and why?\n\n\nAnswer\n\nBased on the torchinfo summary output above, the network has:\nLayer 1: 784 inputs × 128 hidden units + 128 biases = 100,480 parameters\nLayer 2: 128 inputs × 10 outputs + 10 biases = 1,290 parameters\nTotal: 101,770 parameters\nEach fully connected layer has: - Weight matrix of size (input_dim × output_dim) - Bias vector of size (output_dim)\nThis is why the number of parameters grows quickly with network size!\n\n\n\n\n\n\n\n\n\n\nInfo\nTo refresh your knowledge on neural networks, it is worth watching the following videos: 3Blue1Brown - Neural Networks",
    "crumbs": [
      "Background & Preparation",
      "Neural Networks"
    ]
  },
  {
    "objectID": "pages/background/neural_networks.html#references",
    "href": "pages/background/neural_networks.html#references",
    "title": "Neural Networks",
    "section": "References",
    "text": "References\n\n\nHubel, D. H., and T. N. Wiesel. 1959. “Receptive Fields of Single Neurones in the Cat’s Striate Cortex.” The Journal of Physiology 148 (3): 574–91. https://doi.org/10.1113/jphysiol.1959.sp006308.\n\n\nJohnson, Justin. 2022. “EECS 498.008 / 598.008 Deep Learning for Computer Vision.” Lecture {Notes} / {Slides}. https://web.eecs.umich.edu/~justincj/teaching/eecs498/WI2022/.\n\n\nKubilius, Jonas. 2017. “Ventral Visual Stream.” https://figshare.com/articles/figure/Ventral_visual_stream/106794.\n\n\nLee, Honglak, Roger Grosse, Rajesh Ranganath, and Andrew Y. Ng. 2011. “Unsupervised Learning of Hierarchical Representations with Convolutional Deep Belief Networks.” Communications of the ACM 54 (10): 95–103. https://doi.org/10.1145/2001269.2001295.\n\n\nLi, Fei-Fei. 2022. “CS231n Convolutional Neural Networks for Visual Recognition.” Lecture {Notes}. https://cs231n.github.io.\n\n\nPhillips, Devin K. 2015. “Speed of the Human Brain.” Ask A Biologist, May. https://askabiologist.asu.edu/plosable/speed-human-brain.\n\n\nPrince, Simon J. D. 2023. Understanding Deep Learning. MIT Press. https://udlbook.github.io/udlbook/.",
    "crumbs": [
      "Background & Preparation",
      "Neural Networks"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html",
    "href": "pages/background/frameworks.html",
    "title": "Software & Hardware for Deep Learning",
    "section": "",
    "text": "TipLearning Objectives\n\n\n\n\n\nAfter this lecture you should be able to:\n\nExplain the role of computational graphs and automatic differentiation in deep learning frameworks.\nConstruct and inspect tensors, modules, and optimization loops in PyTorch.\nDistinguish autograd vs manual gradient computation and identify common pitfalls (forgetting zero_grad, device mismatches).\nDescribe core hardware considerations (GPU parallelism, data loading bottlenecks, CUDA/cuDNN impact).\nLoad and adapt pre-trained models responsibly for downstream tasks.",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#computational-graph-autograd",
    "href": "pages/background/frameworks.html#computational-graph-autograd",
    "title": "Software & Hardware for Deep Learning",
    "section": "Computational Graph & Autograd",
    "text": "Computational Graph & Autograd\nAt the core of neural networks is the Computational Graph. It automatically embeds dependent operations in a directed acyclic graph (DAG). Gradients are tracked as needed, allowing variables to be efficiently updated/trained.\nThe following shows an example in Numpy where we define computations and manually calculate derivatives. The graph is shown in Figure 2.\n\\[\\begin{equation}\n    f(\\mathbf{A}, \\mathbf{B}, \\mathbf{C}) =  \\sum_{ij} \\big((\\mathbf{A} \\odot \\mathbf{B}) + \\mathbf{C}\\big)_{ij}\n\\end{equation}\\]\n\n\n\n\n\n\nFigure 2: Computational Graph.\n\n\n\n\nimport numpy as np\n\nnp.random.seed(123)\n\nH, W = 2, 3\n\na = np.random.random(size=(H, W))\nb = np.random.random(size=(H, W))\nc = np.random.random(size=(H, W))\n\nd = a * b\ne = d + c\nf = e.sum()\n\ndf_de = 1.0               # d f / d e\nde_dd = 1.0               # d e / d d   (since e = d + c)\nde_dc = np.ones_like(c)   # d e / d c   (derivative of addition w.r.t. c)\ndd_da = b                 # d (a*b) / d a\ndd_db = a                 # d (a*b) / d b\n\ndf_da = df_de * de_dd * dd_da          # chain rule\ndf_db = df_de * de_dd * dd_db\ndf_dc = df_de * de_dc                  # equals ones\n\nprint(\"df/da=\\n\", df_da)\nprint(\"df/db=\\n\", df_db)\nprint(\"df/dc=\\n\", df_dc)\n\ndf/da=\n [[0.9807642  0.68482974 0.4809319 ]\n [0.39211752 0.34317802 0.72904971]]\ndf/db=\n [[0.69646919 0.28613933 0.22685145]\n [0.55131477 0.71946897 0.42310646]]\ndf/dc=\n [[1. 1. 1.]\n [1. 1. 1.]]\n\n\nHere’s the same example in PyTorch. Using x.backward(), gradients with respect to x are computed for variables connected to x.\n\nimport torch\n\nnp.random.seed(123)\n\nH, W = 2, 3\n\na = torch.tensor(a, requires_grad=True)\nb = torch.tensor(b, requires_grad=True)\nc = torch.tensor(c, requires_grad=True)\n\nd = a * b\ne = d + c\nf = e.sum()\n\nf.backward()\nprint(a.grad)\n\ntensor([[0.9808, 0.6848, 0.4809],\n        [0.3921, 0.3432, 0.7290]], dtype=torch.float64)\n\n\nHere are the nodes of the computational graph.\n\nfrom torchviz import make_dot\nmake_dot(f, params={'a': a, 'b': b, 'c': c, 'f':f , 'd': d, 'e':e })\n\n\n\n\n\n\n\n\nTo perform the computation on a GPU, a simple instruction is enough:\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device\")\n\na = a.to(device=device)\nb = b.to(device=device)\nc = c.to(device=device)\n\nUsing cpu device",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#fundamental-concepts",
    "href": "pages/background/frameworks.html#fundamental-concepts",
    "title": "Software & Hardware for Deep Learning",
    "section": "Fundamental Concepts",
    "text": "Fundamental Concepts\nPyTorch is built around three core concepts:\n\nTensor: N-dimensional array, similar to numpy.array but with GPU acceleration\nAutograd: Automatic differentiation to create computational graphs and compute gradients\nModule: Base class (nn.Module) to define components of neural networks with learnable parameters",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#tensors",
    "href": "pages/background/frameworks.html#tensors",
    "title": "Software & Hardware for Deep Learning",
    "section": "Tensors",
    "text": "Tensors\ntorch.Tensor is the central data structure in PyTorch. Essentially very similar to numpy.array, it can be easily loaded onto GPUs.\nTensors can be created in various ways. For example, from lists:\n\ndata = [[1, 2],[3, 4]]\nx_data = torch.tensor(data)\nprint(x_data)\n\ntensor([[1, 2],\n        [3, 4]])\n\n\nOr from numpy.ndarray:\n\nnp_array = np.array(data)\nx_np = torch.from_numpy(np_array)\nprint(x_np)\n\ntensor([[1, 2],\n        [3, 4]])\n\n\nOr from other tensors:\n\nx_ones = torch.ones_like(x_data) # retains the properties of x_data\nprint(f\"Ones Tensor: \\n {x_ones} \\n\")\n\nx_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\nprint(f\"Random Tensor: \\n {x_rand} \\n\")\n\nOnes Tensor: \n tensor([[1, 1],\n        [1, 1]]) \n\nRandom Tensor: \n tensor([[0.8165, 0.7142],\n        [0.5403, 0.7578]]) \n\n\n\nOr with randomly generated numbers or constants:\n\nshape = (2,3,)\nrand_tensor = torch.rand(shape)\nones_tensor = torch.ones(shape)\nzeros_tensor = torch.zeros(shape)\n\nprint(f\"Random Tensor: \\n {rand_tensor} \\n\")\nprint(f\"Ones Tensor: \\n {ones_tensor} \\n\")\nprint(f\"Zeros Tensor: \\n {zeros_tensor}\")\n\nRandom Tensor: \n tensor([[0.3382, 0.7472, 0.8157],\n        [0.4497, 0.2306, 0.4667]]) \n\nOnes Tensor: \n tensor([[1., 1., 1.],\n        [1., 1., 1.]]) \n\nZeros Tensor: \n tensor([[0., 0., 0.],\n        [0., 0., 0.]])\n\n\nTensor attributes:\n\ntensor = torch.rand(3,4)\n\nprint(f\"Shape of tensor: {tensor.shape}\")\nprint(f\"Datatype of tensor: {tensor.dtype}\")\nprint(f\"Device tensor is stored on: {tensor.device}\")\n\nShape of tensor: torch.Size([3, 4])\nDatatype of tensor: torch.float32\nDevice tensor is stored on: cpu\n\n\nThere are over 100 operations that can be performed on a tensor. The full list is available here.\nIndexing and Slicing:\n\ntensor = torch.ones(4, 4)\nprint(f\"First row: {tensor[0]}\")\nprint(f\"First column: {tensor[:, 0]}\")\nprint(f\"Last column: {tensor[:, -1]}\")\ntensor[:,1] = 0\nprint(tensor)\n\nFirst row: tensor([1., 1., 1., 1.])\nFirst column: tensor([1., 1., 1., 1.])\nLast column: tensor([1., 1., 1., 1.])\ntensor([[1., 0., 1., 1.],\n        [1., 0., 1., 1.],\n        [1., 0., 1., 1.],\n        [1., 0., 1., 1.]])\n\n\nJoining tensors:\n\nt1 = torch.cat([tensor, tensor, tensor], dim=1)\nprint(t1)\n\ntensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n\n\nArithmetic operations:\n\n# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\ny1 = tensor @ tensor.T\ny2 = tensor.matmul(tensor.T)\n\ny3 = torch.rand_like(y1)\ntorch.matmul(tensor, tensor.T, out=y3)\n\n\n# This computes the element-wise product. z1, z2, z3 will have the same value\nz1 = tensor * tensor\nz2 = tensor.mul(tensor)\n\nz3 = torch.rand_like(tensor)\ntorch.mul(tensor, tensor, out=z3)\n\ntensor([[1., 0., 1., 1.],\n        [1., 0., 1., 1.],\n        [1., 0., 1., 1.],\n        [1., 0., 1., 1.]])",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#autograd",
    "href": "pages/background/frameworks.html#autograd",
    "title": "Software & Hardware for Deep Learning",
    "section": "Autograd",
    "text": "Autograd\nTo train neural networks, backpropagation is typically used. This calculates the gradient of the loss function with respect to the model parameters. To compute these gradients, PyTorch provides an auto-diff functionality: torch.autograd. This can automatically compute gradients for a computational graph.\n\n\n\n\n\n\nTipAutograd Key Points\n\n\n\n\nSet requires_grad=True on tensors you want to track for gradient computation\nCall .backward() on a scalar loss to compute all gradients\nAccess gradients via .grad attribute of tensors\nUse torch.no_grad() context for inference to save memory and speed up computation\n\n\n\nThe following is an example using a 1-layer neural network (see Figure 3 ):\n\n\n\n\n\n\nFigure 3: Source: PyTorch\n\n\n\nHere is the definition of the network in PyTorch:\n\nimport torch\n\nx = torch.ones(5)  # input tensor\ny = torch.zeros(3)  # expected output\nw = torch.randn(5, 3, requires_grad=True)\nb = torch.randn(3, requires_grad=True)\nz = torch.matmul(x, w)+b\nloss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n\nWe can now use Autograd to compute the gradient:\n\nloss.backward()\nprint(w.grad)\nprint(b.grad)\n\ntensor([[0.2368, 0.2073, 0.2648],\n        [0.2368, 0.2073, 0.2648],\n        [0.2368, 0.2073, 0.2648],\n        [0.2368, 0.2073, 0.2648],\n        [0.2368, 0.2073, 0.2648]])\ntensor([0.2368, 0.2073, 0.2648])",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#torch.nn",
    "href": "pages/background/frameworks.html#torch.nn",
    "title": "Software & Hardware for Deep Learning",
    "section": "torch.nn",
    "text": "torch.nn\nPyTorch provides various building blocks for creating neural networks. These are available in torch.nn. Additionally, you can define any compositions of such building blocks that inherit from torch.nn.Module. A neural network is typically a torch.nn.Module. Each module implements the forward() method to define how data is processed.\n\n\n\n\n\n\nTipBuilding Blocks in torch.nn\n\n\n\nCommon layers:\n\nnn.Linear: Fully connected layer\nnn.Conv2d: 2D convolutional layer\nnn.MaxPool2d: Max pooling layer\nnn.Dropout: Regularization via random dropout\nnn.BatchNorm2d: Batch normalization\n\nCommon activations:\n\nnn.ReLU(), nn.LeakyReLU(), nn.GELU()\nnn.Sigmoid(), nn.Softmax()\n\nLoss functions:\n\nnn.CrossEntropyLoss(): Classification\nnn.BCEWithLogitsLoss(): Binary classification\nnn.MSELoss(): Regression\n\n\n\nHere is an example:\n\nfrom torch import nn\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\nYou can also visualize the model:\n\nmodel = NeuralNetwork()\nprint(model)\n\nNeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_stack): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n\n\nTo use the model, you can pass input data. This will execute the forward() method, along with background operations.\n\nX = torch.rand(1, 28, 28)\nlogits = model(X)\npred_probab = nn.Softmax(dim=1)(logits)\ny_pred = pred_probab.argmax(1)\nprint(f\"Predicted class: {y_pred}\")\n\nPredicted class: tensor([9])\n\n\nThe executed operations will look like this:\n\nfrom torchviz import make_dot\nmake_dot(logits)",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#torch.optim",
    "href": "pages/background/frameworks.html#torch.optim",
    "title": "Software & Hardware for Deep Learning",
    "section": "torch.optim",
    "text": "torch.optim\nTo optimize the parameters of a model, you need an optimization algorithm. torch.optim implements various algorithms, such as Stochastic Gradient Descent or the often used Adam Optimizer.\n\n\n\n\n\n\n\nTipCommon Optimizers\n\n\n\n\nSGD: Basic stochastic gradient descent (with optional momentum)\nAdam: Adaptive learning rates, good default choice\nAdamW: Adam with weight decay, often better for transformers (see Loshchilov and Hutter (2019))\nRMSprop: Adaptive learning rates, good for RNNs\nLearning rate schedulers: Adjust learning rate during training (e.g., torch.optim.lr_scheduler)\n\nRule of thumb: Start with Adam, then try SGD with momentum if you need better generalization.\n\n\n\nfrom torch import optim\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\nYou can then use the optimizer to adjust the parameters, you just need to define a loss function:\n\nloss_fn = torch.nn.CrossEntropyLoss()\nfor i in range(0, 3):\n    input, target = torch.rand(1, 28, 28), torch.randint(low=0, high=10, size=(1, ))\n    optimizer.zero_grad()\n    output = model(input)\n    loss = loss_fn(output, target)\n    loss.backward()\n    optimizer.step()\n\n\n\n\n\n\n\nTipCommon Pitfalls & Solutions\n\n\n\nPitfall 1: Forgetting zero_grad()\n# ❌ Wrong - gradients accumulate\nfor batch in dataloader:\n    loss = compute_loss(batch)\n    loss.backward()\n    optimizer.step()\n\n# ✅ Correct\nfor batch in dataloader:\n    optimizer.zero_grad()  # Clear previous gradients\n    loss = compute_loss(batch)\n    loss.backward()\n    optimizer.step()\nPitfall 2: Device mismatch\n# ❌ Wrong - model on GPU, data on CPU\nmodel = model.cuda()\nfor batch_x, batch_y in dataloader:\n    pred = model(batch_x)  # Error!\n\n# ✅ Correct\nmodel = model.cuda()\nfor batch_x, batch_y in dataloader:\n    batch_x = batch_x.cuda()\n    batch_y = batch_y.cuda()\n    pred = model(batch_x)\nPitfall 3: Not using eval() mode for inference\n# ❌ Wrong - dropout and batchnorm active during inference\npredictions = model(test_data)\n\n# ✅ Correct\nmodel.eval()\nwith torch.no_grad():\n    predictions = model(test_data)\nmodel.train()  # Switch back to training mode",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#training-loops",
    "href": "pages/background/frameworks.html#training-loops",
    "title": "Software & Hardware for Deep Learning",
    "section": "Training Loops",
    "text": "Training Loops\nTypically, you put together a training loop to train a model. A training loop iterates over batches of data and optimizes the model parameters with each iteration.\n\ndef train_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()  # &lt;-- important!\n    for batch, (X, y) in enumerate(dataloader):\n        # Compute prediction and loss\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]\")\n\n\ndef test_loop(dataloader, model, loss_fn):\n    model.eval()  # &lt;-- important!\n\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    test_loss, correct = 0, 0\n\n    with torch.no_grad():  # disables gradient tracking for efficiency\n        for X, y in dataloader:\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n\n    test_loss /= num_batches\n    correct /= size\n    print(\n        f\"Test Error:\\n Accuracy: {(100 * correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f}\\n\"\n    )\n\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\nepochs = 10\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_loop(train_dataloader, model, loss_fn, optimizer)\n    test_loop(test_dataloader, model, loss_fn)\nprint(\"Done!\")\n\n\n\n\n\n\n\nNote\n\n\n\nHigh-level APIs such as Lightning and Keras provide many functionalities to simplify managing training loops. It is highly recommended to use such libraries to reduce boiler-plate code. However, it depends on the individual complexity of a project to what degree such libraries are useful.",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#pre-trained-models",
    "href": "pages/background/frameworks.html#pre-trained-models",
    "title": "Software & Hardware for Deep Learning",
    "section": "Pre-trained models",
    "text": "Pre-trained models\nSince training models can be time-consuming and expensive, pre-trained models are often used. They allow models to be adapted to a specific task more quickly and cost-effectively. In many areas, particularly NLP and computer vision, using pre-trained models is standard. PyTorch provides torchvision for computer vision applications. torchvision provides functionalities useful for modeling image data. Pre-trained models can also be easily integrated, as shown in the following example:\n\nfrom torchvision.models import resnet50, ResNet50_Weights\n\nweights = ResNet50_Weights.IMAGENET1K_V2\nmodel = resnet50(weights=weights)",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#tensorflow",
    "href": "pages/background/frameworks.html#tensorflow",
    "title": "Software & Hardware for Deep Learning",
    "section": "TensorFlow",
    "text": "TensorFlow\nFor a long time, PyTorch and TensorFlow have been the two dominant deep learning frameworks. TensorFlow, developed by Google, is known for its production-readiness, ecosystem integration (e.g., TensorFlow Extended (TFX) for MLOps pipelines, LiteRT for mobile, and TensorFlow.js for web), and its scalability across distributed hardware.\nIn recent years, however, TensorFlow’s low-level API has become less popular in research compared to PyTorch, which offers more flexibility and Pythonic design. Today, most TensorFlow users rely almost exclusively on Keras, its high-level API, to define and train models, while the TensorFlow backend provides performance, device management, and deployment capabilities.",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#keras",
    "href": "pages/background/frameworks.html#keras",
    "title": "Software & Hardware for Deep Learning",
    "section": "Keras",
    "text": "Keras\nKeras started as an independent high-level deep learning API designed to simplify model creation with a clean and intuitive syntax. Since 2017, it has been tightly integrated into TensorFlow as its official front-end (tf.keras), and in 2023, Keras Core was introduced, a framework-agnostic version that can run on multiple backends such as TensorFlow, JAX, and PyTorch.\nKeras focuses on ease of use, modularity, and rapid prototyping, making it an excellent choice for teaching, applied machine learning, and fast experimentation, while still being production-ready through TensorFlow’s ecosystem.",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#jax",
    "href": "pages/background/frameworks.html#jax",
    "title": "Software & Hardware for Deep Learning",
    "section": "Jax",
    "text": "Jax\nJax has gained significant popularity in recent years. Developed by researchers at Google, it is primarily used in research and foundation-model development. Jax provides a NumPy-like API with automatic differentiation (autodiff) and function transformations such as jit (for compilation) and vmap (for vectorization). It enables high-performance, composable numerical computing, and serves as the foundation for frameworks such as Flax (Neural Networks) and Haiku (ML Research).",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#scikit-learn",
    "href": "pages/background/frameworks.html#scikit-learn",
    "title": "Software & Hardware for Deep Learning",
    "section": "Scikit-Learn",
    "text": "Scikit-Learn\nScikit-Learn is THE machine learning framework in Python. However, Scikit-Learn never covered the area of neural networks and lacks auto-diff functionality. Therefore, Scikit-Learn is irrelevant when training neural networks. However, Scikit-Learn functionalities are often used to carry out the machine learning process, such as splitting datasets into train, validation, and test sets. Also, visualizations, such as the confusion matrix or calculating metrics, can be done via Scikit-Learn.",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#onnx",
    "href": "pages/background/frameworks.html#onnx",
    "title": "Software & Hardware for Deep Learning",
    "section": "ONNX",
    "text": "ONNX\ny§ ONNX (Open Neural Network Exchange) is an open format to represent machine learning models. It allows models trained in one framework to be transferred to another. Trained models can also be deployed on various platforms.",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#monitoring",
    "href": "pages/background/frameworks.html#monitoring",
    "title": "Software & Hardware for Deep Learning",
    "section": "Monitoring",
    "text": "Monitoring\nWhen training models, monitoring the training process, debugging, and logging hyperparameters, metrics, etc., is very important. Various tools enable these functionalities. Well-known examples are TensorBoard and Weights & Biases.",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#tensor-operations",
    "href": "pages/background/frameworks.html#tensor-operations",
    "title": "Software & Hardware for Deep Learning",
    "section": "Tensor Operations",
    "text": "Tensor Operations\nIn neural networks, there are many tensor operations. Tensors are essentially multi-dimensional arrays, such as a scalar \\(x\\), a vector \\(\\mathbf{x}\\), or a matrix \\(\\mathbf{X}\\).\nFigure 4 illustrates a matrix multiplication, a typical representative of a tensor operation. As you can see, the calculations (entries of the matrix \\(\\mathbf{A}\\mathbf{C}\\)) are independent of each other and can be fully parallelized.\n\n\n\n\n\n\nFigure 4: Matrix Multiplication (from Li (2022)).",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#graphics-processing-units-gpus",
    "href": "pages/background/frameworks.html#graphics-processing-units-gpus",
    "title": "Software & Hardware for Deep Learning",
    "section": "Graphics Processing Units (GPUs)",
    "text": "Graphics Processing Units (GPUs)\nGPUs have made deep learning possible in the first place. With their parallel structure, they can efficiently compute parallelizable tasks such as tensor operations.\nCPUs have far fewer cores than GPUs, but they are faster and can handle more complex tasks. CPUs are therefore ideal for sequential tasks. GPUs have many more cores, which are less complex and slower. Therefore, GPUs are excellent for parallel tasks. Figure 5 illustrates the differences.\n\n\n\n\n\n\nFigure 5: CPU vs GPU example (from Li (2022)).",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#cuda-cudnn",
    "href": "pages/background/frameworks.html#cuda-cudnn",
    "title": "Software & Hardware for Deep Learning",
    "section": "CUDA & cuDNN",
    "text": "CUDA & cuDNN\nCUDA is an API by Nvidia to perform computations on the GPU. It allows parallelizable tasks to be implemented efficiently. cuDNN is a library that efficiently executes certain operations, such as convolutions, in neural networks on the GPU. cuDNN is based on CUDA and significantly accelerates the training of neural networks. Figure 6 illustrates speed differences when training various neural networks with CPU, GPU, and optimized cuDNN.\n\n\n\n\n\n\nFigure 6: Speed comparison (from Li (2022), data from Link)",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#data-loading",
    "href": "pages/background/frameworks.html#data-loading",
    "title": "Software & Hardware for Deep Learning",
    "section": "Data Loading",
    "text": "Data Loading\nA crucial bottleneck in practice is the transfer of data (such as images) from the disk to the GPU. If this transfer is not fast enough, it is referred to as GPU starvation. There are several approaches to solve this problem:\n\nRead the data into RAM (not feasible for larger datasets)\nUse fast disks, such as SSDs\nUtilize multiple CPU threads to read data in parallel and keep it in RAM (pre-fetching)\n\nFigure 7 shows the various components.\n\n\n\n\n\n\nFigure 7: Source: Li (2022)\n\n\n\nDeep learning frameworks like PyTorch implement special classes that allow data to be prepared in multiple threads. Sometimes a certain number of CPU cores is needed to supply a GPU with enough data. Figure 8 shows a starved GPU: You can clearly see that the utilization repeatedly drops to 0 because the GPU has to wait for data.\n\n\n\n\n\n\nFigure 8: The Y-axis shows the GPU utilization in percentage, while the X-axis represents time. Source",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/frameworks.html#gpu-parallelism",
    "href": "pages/background/frameworks.html#gpu-parallelism",
    "title": "Software & Hardware for Deep Learning",
    "section": "GPU Parallelism",
    "text": "GPU Parallelism\nModels can also be trained on multiple GPUs. There are two main paradigms: data parallelism and model parallelism (see Figure 9 ). With data parallelism, each GPU has a copy of the model, and each GPU is trained on different data batches. With model parallelism, the model is split across multiple GPUs. Models can be trained on a server with multiple GPUs or even over the network (distributed). ML frameworks provide functionalities to handle these.\n\n\n\n\n\n\nFigure 9: Data and Model Parallelism (from Li (2022)).",
    "crumbs": [
      "Background & Preparation",
      "Software & Hardware for Deep Learning"
    ]
  },
  {
    "objectID": "pages/background/machine_learning.html",
    "href": "pages/background/machine_learning.html",
    "title": "Machine Learning Basics",
    "section": "",
    "text": "TipLearning Objectives\n\n\n\n\n\nAfter reviewing this material you should be able to:\n\nDescribe the data-driven approach to machine learning and its core workflow (collect, train, evaluate).\nDefine what a model is mathematically and distinguish between parameters and hyperparameters.\nExplain the role of optimization in fitting models and identify common cost/loss functions.\nJustify why train/validation/test splits are necessary for unbiased model evaluation.\nInterpret the machine learning pipeline from data acquisition through deployment.\nApply model selection principles to choose between competing models.",
    "crumbs": [
      "Background & Preparation",
      "Machine Learning Basics"
    ]
  },
  {
    "objectID": "pages/background/machine_learning.html#the-data-driven-approach",
    "href": "pages/background/machine_learning.html#the-data-driven-approach",
    "title": "Machine Learning Basics",
    "section": "The Data-Driven Approach",
    "text": "The Data-Driven Approach\nWe follow a data-driven approach in machine learning to solve various tasks. Typically, the process involves:\n\nCollecting a dataset of observations (e.g. images) and their labels.\nUsing a machine learning algorithm to train a model that learns to associate observations with labels.\nEvaluating/applying the model on new data.\n\n\ndef train(observations, labels):\n    \"\"\"Train a Model\"\"\"\n    # Fit Model here\n    return model\n\n\ndef predict(test_observations, model):\n    \"\"\"Predict\"\"\"\n    predictions = model(test_observations)\n    return predictions\n\nNow let’s see this data-driven approach applied to a concrete computer vision task: image super-resolution. This example demonstrates how the same train() and predict() framework works for complex image processing problems.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Image super-resolution demonstration: Converting a low-resolution (100×100 pixels) image to high-resolution (400×400 pixels). The middle panel shows why naive upscaling fails—it remains pixelated. Machine learning models learn to add realistic high-frequency details.\n\n\n\n🤔 Think About It\nHow would you train a model for image super-resolution? The task is to upscale low-resolution images to high-resolution with the best possible quality.\n\n\nKey considerations\n\n\nTraining data: Pairs of low-res and high-res images (can be created by downsampling high-res images)\nLoss function: Measure difference between predicted high-res and actual high-res\nArchitecture: CNN that learns to add high-frequency details\nEvaluation: Visual quality metrics (PSNR, SSIM) and perceptual similarity",
    "crumbs": [
      "Background & Preparation",
      "Machine Learning Basics"
    ]
  },
  {
    "objectID": "pages/background/machine_learning.html#machine-learning-process",
    "href": "pages/background/machine_learning.html#machine-learning-process",
    "title": "Machine Learning Basics",
    "section": "Machine Learning Process",
    "text": "Machine Learning Process\nWhen modeling data, one often follows certain process steps: acquiring data, preparing it, training multiple models, selecting the most suitable model, estimating its future performance, and finally deploying it in production. Figure 2 illustrates this process graphically.\n\n\n\n\n\n\nFigure 2: Machine Learning Pipeline (Source: Raschka and Mirjalili (2020))\n\n\n\nAt the core of a machine learning application is typically a mathematical model, which is fitted to a dataset so that it can then be used for prediction (in supervised learning). We often refer to ‘models’, meaning the mathematical description of the dataset.",
    "crumbs": [
      "Background & Preparation",
      "Machine Learning Basics"
    ]
  },
  {
    "objectID": "pages/background/machine_learning.html#models",
    "href": "pages/background/machine_learning.html#models",
    "title": "Machine Learning Basics",
    "section": "Models",
    "text": "Models\nA model is typically described as a function of a data point, generating an output \\(\\hat{y}\\):\n\\[\\begin{align*}\nf(\\mathbf{x}^{(i)}) = \\hat{y}^{(i)}\n\\end{align*}\\]\nMost models have parameters or coefficients that describe the model. The entirety of all parameters is denoted by \\(\\theta\\).\n\\[\\begin{align*}\nf_{\\theta}(\\mathbf{x}^{(i)}) \\text{ or } f(\\theta, \\mathbf{x}^{(i)})\n\\end{align*}\\]\nFor simplicity, we often omit \\(\\theta\\): \\(f(\\mathbf{x}^{(i)})\\)\n\n\n\n\n\n\nNoteLinear Regression Example\n\n\n\n\n\nTo make this concrete, consider linear regression, one of the simplest models. It learns a straight line through data:\n\\[f_\\theta(x) = \\theta_0 + \\theta_1 x\\]\nWhere the parameters are:\n\n\\(\\theta_0\\) (intercept): Where the line crosses the y-axis\n\\(\\theta_1\\) (slope): How steep the line is\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom typing import Callable\n\n\ndef create_linear_model_string(lr, feature_names=None):\n    \"\"\"Create string representation of linear model\"\"\"\n    intercept = lr.intercept_.flatten()\n    coefficients = lr.coef_.flatten()\n    params = np.concatenate([intercept, coefficients])\n\n    if not feature_names:\n        feature_names = [f\"x_{i + 1}^{{(i)}}\" for i in range(0, len(coefficients))]\n    param_strings = [\n        f\"{value:.4f} * {name}\"\n        for name, value in zip([\"1\"] + list(feature_names), params)\n    ]\n    formula = \" + \".join(param_strings)\n    return f\"$y^{{(i)}} = {formula} + \\\\epsilon^{{(i)}}$\"\n\n\ndef calculate_grid_1d(X: np.ndarray, model, step_size: float = 0.02):\n    \"\"\"Calculates Model Predictions on a Grid over the Space of X\"\"\"\n    assert X.ndim == 1\n    x_grid = np.arange(X.min(), X.max(), step_size)\n    p = model.predict(x_grid.reshape(-1, 1))\n    return x_grid, p.ravel()\n\n\ndef add_noise(x: np.ndarray, scale: float = 0.5, seed: int = 123):\n    \"\"\"Add random noise to inputs\"\"\"\n    rng = np.random.default_rng(seed)\n    return x + rng.normal(loc=0.0, scale=scale, size=x.shape)\n\n\ndef create_dataset(\n    fun: Callable = lambda x: x,\n    n_samples: int = 20,\n    x_min: int = 0,\n    x_max: int = 10,\n    noise_scale: float = 0.3,\n    seed: int = 0,\n):\n    \"\"\"Sample Data from True Function.\"\"\"\n    x = np.linspace(0, x_max, n_samples).reshape(-1, 1)\n    y = fun(x)\n    # prevent negative values\n    y_noise = np.clip(add_noise(y, scale=noise_scale, seed=seed), 0, np.inf)\n    return x, y, y_noise\n\n\n# Create synthetic dataset (from lecture 2)\nX, y, y_noise = create_dataset(n_samples=40, noise_scale=1.0)\n\n# Fit linear regression model\nlr = LinearRegression()\nlr = lr.fit(X, y_noise)\ny_pred = lr.predict(X)\nx_grid, y_grid = calculate_grid_1d(X.ravel(), lr)\n\n# Create visualization\nfig, ax = plt.subplots(figsize=(8, 5))\nform = create_linear_model_string(lr)\ntitle = \"Linear Model 1-D\\n\" + form\n_ = sns.scatterplot(x=X.ravel(), y=y_noise.ravel(), ax=ax).set(\n    title=title, xlabel=\"x\", ylabel=\"y\"\n)\n_ = sns.lineplot(x=x_grid, y=y_grid, color=\"red\")\n_ = ax.vlines(\n    X.ravel(), y_pred, y_noise, color=\"black\", linestyles=\"dashed\", linewidths=0.5\n)\nplt.show()\n\nprint(f\"θ₀ (intercept): {lr.intercept_[0]:.3f}\")\nprint(f\"θ₁ (slope): {lr.coef_[0][0]:.3f}\")\n\n\n\n\n\nLinear regression fitted to synthetic 1D dataset. The red line shows the learned model, and dashed lines show residuals (errors) for each data point.\n\n\n\n\nθ₀ (intercept): -0.215\nθ₁ (slope): 1.031\n\n\nKey insight: The model \\(f_\\theta(x)\\) transforms any input \\(x\\) into a prediction \\(\\hat{y}\\) using the learned parameters \\(\\theta_0, \\theta_1\\).",
    "crumbs": [
      "Background & Preparation",
      "Machine Learning Basics"
    ]
  },
  {
    "objectID": "pages/background/machine_learning.html#optimization",
    "href": "pages/background/machine_learning.html#optimization",
    "title": "Machine Learning Basics",
    "section": "Optimization",
    "text": "Optimization\nThe coefficients are fitted to a training dataset through an optimization procedure.\nThe optimization procedure can often be influenced by additional factors, called hyperparameters (\\(\\alpha, \\lambda, \\dots\\)). These cannot be directly optimized.\nThe function/quantity to be optimized is usually called the cost function, i.e., cost function (other terms include objective function, loss function, etc.). We use \\(J(\\cdot)\\) to denote the cost function. Often, the cost function is also referred to as the loss function \\(L(\\cdot)\\). We use \\(l(\\cdot)\\) for the per-sample loss, i.e., the computation of the cost function on a single sample.\nOur goal is to find a model (and its parameters) that minimizes the cost function:\n\\[\\begin{equation*}\n\\mathsf{argmin}_{\\theta, \\lambda} J\\Big(f_{\\theta, \\lambda}(\\mathbf{X}), \\mathbf{y}\\Big)\n\\end{equation*}\\]\n\n\n\n\n\n\nNoteLinear Regression Loss Function\n\n\n\n\n\nFor linear regression, we measure prediction errors using Mean Squared Error (MSE) or the Least Squares approach:\n\\[J(\\theta) = \\frac{1}{n}\\sum_{i=1}^n (y^{(i)} - f_\\theta(x^{(i)}))^2\\]\nOften a factor \\(\\frac{1}{2n}\\) is used to make the derivative computation more elegant:\n\\[J(\\theta) = \\frac{1}{2n}\\sum_{i=1}^n (y^{(i)} - f_\\theta(x^{(i)}))^2\\]\nIntuition:\n\n\\((y^{(i)} - f_\\theta(x^{(i)}))\\) is the residual (error) for data point \\(i\\)\nSquaring penalizes large errors more than small ones\nWe average over all \\(n\\) training points\n\nOptimization goal: Find parameters \\(\\theta^* = [\\theta_0^*, \\theta_1^*]\\) that minimize MSE:\n\\[\\theta^* = \\mathsf{argmin}_{\\theta} J(\\theta)\\]\n\n\nCode\nfrom scipy.stats import norm\n\n\ndef calculate_x_y_coordinates_of_normal(x, y, std):\n    \"\"\"Calculate the x and y coordinates of a vertically drawn normal distr\n    at location x and y\n    \"\"\"\n    width_of_distr = 2.0\n    rv_norm = norm(loc=0, scale=std)\n    y_values_norm = np.arange(0 + 2 * std, 0 - 2 * std, -0.1)\n    x_values_norm = rv_norm.pdf(y_values_norm)\n    x_values_norm = (\n        np.abs(x_values_norm * width_of_distr)\n        - np.min(np.abs(x_values_norm) * width_of_distr)\n        + x\n    )\n    y_values_norm += y\n    return x_values_norm, y_values_norm\n\n\n# Use the same dataset from Models section\nstd = np.std(y_noise - y_pred)\n\nfig, ax = plt.subplots(figsize=(8, 5))\nform = \"$p(y|x) = \\\\mathcal{N}(wx, \\\\sigma^2) = \\\\mathcal{N}(\\\\hat{y}, \\\\sigma^2)$\"\ntitle = \"Lineare Regression 1-D\\n\" + form\n_ = sns.scatterplot(x=X.ravel(), y=y_noise.ravel(), ax=ax).set(\n    title=title, xlabel=\"x\", ylabel=\"y\"\n)\n_ = sns.lineplot(x=x_grid, y=y_grid, color=\"red\")\n\nfor x_loc in np.arange(1, 9, 2.0):\n    y_loc = lr.predict(np.array([x_loc]).reshape(-1, 1))\n    x_values_norm, y_values_norm = calculate_x_y_coordinates_of_normal(\n        x=x_loc, y=y_loc.ravel(), std=std\n    )\n    _ = ax.plot(x_values_norm, y_values_norm, color=\"green\", linewidth=1.5)\n    _ = ax.vlines(\n        x=x_loc,\n        ymin=np.min(y_values_norm),\n        ymax=np.max(y_values_norm),\n        colors=\"green\",\n        ls=\"--\",\n        lw=1.5,\n    )\nplt.show()\n\n# Compute and display the MSE\nfrom sklearn.metrics import mean_squared_error\n\nmse = mean_squared_error(y_noise, y_pred)\nprint(f\"Training MSE: {mse:.3f}\")\nprint(f\"Standard deviation of residuals: {std:.3f}\")\nprint(f\"The optimization found: θ₀*={lr.intercept_[0]:.3f}, θ₁*={lr.coef_[0][0]:.3f}\")\n\n\n\n\n\nProbabilistic view of linear regression. The red line shows the expected value E[y|x], and green curves show the modeled normal distributions p(y|x) at different x locations.\n\n\n\n\nTraining MSE: 0.611\nStandard deviation of residuals: 0.782\nThe optimization found: θ₀*=-0.215, θ₁*=1.031\n\n\nGeometric interpretation: Among all possible lines, we found the one with the smallest average squared distance to the data points.\n\n\n\nUsually, preprocessing of variables precedes the learning of the coefficients. Forms of preprocessing include standardizing, normalizing, feature encoding, dimensionality reduction, and more. This preprocessing also affects the optimization procedure and can be considered hyperparameters.",
    "crumbs": [
      "Background & Preparation",
      "Machine Learning Basics"
    ]
  },
  {
    "objectID": "pages/background/machine_learning.html#model-selection",
    "href": "pages/background/machine_learning.html#model-selection",
    "title": "Machine Learning Basics",
    "section": "Model Selection",
    "text": "Model Selection\nModel selection is one of the most important and complex components of the machine learning process. This step involves comparing multiple models and selecting the “best” model for the task to be modeled. Which model is the “best” must be defined based on a metric that measures the model’s performance.\nEvaluation Metrics are crucial for quantifying model performance and vary depending on the problem type. For regression tasks, common metrics include:\n\nMean Squared Error (MSE): \\(\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{y}_i)^2\\), which penalizes large errors heavily\nMean Absolute Error (MAE): \\(\\text{MAE} = \\frac{1}{n}\\sum_{i=1}^n |y_i - \\hat{y}_i|\\), which treats all errors equally\n\nFor classification tasks, key metrics include:\n\nAccuracy: How often is the model correct (fraction of correct predictions).\nPrecision: If it predicts a specific class, how often is it correct (true positives / predicted positives).\nRecall: How many of the target class does the model identify correctly (true positives / actual positives).\nF1-Score: Precision can be traded against Recall, to balance both we can report F1 (harmonic mean of precision and recall).\n\nThe choice of metric depends on the specific application—for example, in medical diagnosis, recall might be more important than precision to avoid missing positive cases. Different ML-frameworks will implement these and many other evaluation metrics.\nIf we calculate the value of the metric on the training dataset, our model is usually too optimistic about its general performance. This is because the data points in the training dataset were directly used to optimize the cost function, and the model coefficients are thus optimally adjusted to them. New data points, for which predictions are to be made, could not have been used for optimization. Therefore, a dataset is usually divided into a training set and a test set. The model is trained with the training set and its performance is measured on the test set. When comparing many models, it is advisable to compare them on a separate validation set (see Figure 3) and evaluate only the best model on the test set. This makes the estimate on the test set more accurate.\n\n\n\n\n\n\nFigure 3: Train-Test Split to select and evaluate models.",
    "crumbs": [
      "Background & Preparation",
      "Machine Learning Basics"
    ]
  },
  {
    "objectID": "pages/background/machine_learning.html#references",
    "href": "pages/background/machine_learning.html#references",
    "title": "Machine Learning Basics",
    "section": "References",
    "text": "References\n\n\nRaschka, Sebastian, and Vahid Mirjalili. 2020. Python Machine Learning: Machine Learning and Deep Learning with Python, Scikit-Learn, and TensorFlow. Second edition, fourth release,[fully revised and updated]. Expert Insight. Birmingham Mumbai: Packt Publishing.",
    "crumbs": [
      "Background & Preparation",
      "Machine Learning Basics"
    ]
  },
  {
    "objectID": "pages/misc/about.html",
    "href": "pages/misc/about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "pages/misc/exercises.html",
    "href": "pages/misc/exercises.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\nExercises\nExercises can be found here: Link",
    "crumbs": [
      "Exercises"
    ]
  },
  {
    "objectID": "pages/misc/literature.html",
    "href": "pages/misc/literature.html",
    "title": "Books",
    "section": "",
    "text": "Stevens, Eli and Antiga, Luca and Viehmann, Thomas, Deep learning with PyTorch, Manning Publications Co, Stevens, Antiga, and Viehmann (2020)\n\nKann als PDF gratis heruntergeladen werden\nEinführung in PyTorch von Grund auf mit Anwendungsbeispielen",
    "crumbs": [
      "Resources",
      "Books"
    ]
  },
  {
    "objectID": "pages/misc/literature.html#pytorch",
    "href": "pages/misc/literature.html#pytorch",
    "title": "Books",
    "section": "",
    "text": "Stevens, Eli and Antiga, Luca and Viehmann, Thomas, Deep learning with PyTorch, Manning Publications Co, Stevens, Antiga, and Viehmann (2020)\n\nKann als PDF gratis heruntergeladen werden\nEinführung in PyTorch von Grund auf mit Anwendungsbeispielen",
    "crumbs": [
      "Resources",
      "Books"
    ]
  },
  {
    "objectID": "pages/misc/literature.html#deep-learning",
    "href": "pages/misc/literature.html#deep-learning",
    "title": "Books",
    "section": "Deep Learning",
    "text": "Deep Learning\nSimon J.D. Prince, Understanding Deep Learning, MIT Press, Prince (2023)\n\nBrandaktuelles Buch über Deep Learning\nUmfassende Einführung ins Thema mit sehr guten Illustrationen\nOnline verfügbar: Link\n\nGoodfellow, Ian and Bengio, Yoshua and Courville, Aaron, Deep Learning, MIT Press, Goodfellow, Bengio, and Courville (2016)\n\nSehr gute und umfassende Einführung in Deep Learning\nEtwas älter aber immer noch in weiten Teilen aktuell\nOnline verfügbar: Link\n\nChollet, François, Deep Learning with Python, Second Edition, Manning Publications, Chollet (2021)\n\nchapters 8-9 are about computer vision\nfree access with FHNW-Emailadresse in O’Reilly online Mediathek\n\nStevens et al, Deep Learning with PyTorch, Manning Publications, Stevens, Antiga, and Viehmann (2020)",
    "crumbs": [
      "Resources",
      "Books"
    ]
  },
  {
    "objectID": "pages/misc/literature.html#machine-learning",
    "href": "pages/misc/literature.html#machine-learning",
    "title": "Books",
    "section": "Machine Learning",
    "text": "Machine Learning\nGéron A, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition, O’Reilly 2019\n\nJupyter Notebooks sind öffentlich verfügbar: Link\nEinsteigerfreundliche Einführung in Machine Learning mit Scikit-Learn und TensorFlow\n\nRaschka S, Python Machine Learning, 3rd Edition, PACKT 2019\n\nEinsteigerfreundliche Einführung in Machine Learning mit Scikit-Learn und TensorFlow\n\nKevin P. Murphy, Probabilistic Machine Learning: An Introduction, MIT Press 2022\n\nVorabversion gratis verfügbar: Link\nUmfassende Einführung in Machine Learning mit ausführlichen theoretischen Hintergründen\n\nChollet F, Deep Learning with Python, 2nd Edition, MEAP 2020\n\nEin Klassiker für eine Einführung in Deep Learning (und Keras)\n\nHastie T et al., Elements of Statistical Learning, Springer 2009.\n\nKann als pdf gratis runtergeladen werden: Link\nEnthält Machine Learning Grundlagen und viele Methoden (wenig über Neuronale Netzwerke)\n\nVanderPlas J, Python Data Science Handbook, O’Reilly 2017.\n\nWurde mit Jupyter Notebooks geschrieben.\nDer gesamte Inhalt finden sie auf einer website: Link\nDas Repository kann von github runtergelanden werden: Link",
    "crumbs": [
      "Resources",
      "Books"
    ]
  },
  {
    "objectID": "pages/misc/quiz.html",
    "href": "pages/misc/quiz.html",
    "title": "Quiz",
    "section": "",
    "text": "The following questions could be exam questions."
  },
  {
    "objectID": "pages/misc/quiz.html#convolutions",
    "href": "pages/misc/quiz.html#convolutions",
    "title": "Quiz",
    "section": "Convolutions",
    "text": "Convolutions\n\nA convolutional layer has 64 input activations (\\(C_{in} = 64\\) and \\(H=16\\), \\(W=16\\)). You want to reduce its spatial dimensionality by half, while doubling the number of channels. How do you parameterize your convolutional layer? Provide an example.\nIn the example above: How many weights do you need to learn?\nYou have very large images (\\(8000 \\times 8000\\) pixels). Your model always crashes with out-of-memory-errors. What options do you have when parameterizing your convolutions?"
  },
  {
    "objectID": "pages/misc/quiz.html#cnns",
    "href": "pages/misc/quiz.html#cnns",
    "title": "Quiz",
    "section": "CNNs",
    "text": "CNNs\n\nCan CNNs be used to count objects? Take a look at the following figure. You want to count in how many quadrants an objects occurs. Justify your answer.\n\n\n\n\nCan CNNs count objects\n\n\n\nCan CNNs be used to model inputs, e.g. satellite data that are not RGB images, i.e. have more than 3 input channels? Justify your answer.\nYou want to model images which are not square. They have a spatial resolution of 800x400. What is different within a CNN as opposed to if they were square?"
  },
  {
    "objectID": "pages/misc/quiz.html#image-classification",
    "href": "pages/misc/quiz.html#image-classification",
    "title": "Quiz",
    "section": "Image Classification",
    "text": "Image Classification\n\nYou trained a model to identify synthetic (fake) images. The model is quite good but not perfect. When deploying the model you have the option to send some images for manual verificaiton by an expert. Which do you choose? Justify your answer."
  },
  {
    "objectID": "pages/misc/quiz.html#foundation-models",
    "href": "pages/misc/quiz.html#foundation-models",
    "title": "Quiz",
    "section": "Foundation Models",
    "text": "Foundation Models\n\nYou applied CLIP on a dataset to identify synthetic / fake images and used the following prompts:\n\n\n“A synthetic image”.\n“A real image”.\n\nWhen you compare to the ground truth labels that you have collected you see that the model does not perform well. What options do you have to improve the model?"
  }
]