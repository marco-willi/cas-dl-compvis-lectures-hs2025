
---
title: "Introduction"
params:
   images_path: "/assets/images/intro/"
---


# Applications


## Species Identification

::: {#fig-intro-kora-lynx}

![Source: @breitenmoser-wursten_projekt_2024]({{< meta params.images_path >}}kora_lynx.png)

:::

## Synthetic Image Detection

::: {#fig-intro-synthetic-images layout-ncol=2}

![]({{< meta params.images_path >}}application_synthetic_images_grta.png)


![]({{< meta params.images_path >}}sid_trump.jpg)

<!--
![[Source](https://x.com/cryptomattk/status/1687908457880367104)]({{< meta params.images_path >}}sid_pope.jpg) -->

Examples of synthetic images: left from @mathys_synthetic_2024, right from [X](https://x.com/TheInfiniteDude/status/1637211568692932608).
:::

## Communication Safety: Apple's on Device AI

::: {#fig-intro-apple-safety}
![]({{< meta params.images_path >}}apple_nude_safety.png){width=600}

Apple's on-device safety features detect sensitive content while maintaining user privacy. [Source](https://www.apple.com/child-safety/)
:::



## Image Search and Understanding

::: {layout-ncol=2}

::: {.column width="45%"}
![Identification & Search]({{< meta params.images_path >}}google_lens_classification.png
)
:::

::: {.column width="45%"}
![Translation]({{< meta params.images_path >}}google_lens_ocr.png)
:::

[Google Lens](https://search.google/ways-to-search/lens/)

::::


## Self-Driving


{{< video https://storage.googleapis.com/waymo-uploads/files/site-animations/waymo-driver/cameras.webm width=1600 >}}

[Example from Waymo](https://waymo.com/waymo-driver/).



## Biometric ID

{{< video https://www.youtube.com/embed/z-t1h0Y8vuM?si=qnEOYDmqyv8zGvMV start="50" width="80%" height="80%" >}}

[Example from Apple Face ID](https://support.apple.com/en-us/102381)


## Precision Agriculture

<!-- {{< video https://www.youtube-nocookie.com/embed/wfObVKKKJkE width="80%" height="80%" >}} -->


::: {#fig-intro-minneapple width=400}

![Example from @hani_minneapple_2020]({{< meta params.images_path >}}minneapple.png)

:::


## Medical Segmentation


::: {#fig-intro-sam width=400}

![Example from @ma_segment_2024.]({{< meta params.images_path >}}medsam.png)

:::

## Photo Enhancement

{{< video https://storage.googleapis.com/gweb-mobius-cdn/photos/uploads/6e54ed750f84538fd052b31818127f1e4df5711c.compressed.mp4 width=1600 >}}

[Example from Google Magic Editor](https://www.google.com/intl/en/photos/editing/)


::: {.fragment}

What computer vision tasks do you think the model must perform to enable this editing capability?

:::


<!-- ## Photograph Deblurring


![Example from [Link](https://store.google.com/intl/en/ideas/pixel-camera-features/). Original (left) and with deep learning enhanced method (right)]({{< meta params.images_path >}}foto_beispiel1.png){width=400}

## Photograph Enhancement

![Example from [Link](https://store.google.com/intl/en/ideas/pixel-camera-features/). Original (left) and the manipulated version (right).]({{< meta params.images_path >}}foto_beispiel2.png){width=400}

## Photograph Manipulation

![Example from [Link](https://store.google.com/intl/en/ideas/pixel-camera-features/). Original (left) and the manipulated version (right).]({{< meta params.images_path >}}foto_beispiel3.png){width=400} -->




## AI Chips

![From [Link](https://store.google.com/intl/en/ideas/pixel-camera-features/).]({{< meta params.images_path >}}tensor_phone.png){width=300}


# Computer Vision Tasks


## Image Classification

![Multi-Class Image Classification Beispiel (aus @krizhevsky_imagenet_2012).]({{< meta params.images_path >}}image_classification_example.png){width=600}


## Object Detection


![]({{< meta params.images_path >}}yolo_object_detection_example.png){width=600}

Object detection involves locating and recognizing multiple objects in an image (from @Redmon2016a).

## Segmentation


![]({{< meta params.images_path >}}mask_rcnn_object_segmentation_example.png){width=600}

In segmentation, individual pixels are assigned to specific objects (instance segmentation) or classes (semantic segmentation). From @he_mask_2018.

<!-- ## Segmentierung 2

{{< video https://www.youtube-nocookie.com/embed/wfObVKKKJkE start="50" >}} -->

<!-- <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/wfObVKKKJkE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->


<!-- ## Keypoint Detektierung


![Keypoint Detection Beispiel (aus @he_mask_2018).]({{< meta params.images_path >}}mask_rcnn_keypoint_detection_example.png){width=600}
 -->


<!--
::: {#fig-intro-image-gen layout="[[1,1], [1]]"}


![Nvidia dlss: [Link](https://images.nvidia.com/aem-dam/Solutions/geforce/news/control-nvidia-dlss-2-0-update/deliver-us-the-moon-nvidia-dlss-2-0-performance-boost.png)]({{< meta params.images_path >}}dssl.png){width=600}


![Norwegian Bride (est late 1890s) aus DeOldify: [Link](https://github.com/jantic/DeOldify)]({{< meta params.images_path >}}colorization_example.png){width=600,#fig-intro-colorization-example}

![Image Generation Beispiel (aus @image_to_image_isola2018).]({{< meta params.images_path >}}pix2pix_examples.png){width=600,#fig-pix2pix-example}

::: -->

## Image Generation - Manipulation


{{< video https://vcai.mpi-inf.mpg.de/projects/DragGAN/data/DragGAN.mp4 width=1200 >}}

[Source: Link](https://vcai.mpi-inf.mpg.de/projects/DragGAN/), DragGAN by @pan_drag_2023


## Image Generation - Translation


![]({{< meta params.images_path >}}pix2pix_examples.png){width=600,#fig-pix2pix-example}

Translation examples from @image_to_image_isola2018.


## Image Generation - Super Resolution

![Nvidia dlss: [Link](https://images.nvidia.com/aem-dam/Solutions/geforce/news/control-nvidia-dlss-2-0-update/deliver-us-the-moon-nvidia-dlss-2-0-performance-boost.png)]({{< meta params.images_path >}}dssl.png){width=600}


## Image Generation - Colorization

![Norwegian Bride (est late 1890s) from DeOldify: [Link](https://github.com/jantic/DeOldify)]({{< meta params.images_path >}}colorization_example.png){width=600}

## Many tasks


:::: {.columns}

::: {.column width="50%"}
- Image Classification
- Object Detection (and Tracking)
- Image Segmentation
  - Semantic Segmentation
  - Instance Segmentation
- Optical Character Recognition (OCR)
- Pose Estimation
- Facial Recognition
- Action Recognition

:::

::: {.column width="50%"}
- Image Generation
  - Style Transfer
  - Image Inpainting
  - Super-Resolution
  - Text-to-Image (and more)
- Image Captioning
- 3D Reconstruction
- Image Retrieval
:::


::::

List is not exhaustive!


## What About Videos?

::: {#fig-intro-sora2}

{{< video https://openaiassets.blob.core.windows.net/$web/nf2/blog-final2/20250929_0337_New%20Video_simple_compose_01k6agr8ctey29mze208t29w38%20(1).mp4 width=1200 >}}

:::

[OpenAI Sora 2](https://openai.com/index/sora-2/) - Text-to-video generation

## What About Videos?

::: {#fig-intro-cotracker}

{{< video https://co-tracker.github.io/videos/teaser/rollerblade.mp4 width=1200 >}}

:::

[CoTracker](https://co-tracker.github.io/) - Tracking points across video frames (@karaev_cotracker_2024)


## What About Videos? {.center}


Many of the image-level tasks can be extended to videos.

After all, videos are nothing but a sequence of images.




# Challenges


## Semantic Gap

::: {#fig-cat-number-grid}

![]({{< meta params.images_path >}}semantic_gap_comparison.png){width=600}

Illustration of the semantic gap: computers see numbers, humans see meaning.
:::


## Viewpoint

::: {#fig-intro-challenge-viewpoint}

![]({{< meta params.images_path >}}viewpoint_challenge.png){width=600}

The same cat from different viewpoints looks completely different at the pixel level.
:::

## Deformation

::: {#fig-challenge-deformation}

![]({{< meta params.images_path >}}challenge_deformation.png){width=600}

Cats exhibit significant shape variation due to pose changes. [Source](http://cs231n.stanford.edu/)
:::

## Illumination

::: {#fig-challenge-illumination}

![]({{< meta params.images_path >}}challenge_illumination.png){width=600}

The same scene under different lighting conditions. [Source](http://cs231n.stanford.edu/)
:::


## Background Clutter

::: {#fig-challenge-background}

![]({{< meta params.images_path >}}challenge_background.png){width=600}

Cat camouflaged against a similarly-textured background. [Source](http://cs231n.stanford.edu/)
:::


## Occlusion

::: {#fig-challenge-occlusion}

![]({{< meta params.images_path >}}challenge_occlusion.png){width=600}

Partially occluded cat - only part of the object is visible. [Source](http://cs231n.stanford.edu/)
:::


## Intra-Class Variation

::: {#fig-challenge-intra-class}

![]({{< meta params.images_path >}}challenge_intra_class_variation.jpg){width=600}

High intra-class variation: all are cats but with vastly different appearances. [Source](https://www.maxpixel.net/Cat-Kittens-Free-Float-Kitten-Rush-Cat-Puppy-555822)
:::

<!--
## Context Dependence

::: {#fig-tiger-context}

![]({{< meta params.images_path >}}tiger_context.jpg){width=600}

Is this a tiger? Context clues help determine the answer. [Source](https://www.linkedin.com/posts/ralph-aboujaoude-diaz-40838313_technology-artificialintelligence-computervision-activity-6912446088364875776-h-Iq?utm_source=linkedin_share&utm_medium=member_desktop_web)
::: -->


## Context Dependence - Blurred Objects

::: {#fig-blop-context}

![]({{< meta params.images_path >}}challenges_context_blop.png){width=600}

Source @torralba_using_2010
:::


::: {.fragment}
**Question**: What kind of objects are marked in these images?
:::


# Machine Learning

## Machine Learning Approach

With Machine Learning, we follow a data-driven approach to solve various tasks:

- Collect a dataset of images and their labels.
- Use a machine learning algorithm to train a model (e.g., a classifier).
- Evaluate and apply the model to new data.


::: {.fragment}
```python
def train(images, labels):
    """ Train a Model """
    # Fit Model here
    return model

def predict(test_images, model):
    """ Predict """
    predictions = model(test_images)
    return predictions
```
:::


## Quiz: Image Super Resolution

![]({{< meta params.images_path >}}super_resolution_demo_simple.png){height=400}

How would you train a model for image super resolution?

The task of the model would be to scale low-resolution images to high-resolution images with the best possible quality.



<!-- ## Machine Learning Pipeline

![Machine Learning Pipeline (Source: @raschka_python_2020)]({{< meta params.images_path >}}python_ml.png){width=600} -->

## Machine Learning Pipeline

::: {.fragment}
![]({{< meta params.images_path >}}ml_workflow_part1.jpg){height=400}
:::
::: {.fragment}
![]({{< meta params.images_path >}}ml_workflow_part2.jpg){height=400}
:::

## PyTorch


In this class, we use PyTorch. PyTorch has gained immense popularity in recent years, characterized by high flexibility, a clean API, and many open-source resources.

**Fundamental Concepts:**

- Tensor: N-dimensional array, like [numpy.array](https://numpy.org/doc/stable/reference/generated/numpy.array.html)
- Autograd: Functionality to create *computational graphs* and compute gradients.
- Module: Class to define components of neural networks

Let's check it out! (on images)


# References

::: {style="font-size: 50%;"}

::: {#refs}
:::

:::
