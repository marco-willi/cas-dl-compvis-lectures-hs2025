---
title: "3 - Generative Models "
params:
   images_path: "/assets/images/genai/"
---

::: {.callout-tip title="Learning Objectives"  collapse="true"}

TODO

:::


::: {.callout-tip title="TLDR Recap" collapse="true"}

TODO

:::

## Generative Adversarial Networks



::: {#fig-genai-gan-idea}

![]({{< meta params.images_path >}}gan-architecture.jpg)

GAN idea, from [Link](https://microsoft.github.io/GenStudio/)
:::


::: {#fig-genai-gan-learning}

![]({{< meta params.images_path >}}gan_learning.png)

GAN learning process, from @foster_generative_2023
:::


::: {#fig-genai-gan-conditional}

![]({{< meta params.images_path >}}gan_conditional_generation.png)

GAN conditional generation
:::


::: {#fig-genai-gan-translation layout-ncol=2}

![Model architecture]({{< meta params.images_path >}}gan_image_translation_model.png)

![Translation examples]({{< meta params.images_path >}}gan_image_translation_examples.png)

GAN image translation
:::


::: {.callout-note title="Pros and Cons of GANs"}

**Pros**

- High-Quality Output, Sharp Details
- Fast Generation

**Cons**

- Training instability → mode collapse and vanishing gradients
- Difficult to evaluate, no likelihood

:::


## Variational Autoencoders


::: {#fig-genai-vae-illustration}

![]({{< meta params.images_path >}}vae_illustration.png)

VAE illustration. From [Source](https://lilianweng.github.io/posts/2018-08-12-vae/).
:::

::: {#fig-genai-vae-illustration2}

![]({{< meta params.images_path >}}vae_illustration2.png)

VAE illustration (alternative view). From [Source](https://lilianweng.github.io/posts/2018-08-12-vae/).
:::

::: {#fig-genai-vae-latent-space}

![]({{< meta params.images_path >}}vae_latent_space_face.png)

VAE latent space: faces generated by traversing the latent space, from @prince_understanding_2023.
:::

::: {.callout-note title="Pros and Cons of VAEs"}

**Pros**

- Principled probabilistic foundation
- Latent space structure: can interpolate in latent space and interpret factors
- Stable training
- Can be used for representation learning

**Cons**

- Blurry outputs (more complex variants can reduce this)

:::


## Diffusion Models


::: {#fig-genai-diffusion-overview}

![]({{< meta params.images_path >}}diffusion_overview.png)

Diffusion model overview, from @prince_understanding_2023.
:::

Forward Process gradually adds random Gaussian noise to the input to produce intermediate latent representations z. This is a pre-specified process  (no neural network).
Reverse Process gradually removes noise added by Forward Process. This is parameterized by a neural network.


::: {#fig-genai-diffusion-forward}

![]({{< meta params.images_path >}}diffusion_forward.png)

Diffusion forward process illustration, from @prince_understanding_2023.
:::

Beta describes how the signal is attenuated / noise is added at each step.
This is also referred to as the noise schedule.

Importantly: We can directly calculate / jump to z_t.



::: {#fig-genai-diffusion-denoising}

![]({{< meta params.images_path >}}diffusion_denoising.png)

Diffusion denoising process illustration, from @prince_understanding_2023.
:::


At each timestep a neural network estimates the current noise added.
Important: The neural network is aware of the timestep.


::: {#fig-genai-diffusion-algorithm}

![]({{< meta params.images_path >}}diffusion_algorithm.png)

Diffusion algorithm illustration.
:::

::: {#fig-genai-diffusion-unet}

![]({{< meta params.images_path >}}diffusion_unet.png)

Diffusion model U-Net architecture, from @prince_understanding_2023.
:::

::: {.callout-note title="Pros and Cons of Diffusion Models"}

**Pros**

- High-quality, diverse outputs
- Stable and reliable training

**Cons**

- Slow inference time
- High compute (training + inference) cost

:::


## Pre-Trained Models

::: {.callout-note title="Pros and Cons of Pre-Trained Models"}

**Pros**

- High-quality image generation out-of-the-box
- You can generate images via prompts
- Easy to customize or fine-tune with minimal investment

**Cons**

- Not suitable if your data is from a specific domain not covered by these models
- May not work well for very specific output constraints (e.g. branding)

:::

::: {#fig-genai-stable-diffusion-xl-examples}

![]({{< meta params.images_path >}}pract_stable_diffusion_xl_examples.png)

Stable Diffusion XL: Example generations, [Source](https://huggingface.co/stabilityai/stable-diffusion-3.5-large).
:::


::: {#fig-genai-diffusion-sd-architecture}

![]({{< meta params.images_path >}}diffusion_sd_architecture_genbook.png)

Stable Diffusion architecture, adapted from GenBook.
:::


Conditioning

::: {#fig-genai-diffusion-latent-diff-architecture}

![]({{< meta params.images_path >}}diffusion_latent_diff_architecture.png)

Latent Diffusion architecture, from @rombach_high-resolution_2022.
:::

::: {#fig-genai-lora-architecture}

![]({{< meta params.images_path >}}lora.png)

LoRA (Low-Rank Adaptation) architecture for efficient fine-tuning. From @hu_lora_2021.
:::

### Hardware requirements

Inference (Image Generation)
Minimum GPU 4-6 GB VRAM
Recommended GPU: 8-12 GB VRAM
CPU-only possible but extremely slow
Optimization: a lot of options

Fine-Tuning (LoRA).
Minimum GPU 12-16 GB VRAM
Recommended GPU 24 GB VRAM

### Open-Source Models

Hugging-Face
diffuser library with unified API for Diffusion models
Extensive model hub with thousands of open-source models
Spaces for interactive demos
Docs for fine-tuning and training models
CivitAI
Community hub for sharing (mostly?) stable diffusion based models
Automatic111 WebUI
Feature-rich web interface for stable diffusion models
Supports inpainting, depth-guidance, etc.
Can be run locally

### Closed-Source Models

OpenAI
Inpainting, text-to-image, with Dall-E3 (newest model not yet available via API)
Google Gemini (Imagen)
High-quality text-to-image generation. Very photorealistic.
Replicate
API platform with open- and closed-source models
Pay-per-inference, can host own models
Midjourney
Highly curated artistic images, high aesthetic and stylized images
No API

## Conclusions & Discussions

::: {#fig-genai-deterioration-on-pollution}

![]({{< meta params.images_path >}}deterioration_on_pollution.png)

Example: Deterioration of generated image quality under pollution or domain shift. From @alemohammad_self-consuming_2023.
:::


Zunächst hatte die Polizei … die Aktion habe nicht stattgefunden, das Bild davon sei ein »Fake«.

... Auf Anfrage des SPIEGEL sagte ein Sprecher der Brandenburger Polizei: »Ob die Projektion tatsächlich so ablief, ist Teil dieser Ermittlungen. Derzeit können wir es jedenfalls nicht ausschließen.«


::: {#fig-genai-real-or-not-musk}

![]({{< meta params.images_path >}}real_or_not_musk.png)

"Real or Not?" [Link](https://www.spiegel.de/panorama/elon-musk-staatsschutz-ermittelt-nach-projektion-tesla-werk-in-gruenheide-a-8268048f-050b-4ae7-adf8-bb9cf572cf25?sara_ref=re-so-app-sh)
:::


::: {#fig-genai-ai-bias-wp-front}

![]({{< meta params.images_path >}}ai_bias_wp_front.png)

AI bias: Example from a whitepaper front page. [Link](https://www.washingtonpost.com/technology/interactive/2024/ai-bias-beautiful-women-ugly-images/)
:::



::: {#fig-genai-ai-bias-wp-examples}

![]({{< meta params.images_path >}}ai_bias_wp_examples.png)

AI bias: Additional examples. [Link](https://www.washingtonpost.com/technology/interactive/2024/ai-bias-beautiful-women-ugly-images/)
:::

### Project Ideas

Fine-tune Stable-Diffusion with Dreambooth approach to generate images of yourself.
Inspect degradation of generative models when trained on synthetic data.
Implement Diffusion Model from scratch.
Chain different models into a creative pipeline.

## References

Understanding Deep Learning, Price, https://udlbook.github.io/udlbook/
Variational Autoencoders: https://lilianweng.github.io/posts/2018-08-12-vae/
Generative Deep Learning, 2nd Edition, David Foster



## References

::: {#refs}
:::
