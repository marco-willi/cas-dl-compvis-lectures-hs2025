<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Marco Willi">

<title>Software &amp; Hardware for Deep Learning – CAS Deep Learning - Computer Vision</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../pages/lectures/intro.qmd" rel="next">
<link href="../../pages/background/neural_networks.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-065a5179aebd64318d7ea99d77b64a9e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-159896a7fbbc1299bfd73fe3af9cd852.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-SCHRGR3LNM"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-SCHRGR3LNM', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../pages/background/machine_learning.html">Background &amp; Preparation</a></li><li class="breadcrumb-item"><a href="../../pages/background/frameworks.html">Software &amp; Hardware for Deep Learning</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      <img src="../../assets/cv_logo_small.png" alt="" class="sidebar-logo light-content py-0 d-lg-inline d-none">
      <img src="../../assets/cv_logo_small.png" alt="" class="sidebar-logo dark-content py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main">
    <a href="https://github.com/marco-willi/cas-dl-compvis-lectures-hs2025" title="GitHub organization" class="quarto-navigation-tool px-1" aria-label="GitHub organization"><i class="bi bi-github"></i></a>
    <a href="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-code-square"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Background &amp; Preparation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/background/machine_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Machine Learning Basics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/background/neural_networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/background/frameworks.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Software &amp; Hardware for Deep Learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Lectures</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/misc/literature.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Books</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/misc/links.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Helpful Links &amp; Resources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/misc/notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Mathematical Notation</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#deep-learning-software" id="toc-deep-learning-software" class="nav-link active" data-scroll-target="#deep-learning-software">Deep Learning Software</a>
  <ul class="collapse">
  <li><a href="#computational-graph-autograd" id="toc-computational-graph-autograd" class="nav-link" data-scroll-target="#computational-graph-autograd">Computational Graph &amp; Autograd</a></li>
  </ul></li>
  <li><a href="#pytorch" id="toc-pytorch" class="nav-link" data-scroll-target="#pytorch">PyTorch</a>
  <ul class="collapse">
  <li><a href="#fundamental-concepts" id="toc-fundamental-concepts" class="nav-link" data-scroll-target="#fundamental-concepts">Fundamental Concepts</a></li>
  <li><a href="#tensors" id="toc-tensors" class="nav-link" data-scroll-target="#tensors">Tensors</a></li>
  <li><a href="#autograd" id="toc-autograd" class="nav-link" data-scroll-target="#autograd">Autograd</a></li>
  <li><a href="#torch.nn" id="toc-torch.nn" class="nav-link" data-scroll-target="#torch.nn">torch.nn</a></li>
  <li><a href="#torch.optim" id="toc-torch.optim" class="nav-link" data-scroll-target="#torch.optim">torch.optim</a></li>
  <li><a href="#training-loops" id="toc-training-loops" class="nav-link" data-scroll-target="#training-loops">Training Loops</a></li>
  <li><a href="#pre-trained-models" id="toc-pre-trained-models" class="nav-link" data-scroll-target="#pre-trained-models">Pre-trained models</a></li>
  </ul></li>
  <li><a href="#other-frameworks" id="toc-other-frameworks" class="nav-link" data-scroll-target="#other-frameworks">Other Frameworks</a>
  <ul class="collapse">
  <li><a href="#tensorflow" id="toc-tensorflow" class="nav-link" data-scroll-target="#tensorflow">TensorFlow</a></li>
  <li><a href="#keras" id="toc-keras" class="nav-link" data-scroll-target="#keras">Keras</a></li>
  <li><a href="#jax" id="toc-jax" class="nav-link" data-scroll-target="#jax">Jax</a></li>
  <li><a href="#scikit-learn" id="toc-scikit-learn" class="nav-link" data-scroll-target="#scikit-learn">Scikit-Learn</a></li>
  <li><a href="#onnx" id="toc-onnx" class="nav-link" data-scroll-target="#onnx">ONNX</a></li>
  <li><a href="#monitoring" id="toc-monitoring" class="nav-link" data-scroll-target="#monitoring">Monitoring</a></li>
  </ul></li>
  <li><a href="#hardware" id="toc-hardware" class="nav-link" data-scroll-target="#hardware">Hardware</a>
  <ul class="collapse">
  <li><a href="#tensor-operations" id="toc-tensor-operations" class="nav-link" data-scroll-target="#tensor-operations">Tensor Operations</a></li>
  <li><a href="#graphics-processing-units-gpus" id="toc-graphics-processing-units-gpus" class="nav-link" data-scroll-target="#graphics-processing-units-gpus">Graphics Processing Units (GPUs)</a></li>
  <li><a href="#cuda-cudnn" id="toc-cuda-cudnn" class="nav-link" data-scroll-target="#cuda-cudnn">CUDA &amp; cuDNN</a></li>
  <li><a href="#data-loading" id="toc-data-loading" class="nav-link" data-scroll-target="#data-loading">Data Loading</a></li>
  <li><a href="#gpu-parallelism" id="toc-gpu-parallelism" class="nav-link" data-scroll-target="#gpu-parallelism">GPU Parallelism</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/marco-willi/cas-dl-compvis-lectures-hs2025/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../pages/background/machine_learning.html">Background &amp; Preparation</a></li><li class="breadcrumb-item"><a href="../../pages/background/frameworks.html">Software &amp; Hardware for Deep Learning</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Software &amp; Hardware for Deep Learning</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Marco Willi </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Institute for Data Science I4DS, FHNW
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-tip callout-titled" title="Learning Objectives">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Learning Objectives
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>After this lecture you should be able to:</p>
<ul>
<li>Explain the role of computational graphs and automatic differentiation in deep learning frameworks.</li>
<li>Construct and inspect tensors, modules, and optimization loops in PyTorch.</li>
<li>Distinguish autograd vs manual gradient computation and identify common pitfalls (forgetting zero_grad, device mismatches).</li>
<li>Describe core hardware considerations (GPU parallelism, data loading bottlenecks, CUDA/cuDNN impact).</li>
<li>Load and adapt pre-trained models responsibly for downstream tasks.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="TLDR Recap">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>TLDR Recap
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>PyTorch Fundamentals:</strong></p>
<ul>
<li><strong>Tensors</strong>: Multi-dimensional arrays (like NumPy) optimized for GPU computation</li>
<li><strong>Autograd</strong>: Automatic differentiation via computational graphs</li>
<li><strong>Dynamic Graphs</strong>: Built on-the-fly during forward pass for flexibility</li>
<li><strong>Device Management</strong>: Easy CPU ↔︎ GPU transfer with <code>.to(device)</code></li>
</ul>
<p><strong>Training Loop Structure:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>model.train()  <span class="co"># Training mode</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> dataloader:</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()        <span class="co"># Clear old gradients</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> model(X_batch)      <span class="co"># Forward pass</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(y_pred, y_batch)  <span class="co"># Compute loss</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    loss.backward()              <span class="co"># Backward pass (compute gradients)</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    optimizer.step()             <span class="co"># Update parameters</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Key Components:</strong></p>
<ul>
<li><strong>nn.Module</strong>: Base class for all neural network layers and models</li>
<li><strong>Loss Functions</strong>: MSE, CrossEntropy, etc. (in <code>torch.nn</code>)</li>
<li><strong>Optimizers</strong>: SGD, Adam, etc. (in <code>torch.optim</code>)</li>
<li><strong>DataLoader</strong>: Efficient batching and shuffling of datasets</li>
</ul>
<p><strong>Common Patterns:</strong></p>
<ul>
<li>Use <code>model.eval()</code> and <code>torch.no_grad()</code> for inference/validation</li>
<li>Move data and model to same device: <code>X.to(device)</code>, <code>model.to(device)</code></li>
<li>Save/load models: <code>torch.save(model.state_dict(), path)</code></li>
</ul>
<p><strong>Hardware Considerations:</strong></p>
<ul>
<li>GPUs enable parallel computation essential for deep learning</li>
<li>CUDA/cuDNN optimize neural network operations on NVIDIA GPUs</li>
<li>Data loading can be a bottleneck (GPU starvation) - use multi-threaded data loaders</li>
<li>GPU parallelism: data parallelism (model copies) vs model parallelism (split model)</li>
</ul>
<p><strong>Best Practices:</strong></p>
<ul>
<li>Always call <code>optimizer.zero_grad()</code> before backward pass</li>
<li>Use appropriate loss functions for your task</li>
<li>Monitor training on validation set to detect overfitting</li>
<li>Leverage GPU when available for significant speedup</li>
</ul>
</div>
</div>
</div>
<section id="deep-learning-software" class="level1">
<h1>Deep Learning Software</h1>
<p>There are a variety of Deep Learning frameworks. These frameworks allow for easy configuration, training, and deploying of neural networks. They are often developed via Python API. <a href="#fig-infrastructure-frameworks" class="quarto-xref">Figure&nbsp;1</a> shows some frameworks.</p>
<div id="fig-infrastructure-frameworks" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-infrastructure-frameworks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../assets/images/frameworks/frameworks.png" class="img-fluid figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-infrastructure-frameworks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Frameworks (from <span class="citation" data-cites="li_cs231n_2022">Li (<a href="#ref-li_cs231n_2022" role="doc-biblioref">2022</a>)</span>).
</figcaption>
</figure>
</div>
<p>Key features of such frameworks are:</p>
<ul>
<li>Fast development and testing of neural networks</li>
<li>Automatic differentiation of operations</li>
<li>Efficient execution on diverse hardware</li>
</ul>
<section id="computational-graph-autograd" class="level2">
<h2 class="anchored" data-anchor-id="computational-graph-autograd">Computational Graph &amp; Autograd</h2>
<p>At the core of neural networks is the <em>Computational Graph</em>. It automatically embeds dependent operations in a <em>directed acyclic graph (DAG)</em>. Gradients are tracked as needed, allowing variables to be efficiently updated/trained.</p>
<p>The following shows an example in Numpy where we define computations and manually calculate derivatives. The graph is shown in <a href="#fig-infrastructure-comp-graph2" class="quarto-xref">Figure&nbsp;2</a>.</p>
<p><span class="math display">\[\begin{equation}
    f(\mathbf{A}, \mathbf{B}, \mathbf{C}) =  \sum_{ij} \big((\mathbf{A} \odot \mathbf{B}) + \mathbf{C}\big)_{ij}
\end{equation}\]</span></p>
<div id="fig-infrastructure-comp-graph2" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-infrastructure-comp-graph2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../assets/images/frameworks/comp-graph2.jpg" class="img-fluid figure-img" width="200">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-infrastructure-comp-graph2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Computational Graph.
</figcaption>
</figure>
</div>
<div id="4161ae8c" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>H, W <span class="op">=</span> <span class="dv">2</span>, <span class="dv">3</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.random.random(size<span class="op">=</span>(H, W))</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.random.random(size<span class="op">=</span>(H, W))</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> np.random.random(size<span class="op">=</span>(H, W))</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e.<span class="bu">sum</span>()</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>df_de <span class="op">=</span> <span class="fl">1.0</span>               <span class="co"># d f / d e</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>de_dd <span class="op">=</span> <span class="fl">1.0</span>               <span class="co"># d e / d d   (since e = d + c)</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>de_dc <span class="op">=</span> np.ones_like(c)   <span class="co"># d e / d c   (derivative of addition w.r.t. c)</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>dd_da <span class="op">=</span> b                 <span class="co"># d (a*b) / d a</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>dd_db <span class="op">=</span> a                 <span class="co"># d (a*b) / d b</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>df_da <span class="op">=</span> df_de <span class="op">*</span> de_dd <span class="op">*</span> dd_da          <span class="co"># chain rule</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>df_db <span class="op">=</span> df_de <span class="op">*</span> de_dd <span class="op">*</span> dd_db</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>df_dc <span class="op">=</span> df_de <span class="op">*</span> de_dc                  <span class="co"># equals ones</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"df/da=</span><span class="ch">\n</span><span class="st">"</span>, df_da)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"df/db=</span><span class="ch">\n</span><span class="st">"</span>, df_db)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"df/dc=</span><span class="ch">\n</span><span class="st">"</span>, df_dc)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>df/da=
 [[0.9807642  0.68482974 0.4809319 ]
 [0.39211752 0.34317802 0.72904971]]
df/db=
 [[0.69646919 0.28613933 0.22685145]
 [0.55131477 0.71946897 0.42310646]]
df/dc=
 [[1. 1. 1.]
 [1. 1. 1.]]</code></pre>
</div>
</div>
<p>Here’s the same example in PyTorch. Using <code>x.backward()</code>, gradients with respect to <code>x</code> are computed for variables connected to <code>x</code>.</p>
<div id="a0001064" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>H, W <span class="op">=</span> <span class="dv">2</span>, <span class="dv">3</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.tensor(a, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.tensor(b, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> torch.tensor(c, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e.<span class="bu">sum</span>()</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>f.backward()</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a.grad)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0.9808, 0.6848, 0.4809],
        [0.3921, 0.3432, 0.7290]], dtype=torch.float64)</code></pre>
</div>
</div>
<p>Here are the nodes of the computational graph.</p>
<div id="af468968" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchviz <span class="im">import</span> make_dot</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>make_dot(f, params<span class="op">=</span>{<span class="st">'a'</span>: a, <span class="st">'b'</span>: b, <span class="st">'c'</span>: c, <span class="st">'f'</span>:f , <span class="st">'d'</span>: d, <span class="st">'e'</span>:e })</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>
<figure class="figure">
<p><img src="frameworks_files/figure-html/cell-4-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>To perform the computation on a GPU, a simple instruction is enough:</p>
<div id="0fca5fa7" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss"> device"</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> a.to(device<span class="op">=</span>device)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> b.to(device<span class="op">=</span>device)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> c.to(device<span class="op">=</span>device)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using cpu device</code></pre>
</div>
</div>
</section>
</section>
<section id="pytorch" class="level1">
<h1>PyTorch</h1>
<p>In this class, we use PyTorch. PyTorch has gained enormous popularity in recent years and stands out for its high flexibility, a clean API, and many open-source resources.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Why PyTorch?">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Why PyTorch?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Key Advantages:</strong></p>
<ul>
<li><strong>Pythonic API</strong>: Feels natural to Python developers, easy to debug</li>
<li><strong>Dynamic computation graphs</strong>: Build graphs on-the-fly, great for research</li>
<li><strong>Strong ecosystem</strong>: torchvision (CV), torchaudio (audio), transformers library integration</li>
<li><strong>Industry &amp; research adoption</strong>: Used by Meta, <a href="https://youtu.be/oBklltKXtDE?si=arGXjt3JX6NbpStj&amp;t=116">Tesla</a>, OpenAI, and top ML research labs (<a href="https://pytorch.org/blog/pytorch-the-open-language-of-ai/">Source</a>)</li>
<li><strong>Excellent documentation</strong>: Comprehensive tutorials and active community</li>
</ul>
<p><strong>When to use PyTorch:</strong></p>
<ul>
<li>Research projects requiring flexibility</li>
<li>Computer vision and NLP applications</li>
<li>When you need fine-grained control over training loops</li>
<li>Prototyping new architectures or training procedures</li>
</ul>
</div>
</div>
</div>
<section id="fundamental-concepts" class="level2">
<h2 class="anchored" data-anchor-id="fundamental-concepts">Fundamental Concepts</h2>
<p>PyTorch is built around three core concepts:</p>
<ul>
<li><strong>Tensor</strong>: N-dimensional array, similar to <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html"><code>numpy.array</code></a> but with GPU acceleration</li>
<li><strong>Autograd</strong>: Automatic differentiation to create computational graphs and compute gradients</li>
<li><strong>Module</strong>: Base class (<code>nn.Module</code>) to define components of neural networks with learnable parameters</li>
</ul>
</section>
<section id="tensors" class="level2">
<h2 class="anchored" data-anchor-id="tensors">Tensors</h2>
<p><a href="https://pytorch.org/docs/stable/tensors.html"><code>torch.Tensor</code></a> is the central data structure in PyTorch. Essentially very similar to <code>numpy.array</code>, it can be easily loaded onto GPUs.</p>
<p>Tensors can be created in various ways. For example, from lists:</p>
<div id="5ee668e6" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>],[<span class="dv">3</span>, <span class="dv">4</span>]]</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>x_data <span class="op">=</span> torch.tensor(data)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_data)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1, 2],
        [3, 4]])</code></pre>
</div>
</div>
<p>Or from numpy.ndarray:</p>
<div id="ac8695df" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>np_array <span class="op">=</span> np.array(data)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>x_np <span class="op">=</span> torch.from_numpy(np_array)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_np)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1, 2],
        [3, 4]])</code></pre>
</div>
</div>
<p>Or from other tensors:</p>
<div id="b9923124" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>x_ones <span class="op">=</span> torch.ones_like(x_data) <span class="co"># retains the properties of x_data</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Ones Tensor: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>x_ones<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>x_rand <span class="op">=</span> torch.rand_like(x_data, dtype<span class="op">=</span>torch.<span class="bu">float</span>) <span class="co"># overrides the datatype of x_data</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Random Tensor: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>x_rand<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ones Tensor: 
 tensor([[1, 1],
        [1, 1]]) 

Random Tensor: 
 tensor([[0.8889, 0.2927],
        [0.2620, 0.2286]]) 
</code></pre>
</div>
</div>
<p>Or with randomly generated numbers or constants:</p>
<div id="e8fe7648" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>shape <span class="op">=</span> (<span class="dv">2</span>,<span class="dv">3</span>,)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>rand_tensor <span class="op">=</span> torch.rand(shape)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>ones_tensor <span class="op">=</span> torch.ones(shape)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>zeros_tensor <span class="op">=</span> torch.zeros(shape)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Random Tensor: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>rand_tensor<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Ones Tensor: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>ones_tensor<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Zeros Tensor: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>zeros_tensor<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Random Tensor: 
 tensor([[0.3170, 0.6634, 0.7283],
        [0.6659, 0.3566, 0.9955]]) 

Ones Tensor: 
 tensor([[1., 1., 1.],
        [1., 1., 1.]]) 

Zeros Tensor: 
 tensor([[0., 0., 0.],
        [0., 0., 0.]])</code></pre>
</div>
</div>
<p>Tensor attributes:</p>
<div id="f39ca6b1" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Shape of tensor: </span><span class="sc">{</span>tensor<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Datatype of tensor: </span><span class="sc">{</span>tensor<span class="sc">.</span>dtype<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Device tensor is stored on: </span><span class="sc">{</span>tensor<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape of tensor: torch.Size([3, 4])
Datatype of tensor: torch.float32
Device tensor is stored on: cpu</code></pre>
</div>
</div>
<p>There are over 100 operations that can be performed on a tensor. The full list is available <a href="https://pytorch.org/docs/stable/torch.html">here</a>.</p>
<p>Indexing and Slicing:</p>
<div id="13fcf86a" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.ones(<span class="dv">4</span>, <span class="dv">4</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First row: </span><span class="sc">{</span>tensor[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First column: </span><span class="sc">{</span>tensor[:, <span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Last column: </span><span class="sc">{</span>tensor[:, <span class="op">-</span><span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>tensor[:,<span class="dv">1</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>First row: tensor([1., 1., 1., 1.])
First column: tensor([1., 1., 1., 1.])
Last column: tensor([1., 1., 1., 1.])
tensor([[1., 0., 1., 1.],
        [1., 0., 1., 1.],
        [1., 0., 1., 1.],
        [1., 0., 1., 1.]])</code></pre>
</div>
</div>
<p>Joining tensors:</p>
<div id="ba2040e4" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> torch.cat([tensor, tensor, tensor], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t1)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],
        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],
        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],
        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])</code></pre>
</div>
</div>
<p>Arithmetic operations:</p>
<div id="92dd6086" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>y1 <span class="op">=</span> tensor <span class="op">@</span> tensor.T</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>y2 <span class="op">=</span> tensor.matmul(tensor.T)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>y3 <span class="op">=</span> torch.rand_like(y1)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>torch.matmul(tensor, tensor.T, out<span class="op">=</span>y3)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co"># This computes the element-wise product. z1, z2, z3 will have the same value</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>z1 <span class="op">=</span> tensor <span class="op">*</span> tensor</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>z2 <span class="op">=</span> tensor.mul(tensor)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>z3 <span class="op">=</span> torch.rand_like(tensor)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>torch.mul(tensor, tensor, out<span class="op">=</span>z3)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>tensor([[1., 0., 1., 1.],
        [1., 0., 1., 1.],
        [1., 0., 1., 1.],
        [1., 0., 1., 1.]])</code></pre>
</div>
</div>
</section>
<section id="autograd" class="level2">
<h2 class="anchored" data-anchor-id="autograd">Autograd</h2>
<p>To train neural networks, backpropagation is typically used. This calculates the gradient of the loss function with respect to the model parameters. To compute these gradients, PyTorch provides an <em>auto-diff</em> functionality: <a href="https://pytorch.org/docs/stable/autograd.html"><code>torch.autograd</code></a>. This can automatically compute gradients for a <em>computational graph</em>.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Autograd Key Points">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Autograd Key Points
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Set <code>requires_grad=True</code> on tensors you want to track for gradient computation</li>
<li>Call <code>.backward()</code> on a scalar loss to compute all gradients</li>
<li>Access gradients via <code>.grad</code> attribute of tensors</li>
<li>Use <code>torch.no_grad()</code> context for inference to save memory and speed up computation</li>
</ul>
</div>
</div>
<p>The following is an example using a 1-layer neural network (see <a href="#fig-infrastructure-comp-graph" class="quarto-xref">Figure&nbsp;3</a> ):</p>
<div id="fig-infrastructure-comp-graph" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-infrastructure-comp-graph-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../assets/images/frameworks/comp-graph.jpg" class="img-fluid figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-infrastructure-comp-graph-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Source: <a href="https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html">PyTorch</a>
</figcaption>
</figure>
</div>
<p>Here is the definition of the network in PyTorch:</p>
<div id="87a116b5" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.ones(<span class="dv">5</span>)  <span class="co"># input tensor</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.zeros(<span class="dv">3</span>)  <span class="co"># expected output</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.randn(<span class="dv">5</span>, <span class="dv">3</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randn(<span class="dv">3</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.matmul(x, w)<span class="op">+</span>b</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> torch.nn.functional.binary_cross_entropy_with_logits(z, y)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>We can now use Autograd to compute the gradient:</p>
<div id="7a2aa4e7" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(w.grad)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(b.grad)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0.2004, 0.2698, 0.0898],
        [0.2004, 0.2698, 0.0898],
        [0.2004, 0.2698, 0.0898],
        [0.2004, 0.2698, 0.0898],
        [0.2004, 0.2698, 0.0898]])
tensor([0.2004, 0.2698, 0.0898])</code></pre>
</div>
</div>
</section>
<section id="torch.nn" class="level2">
<h2 class="anchored" data-anchor-id="torch.nn">torch.nn</h2>
<p>PyTorch provides various building blocks for creating neural networks. These are available in <a href="https://pytorch.org/docs/stable/nn.html"><code>torch.nn</code></a>. Additionally, you can define any compositions of such building blocks that inherit from <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module"><code>torch.nn.Module</code></a>. A neural network is typically a <code>torch.nn.Module</code>. Each module implements the <code>forward()</code> method to define how data is processed.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Building Blocks in torch.nn">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Building Blocks in torch.nn
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Common layers:</strong></p>
<ul>
<li><code>nn.Linear</code>: Fully connected layer</li>
<li><code>nn.Conv2d</code>: 2D convolutional layer</li>
<li><code>nn.MaxPool2d</code>: Max pooling layer</li>
<li><code>nn.Dropout</code>: Regularization via random dropout</li>
<li><code>nn.BatchNorm2d</code>: Batch normalization</li>
</ul>
<p><strong>Common activations:</strong></p>
<ul>
<li><code>nn.ReLU()</code>, <code>nn.LeakyReLU()</code>, <code>nn.GELU()</code></li>
<li><code>nn.Sigmoid()</code>, <code>nn.Softmax()</code></li>
</ul>
<p><strong>Loss functions:</strong></p>
<ul>
<li><code>nn.CrossEntropyLoss()</code>: Classification</li>
<li><code>nn.BCEWithLogitsLoss()</code>: Binary classification</li>
<li><code>nn.MSELoss()</code>: Regression</li>
</ul>
</div>
</div>
<p>Here is an example:</p>
<div id="2a62e534" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NeuralNetwork(nn.Module):</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(NeuralNetwork, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flatten <span class="op">=</span> nn.Flatten()</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear_relu_stack <span class="op">=</span> nn.Sequential(</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">28</span><span class="op">*</span><span class="dv">28</span>, <span class="dv">512</span>),</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">512</span>),</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">10</span>),</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.flatten(x)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.linear_relu_stack(x)</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> logits</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>You can also visualize the model:</p>
<div id="97fb3e9e" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> NeuralNetwork()</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>NeuralNetwork(
  (flatten): Flatten(start_dim=1, end_dim=-1)
  (linear_relu_stack): Sequential(
    (0): Linear(in_features=784, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=10, bias=True)
  )
)</code></pre>
</div>
</div>
<p>To use the model, you can pass input data. This will execute the <code>forward()</code> method, along with background operations.</p>
<div id="22dc35ff" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.rand(<span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> model(X)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>pred_probab <span class="op">=</span> nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>)(logits)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> pred_probab.argmax(<span class="dv">1</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Predicted class: </span><span class="sc">{</span>y_pred<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Predicted class: tensor([5])</code></pre>
</div>
</div>
<p>The executed operations will look like this:</p>
<div id="1bb9ab3e" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchviz <span class="im">import</span> make_dot</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>make_dot(logits)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<div>
<figure class="figure">
<p><img src="frameworks_files/figure-html/cell-19-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="torch.optim" class="level2">
<h2 class="anchored" data-anchor-id="torch.optim">torch.optim</h2>
<p>To optimize the parameters of a model, you need an optimization algorithm. <a href="https://pytorch.org/docs/stable/optim.html"><code>torch.optim</code></a> implements various algorithms, such as <em>Stochastic Gradient Descent</em> or the often used <em>Adam Optimizer</em>.</p>
<!-- TODO: validate rule of thumb -> better use adamw alaways -->
<div class="callout callout-style-default callout-tip callout-titled" title="Common Optimizers">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Common Optimizers
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>SGD</strong>: Basic stochastic gradient descent (with optional momentum)</li>
<li><strong>Adam</strong>: Adaptive learning rates, good default choice</li>
<li><strong>AdamW</strong>: Adam with weight decay, often better for transformers (see <span class="citation" data-cites="loshchilov_decoupled_2019">Loshchilov and Hutter (<a href="#ref-loshchilov_decoupled_2019" role="doc-biblioref">2019</a>)</span>)</li>
<li><strong>RMSprop</strong>: Adaptive learning rates, good for RNNs</li>
<li><strong>Learning rate schedulers</strong>: Adjust learning rate during training (e.g., <code>torch.optim.lr_scheduler</code>)</li>
</ul>
<p><strong>Rule of thumb</strong>: Start with Adam, then try SGD with momentum if you need better generalization.</p>
</div>
</div>
<div id="f373408f" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> optim</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>, momentum<span class="op">=</span><span class="fl">0.9</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>You can then use the optimizer to adjust the parameters, you just need to define a loss function:</p>
<div id="80a7dfe8" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">3</span>):</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">input</span>, target <span class="op">=</span> torch.rand(<span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>), torch.randint(low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, size<span class="op">=</span>(<span class="dv">1</span>, ))</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> model(<span class="bu">input</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output, target)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Common Pitfalls &amp; Solutions">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Common Pitfalls &amp; Solutions
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Pitfall 1: Forgetting zero_grad()</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ❌ Wrong - gradients accumulate</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch <span class="kw">in</span> dataloader:</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> compute_loss(batch)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ✅ Correct</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch <span class="kw">in</span> dataloader:</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()  <span class="co"># Clear previous gradients</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> compute_loss(batch)</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Pitfall 2: Device mismatch</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ❌ Wrong - model on GPU, data on CPU</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.cuda()</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch_x, batch_y <span class="kw">in</span> dataloader:</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    pred <span class="op">=</span> model(batch_x)  <span class="co"># Error!</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ✅ Correct</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.cuda()</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch_x, batch_y <span class="kw">in</span> dataloader:</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    batch_x <span class="op">=</span> batch_x.cuda()</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>    batch_y <span class="op">=</span> batch_y.cuda()</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    pred <span class="op">=</span> model(batch_x)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Pitfall 3: Not using eval() mode for inference</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ❌ Wrong - dropout and batchnorm active during inference</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> model(test_data)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ✅ Correct</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> model(test_data)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>model.train()  <span class="co"># Switch back to training mode</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</section>
<section id="training-loops" class="level2">
<h2 class="anchored" data-anchor-id="training-loops">Training Loops</h2>
<p>Typically, you put together a training loop to train a model. A training loop iterates over batches of data and optimizes the model parameters with each iteration.</p>
<div id="ec0ff5cd" class="cell" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_loop(dataloader, model, loss_fn, optimizer):</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">len</span>(dataloader.dataset)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    model.train()  <span class="co"># &lt;-- important!</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch, (X, y) <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute prediction and loss</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> model(X)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(pred, y)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Backpropagation</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> batch <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>            loss, current <span class="op">=</span> loss.item(), batch <span class="op">*</span> <span class="bu">len</span>(X)</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"loss: </span><span class="sc">{</span>loss<span class="sc">:&gt;7f}</span><span class="ss">  [</span><span class="sc">{</span>current<span class="sc">:&gt;5d}</span><span class="ss">/</span><span class="sc">{</span>size<span class="sc">:&gt;5d}</span><span class="ss">]"</span>)</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_loop(dataloader, model, loss_fn):</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()  <span class="co"># &lt;-- important!</span></span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">len</span>(dataloader.dataset)</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>    num_batches <span class="op">=</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>    test_loss, correct <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():  <span class="co"># disables gradient tracking for efficiency</span></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X, y <span class="kw">in</span> dataloader:</span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> model(X)</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>            test_loss <span class="op">+=</span> loss_fn(pred, y).item()</span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>            correct <span class="op">+=</span> (pred.argmax(<span class="dv">1</span>) <span class="op">==</span> y).<span class="bu">type</span>(torch.<span class="bu">float</span>).<span class="bu">sum</span>().item()</span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>    test_loss <span class="op">/=</span> num_batches</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">/=</span> size</span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"Test Error:</span><span class="ch">\n</span><span class="ss"> Accuracy: </span><span class="sc">{</span>(<span class="dv">100</span> <span class="op">*</span> correct)<span class="sc">:&gt;0.1f}</span><span class="ss">%, Avg loss: </span><span class="sc">{</span>test_loss<span class="sc">:&gt;8f}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>    )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="c29cd4c8" class="cell" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>t<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ch">\n</span><span class="ss">-------------------------------"</span>)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    train_loop(train_dataloader, model, loss_fn, optimizer)</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    test_loop(test_dataloader, model, loss_fn)</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Done!"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>High-level APIs such as <a href="https://lightning.ai/">Lightning</a> and <a href="https://keras.io/">Keras</a> provide many functionalities to simplify managing training loops. It is highly recommended to use such libraries to reduce boiler-plate code. However, it depends on the individual complexity of a project to what degree such libraries are useful.</p>
</div>
</div>
</section>
<section id="pre-trained-models" class="level2">
<h2 class="anchored" data-anchor-id="pre-trained-models">Pre-trained models</h2>
<p>Since training models can be time-consuming and expensive, pre-trained models are often used. They allow models to be adapted to a specific task more quickly and cost-effectively. In many areas, particularly NLP and computer vision, using pre-trained models is standard. PyTorch provides <a href="https://pytorch.org/vision/stable/index.html"><code>torchvision</code></a> for computer vision applications. <code>torchvision</code> provides functionalities useful for modeling image data. Pre-trained models can also be easily integrated, as shown in the following example:</p>
<div id="66a99ae8" class="cell" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models <span class="im">import</span> resnet50, ResNet50_Weights</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> ResNet50_Weights.IMAGENET1K_V2</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> resnet50(weights<span class="op">=</span>weights)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="other-frameworks" class="level1">
<h1>Other Frameworks</h1>
<p>Other important frameworks are listed below (not exhaustive).</p>
<section id="tensorflow" class="level2">
<h2 class="anchored" data-anchor-id="tensorflow">TensorFlow</h2>
<p>For a long time, PyTorch and TensorFlow have been the two dominant deep learning frameworks. TensorFlow, developed by Google, is known for its production-readiness, ecosystem integration (e.g., <a href="https://www.tensorflow.org/tfx">TensorFlow Extended (TFX)</a> for MLOps pipelines, <a href="https://ai.google.dev/edge/litert">LiteRT</a> for mobile, and <a href="https://www.tensorflow.org/js">TensorFlow.js</a> for web), and its scalability across distributed hardware.</p>
<p>In recent years, however, TensorFlow’s low-level API has become less popular in research compared to PyTorch, which offers more flexibility and Pythonic design. Today, most TensorFlow users rely almost exclusively on Keras, its high-level API, to define and train models, while the TensorFlow backend provides performance, device management, and deployment capabilities.</p>
</section>
<section id="keras" class="level2">
<h2 class="anchored" data-anchor-id="keras">Keras</h2>
<p><a href="https://keras.io/">Keras</a> started as an independent high-level deep learning API designed to simplify model creation with a clean and intuitive syntax. Since 2017, it has been tightly integrated into TensorFlow as its official front-end (tf.keras), and in 2023, Keras Core was introduced, a framework-agnostic version that can run on multiple backends such as TensorFlow, JAX, and PyTorch.</p>
<p>Keras focuses on ease of use, modularity, and rapid prototyping, making it an excellent choice for teaching, applied machine learning, and fast experimentation, while still being production-ready through TensorFlow’s ecosystem.</p>
</section>
<section id="jax" class="level2">
<h2 class="anchored" data-anchor-id="jax">Jax</h2>
<p><a href="https://jax.readthedocs.io/en/latest/">Jax</a> has gained significant popularity in recent years. Developed by researchers at Google, it is primarily used in research and foundation-model development. Jax provides a NumPy-like API with automatic differentiation (autodiff) and function transformations such as jit (for compilation) and vmap (for vectorization). It enables high-performance, composable numerical computing, and serves as the foundation for frameworks such as <a href="https://flax.readthedocs.io/en/stable/">Flax (Neural Networks)</a> and <a href="https://dm-haiku.readthedocs.io/en/latest/">Haiku (ML Research)</a>.</p>
</section>
<section id="scikit-learn" class="level2">
<h2 class="anchored" data-anchor-id="scikit-learn">Scikit-Learn</h2>
<p><a href="https://scikit-learn.org/stable/"><code>Scikit-Learn</code></a> is THE machine learning framework in Python. However, Scikit-Learn never covered the area of neural networks and lacks auto-diff functionality. Therefore, Scikit-Learn is irrelevant when training neural networks. However, Scikit-Learn functionalities are often used to carry out the machine learning process, such as splitting datasets into train, validation, and test sets. Also, visualizations, such as the confusion matrix or calculating metrics, can be done via Scikit-Learn.</p>
</section>
<section id="onnx" class="level2">
<h2 class="anchored" data-anchor-id="onnx">ONNX</h2>
<p>y§ <a href="https://onnx.ai/">ONNX</a> (Open Neural Network Exchange) is an open format to represent machine learning models. It allows models trained in one framework to be transferred to another. Trained models can also be deployed on various platforms.</p>
</section>
<section id="monitoring" class="level2">
<h2 class="anchored" data-anchor-id="monitoring">Monitoring</h2>
<p>When training models, monitoring the training process, debugging, and logging hyperparameters, metrics, etc., is very important. Various tools enable these functionalities. Well-known examples are <a href="https://www.tensorflow.org/tensorboard"><code>TensorBoard</code></a> and <a href="https://wandb.ai/site"><code>Weights &amp; Biases</code></a>.</p>
</section>
</section>
<section id="hardware" class="level1">
<h1>Hardware</h1>
<section id="tensor-operations" class="level2">
<h2 class="anchored" data-anchor-id="tensor-operations">Tensor Operations</h2>
<p>In neural networks, there are many tensor operations. Tensors are essentially multi-dimensional arrays, such as a scalar <span class="math inline">\(x\)</span>, a vector <span class="math inline">\(\mathbf{x}\)</span>, or a matrix <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p><a href="#fig-infrastructure-matrix-mult" class="quarto-xref">Figure&nbsp;4</a> illustrates a matrix multiplication, a typical representative of a tensor operation. As you can see, the calculations (entries of the matrix <span class="math inline">\(\mathbf{A}\mathbf{C}\)</span>) are independent of each other and can be fully parallelized.</p>
<div id="fig-infrastructure-matrix-mult" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-infrastructure-matrix-mult-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../assets/images/frameworks/matrix_mult.png" class="img-fluid figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-infrastructure-matrix-mult-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Matrix Multiplication (from <span class="citation" data-cites="li_cs231n_2022">Li (<a href="#ref-li_cs231n_2022" role="doc-biblioref">2022</a>)</span>).
</figcaption>
</figure>
</div>
</section>
<section id="graphics-processing-units-gpus" class="level2">
<h2 class="anchored" data-anchor-id="graphics-processing-units-gpus">Graphics Processing Units (GPUs)</h2>
<p>GPUs have made deep learning possible in the first place. With their parallel structure, they can efficiently compute parallelizable tasks such as tensor operations.</p>
<p>CPUs have far fewer cores than GPUs, but they are faster and can handle more complex tasks. CPUs are therefore ideal for sequential tasks. GPUs have many more cores, which are less complex and slower. Therefore, GPUs are excellent for parallel tasks. <a href="#fig-infrastructure-cpu-vs-gpu" class="quarto-xref">Figure&nbsp;5</a> illustrates the differences.</p>
<div id="fig-infrastructure-cpu-vs-gpu" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-infrastructure-cpu-vs-gpu-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../assets/images/frameworks/cpu_vs_gpu.png" class="img-fluid figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-infrastructure-cpu-vs-gpu-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: CPU vs GPU example (from <span class="citation" data-cites="li_cs231n_2022">Li (<a href="#ref-li_cs231n_2022" role="doc-biblioref">2022</a>)</span>).
</figcaption>
</figure>
</div>
</section>
<section id="cuda-cudnn" class="level2">
<h2 class="anchored" data-anchor-id="cuda-cudnn">CUDA &amp; cuDNN</h2>
<p><a href="https://developer.nvidia.com/cuda-toolkit">CUDA</a> is an API by Nvidia to perform computations on the GPU. It allows parallelizable tasks to be implemented efficiently. <a href="https://developer.nvidia.com/cudnn">cuDNN</a> is a library that efficiently executes certain operations, such as convolutions, in neural networks on the GPU. cuDNN is based on CUDA and significantly accelerates the training of neural networks. <a href="#fig-infrastructure-speed-gpu-cpu" class="quarto-xref">Figure&nbsp;6</a> illustrates speed differences when training various neural networks with CPU, GPU, and optimized cuDNN.</p>
<div id="fig-infrastructure-speed-gpu-cpu" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-infrastructure-speed-gpu-cpu-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../assets/images/frameworks/speed_gpu_cpu.png" class="img-fluid figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-infrastructure-speed-gpu-cpu-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Speed comparison (from <span class="citation" data-cites="li_cs231n_2022">Li (<a href="#ref-li_cs231n_2022" role="doc-biblioref">2022</a>)</span>, data from <a href="https://github.com/jcjohnson/cnn-benchmarks">Link</a>)
</figcaption>
</figure>
</div>
</section>
<section id="data-loading" class="level2">
<h2 class="anchored" data-anchor-id="data-loading">Data Loading</h2>
<p>A crucial bottleneck in practice is the transfer of data (such as images) from the disk to the GPU. If this transfer is not fast enough, it is referred to as <em>GPU starvation</em>. There are several approaches to solve this problem:</p>
<ul>
<li>Read the data into RAM (not feasible for larger datasets)</li>
<li>Use fast disks, such as SSDs</li>
<li>Utilize multiple CPU threads to read data in parallel and keep it in RAM (<em>pre-fetching</em>)</li>
</ul>
<p><a href="#fig-infrastructure-computer" class="quarto-xref">Figure&nbsp;7</a> shows the various components.</p>
<div id="fig-infrastructure-computer" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-infrastructure-computer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../assets/images/frameworks/computer.jpg" class="img-fluid figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-infrastructure-computer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: Source: <span class="citation" data-cites="li_cs231n_2022">Li (<a href="#ref-li_cs231n_2022" role="doc-biblioref">2022</a>)</span>
</figcaption>
</figure>
</div>
<p>Deep learning frameworks like PyTorch implement special classes that allow data to be prepared in multiple threads. Sometimes a certain number of CPU cores is needed to supply a GPU with enough data. <a href="#fig-infrastructure-gpu-starvation" class="quarto-xref">Figure&nbsp;8</a> shows a starved GPU: You can clearly see that the utilization repeatedly drops to 0 because the GPU has to wait for data.</p>
<div id="fig-infrastructure-gpu-starvation" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-infrastructure-gpu-starvation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../assets/images/frameworks/gpu_starvation.png" class="img-fluid figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-infrastructure-gpu-starvation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: The Y-axis shows the GPU utilization in percentage, while the X-axis represents time. <a href="https://stackoverflow.com/questions/44598246/tensorflow-data-starved-gpu">Source</a>
</figcaption>
</figure>
</div>
</section>
<section id="gpu-parallelism" class="level2">
<h2 class="anchored" data-anchor-id="gpu-parallelism">GPU Parallelism</h2>
<p>Models can also be trained on multiple GPUs. There are two main paradigms: <em>data parallelism</em> and <em>model parallelism</em> (see <a href="#fig-infrastructure-parallelism" class="quarto-xref">Figure&nbsp;9</a> ). With <em>data parallelism</em>, each GPU has a copy of the model, and each GPU is trained on different data batches. With <em>model parallelism</em>, the model is split across multiple GPUs. Models can be trained on a server with multiple GPUs or even over the network (<em>distributed</em>). ML frameworks provide functionalities to handle these.</p>
<div id="fig-infrastructure-parallelism" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-infrastructure-parallelism-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../assets/images/frameworks/parallelism.jpg" class="img-fluid figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-infrastructure-parallelism-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: Data and Model Parallelism (from <span class="citation" data-cites="li_cs231n_2022">Li (<a href="#ref-li_cs231n_2022" role="doc-biblioref">2022</a>)</span>).
</figcaption>
</figure>
</div>
</section>
</section>
<section id="references" class="level1">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-li_cs231n_2022" class="csl-entry" role="listitem">
Li, Fei-Fei. 2022. <span>“<span>CS231n</span> <span>Convolutional</span> <span>Neural</span> <span>Networks</span> for <span>Visual</span> <span>Recognition</span>.”</span> Lecture {Notes}. <a href="https://cs231n.github.io">https://cs231n.github.io</a>.
</div>
<div id="ref-loshchilov_decoupled_2019" class="csl-entry" role="listitem">
Loshchilov, Ilya, and Frank Hutter. 2019. <span>“Decoupled <span>Weight</span> <span>Decay</span> <span>Regularization</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1711.05101">https://doi.org/10.48550/arXiv.1711.05101</a>.
</div>
</div>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/marco-willi\.github\.io\/cas-dl-compvis-lectures-hs2025\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../pages/background/neural_networks.html" class="pagination-link" aria-label="Neural Networks">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Neural Networks</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../pages/lectures/intro.qmd" class="pagination-link" aria-label="">
        <span class="nav-page-text"></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb42" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Software &amp; Hardware for Deep Learning"</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="an">params:</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co">   images_path: "/assets/images/frameworks/"</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="Learning Objectives" collapse="true"}</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>After this lecture you should be able to:</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Explain the role of computational graphs and automatic differentiation in deep learning frameworks.</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Construct and inspect tensors, modules, and optimization loops in PyTorch.</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Distinguish autograd vs manual gradient computation and identify common pitfalls (forgetting zero_grad, device mismatches).</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Describe core hardware considerations (GPU parallelism, data loading bottlenecks, CUDA/cuDNN impact).</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Load and adapt pre-trained models responsibly for downstream tasks.</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="TLDR Recap" collapse="true"}</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>**PyTorch Fundamentals:**</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Tensors**: Multi-dimensional arrays (like NumPy) optimized for GPU computation</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Autograd**: Automatic differentiation via computational graphs</span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Dynamic Graphs**: Built on-the-fly during forward pass for flexibility</span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Device Management**: Easy CPU ↔ GPU transfer with <span class="in">`.to(device)`</span></span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>**Training Loop Structure:**</span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a>model.train()  <span class="co"># Training mode</span></span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> X_batch, y_batch <span class="kw">in</span> dataloader:</span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()        <span class="co"># Clear old gradients</span></span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> model(X_batch)      <span class="co"># Forward pass</span></span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(y_pred, y_batch)  <span class="co"># Compute loss</span></span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>    loss.backward()              <span class="co"># Backward pass (compute gradients)</span></span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a>    optimizer.step()             <span class="co"># Update parameters</span></span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a>**Key Components:**</span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**nn.Module**: Base class for all neural network layers and models</span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Loss Functions**: MSE, CrossEntropy, etc. (in <span class="in">`torch.nn`</span>)</span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Optimizers**: SGD, Adam, etc. (in <span class="in">`torch.optim`</span>)</span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**DataLoader**: Efficient batching and shuffling of datasets</span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-44"><a href="#cb42-44" aria-hidden="true" tabindex="-1"></a>**Common Patterns:**</span>
<span id="cb42-45"><a href="#cb42-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-46"><a href="#cb42-46" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use <span class="in">`model.eval()`</span> and <span class="in">`torch.no_grad()`</span> for inference/validation</span>
<span id="cb42-47"><a href="#cb42-47" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Move data and model to same device: <span class="in">`X.to(device)`</span>, <span class="in">`model.to(device)`</span></span>
<span id="cb42-48"><a href="#cb42-48" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Save/load models: <span class="in">`torch.save(model.state_dict(), path)`</span></span>
<span id="cb42-49"><a href="#cb42-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-50"><a href="#cb42-50" aria-hidden="true" tabindex="-1"></a>**Hardware Considerations:**</span>
<span id="cb42-51"><a href="#cb42-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-52"><a href="#cb42-52" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>GPUs enable parallel computation essential for deep learning</span>
<span id="cb42-53"><a href="#cb42-53" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>CUDA/cuDNN optimize neural network operations on NVIDIA GPUs</span>
<span id="cb42-54"><a href="#cb42-54" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Data loading can be a bottleneck (GPU starvation) - use multi-threaded data loaders</span>
<span id="cb42-55"><a href="#cb42-55" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>GPU parallelism: data parallelism (model copies) vs model parallelism (split model)</span>
<span id="cb42-56"><a href="#cb42-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-57"><a href="#cb42-57" aria-hidden="true" tabindex="-1"></a>**Best Practices:**</span>
<span id="cb42-58"><a href="#cb42-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-59"><a href="#cb42-59" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Always call <span class="in">`optimizer.zero_grad()`</span> before backward pass</span>
<span id="cb42-60"><a href="#cb42-60" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use appropriate loss functions for your task</span>
<span id="cb42-61"><a href="#cb42-61" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Monitor training on validation set to detect overfitting</span>
<span id="cb42-62"><a href="#cb42-62" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Leverage GPU when available for significant speedup</span>
<span id="cb42-63"><a href="#cb42-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-64"><a href="#cb42-64" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-65"><a href="#cb42-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-66"><a href="#cb42-66" aria-hidden="true" tabindex="-1"></a>::: {.content-hidden}</span>
<span id="cb42-67"><a href="#cb42-67" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-68"><a href="#cb42-68" aria-hidden="true" tabindex="-1"></a>{{&lt; include /assets/_macros.tex &gt;}}</span>
<span id="cb42-69"><a href="#cb42-69" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-70"><a href="#cb42-70" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-71"><a href="#cb42-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-72"><a href="#cb42-72" aria-hidden="true" tabindex="-1"></a><span class="fu"># Deep Learning Software</span></span>
<span id="cb42-73"><a href="#cb42-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-74"><a href="#cb42-74" aria-hidden="true" tabindex="-1"></a>There are a variety of Deep Learning frameworks. These frameworks allow for easy configuration, training, and deploying of neural networks. They are often developed via Python API. @fig-infrastructure-frameworks shows some frameworks.</span>
<span id="cb42-75"><a href="#cb42-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-76"><a href="#cb42-76" aria-hidden="true" tabindex="-1"></a>::: {#fig-infrastructure-frameworks}</span>
<span id="cb42-77"><a href="#cb42-77" aria-hidden="true" tabindex="-1"></a><span class="al">![]({{&lt; meta params.images_path &gt;}}frameworks.png)</span>{width=600}</span>
<span id="cb42-78"><a href="#cb42-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-79"><a href="#cb42-79" aria-hidden="true" tabindex="-1"></a>Frameworks (from @li_cs231n_2022).</span>
<span id="cb42-80"><a href="#cb42-80" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-81"><a href="#cb42-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-82"><a href="#cb42-82" aria-hidden="true" tabindex="-1"></a>Key features of such frameworks are:</span>
<span id="cb42-83"><a href="#cb42-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-84"><a href="#cb42-84" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Fast development and testing of neural networks</span>
<span id="cb42-85"><a href="#cb42-85" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Automatic differentiation of operations</span>
<span id="cb42-86"><a href="#cb42-86" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Efficient execution on diverse hardware</span>
<span id="cb42-87"><a href="#cb42-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-88"><a href="#cb42-88" aria-hidden="true" tabindex="-1"></a><span class="fu">## Computational Graph &amp; Autograd</span></span>
<span id="cb42-89"><a href="#cb42-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-90"><a href="#cb42-90" aria-hidden="true" tabindex="-1"></a>At the core of neural networks is the _Computational Graph_. It automatically embeds dependent operations in a _directed acyclic graph (DAG)_. Gradients are tracked as needed, allowing variables to be efficiently updated/trained.</span>
<span id="cb42-91"><a href="#cb42-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-92"><a href="#cb42-92" aria-hidden="true" tabindex="-1"></a>The following shows an example in Numpy where we define computations and manually calculate derivatives. The graph is shown in @fig-infrastructure-comp-graph2.</span>
<span id="cb42-93"><a href="#cb42-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-94"><a href="#cb42-94" aria-hidden="true" tabindex="-1"></a>\begin{equation}</span>
<span id="cb42-95"><a href="#cb42-95" aria-hidden="true" tabindex="-1"></a>    f(\mathbf{A}, \mathbf{B}, \mathbf{C}) =  \sum_{ij} \big((\mathbf{A} \odot \mathbf{B}) + \mathbf{C}\big)_{ij}</span>
<span id="cb42-96"><a href="#cb42-96" aria-hidden="true" tabindex="-1"></a>\end{equation}</span>
<span id="cb42-97"><a href="#cb42-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-98"><a href="#cb42-98" aria-hidden="true" tabindex="-1"></a>::: {#fig-infrastructure-comp-graph2}</span>
<span id="cb42-99"><a href="#cb42-99" aria-hidden="true" tabindex="-1"></a><span class="al">![]({{&lt; meta params.images_path &gt;}}comp-graph2.jpg)</span>{width=200}</span>
<span id="cb42-100"><a href="#cb42-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-101"><a href="#cb42-101" aria-hidden="true" tabindex="-1"></a>Computational Graph.</span>
<span id="cb42-102"><a href="#cb42-102" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-103"><a href="#cb42-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-106"><a href="#cb42-106" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-107"><a href="#cb42-107" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-108"><a href="#cb42-108" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-109"><a href="#cb42-109" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb42-110"><a href="#cb42-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-111"><a href="#cb42-111" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb42-112"><a href="#cb42-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-113"><a href="#cb42-113" aria-hidden="true" tabindex="-1"></a>H, W <span class="op">=</span> <span class="dv">2</span>, <span class="dv">3</span></span>
<span id="cb42-114"><a href="#cb42-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-115"><a href="#cb42-115" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> np.random.random(size<span class="op">=</span>(H, W))</span>
<span id="cb42-116"><a href="#cb42-116" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.random.random(size<span class="op">=</span>(H, W))</span>
<span id="cb42-117"><a href="#cb42-117" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> np.random.random(size<span class="op">=</span>(H, W))</span>
<span id="cb42-118"><a href="#cb42-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-119"><a href="#cb42-119" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb42-120"><a href="#cb42-120" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb42-121"><a href="#cb42-121" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e.<span class="bu">sum</span>()</span>
<span id="cb42-122"><a href="#cb42-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-123"><a href="#cb42-123" aria-hidden="true" tabindex="-1"></a>df_de <span class="op">=</span> <span class="fl">1.0</span>               <span class="co"># d f / d e</span></span>
<span id="cb42-124"><a href="#cb42-124" aria-hidden="true" tabindex="-1"></a>de_dd <span class="op">=</span> <span class="fl">1.0</span>               <span class="co"># d e / d d   (since e = d + c)</span></span>
<span id="cb42-125"><a href="#cb42-125" aria-hidden="true" tabindex="-1"></a>de_dc <span class="op">=</span> np.ones_like(c)   <span class="co"># d e / d c   (derivative of addition w.r.t. c)</span></span>
<span id="cb42-126"><a href="#cb42-126" aria-hidden="true" tabindex="-1"></a>dd_da <span class="op">=</span> b                 <span class="co"># d (a*b) / d a</span></span>
<span id="cb42-127"><a href="#cb42-127" aria-hidden="true" tabindex="-1"></a>dd_db <span class="op">=</span> a                 <span class="co"># d (a*b) / d b</span></span>
<span id="cb42-128"><a href="#cb42-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-129"><a href="#cb42-129" aria-hidden="true" tabindex="-1"></a>df_da <span class="op">=</span> df_de <span class="op">*</span> de_dd <span class="op">*</span> dd_da          <span class="co"># chain rule</span></span>
<span id="cb42-130"><a href="#cb42-130" aria-hidden="true" tabindex="-1"></a>df_db <span class="op">=</span> df_de <span class="op">*</span> de_dd <span class="op">*</span> dd_db</span>
<span id="cb42-131"><a href="#cb42-131" aria-hidden="true" tabindex="-1"></a>df_dc <span class="op">=</span> df_de <span class="op">*</span> de_dc                  <span class="co"># equals ones</span></span>
<span id="cb42-132"><a href="#cb42-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-133"><a href="#cb42-133" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"df/da=</span><span class="ch">\n</span><span class="st">"</span>, df_da)</span>
<span id="cb42-134"><a href="#cb42-134" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"df/db=</span><span class="ch">\n</span><span class="st">"</span>, df_db)</span>
<span id="cb42-135"><a href="#cb42-135" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"df/dc=</span><span class="ch">\n</span><span class="st">"</span>, df_dc)</span>
<span id="cb42-136"><a href="#cb42-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-137"><a href="#cb42-137" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-138"><a href="#cb42-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-139"><a href="#cb42-139" aria-hidden="true" tabindex="-1"></a>Here's the same example in PyTorch. Using <span class="in">`x.backward()`</span>, gradients with respect to <span class="in">`x`</span> are computed for variables connected to <span class="in">`x`</span>.</span>
<span id="cb42-140"><a href="#cb42-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-143"><a href="#cb42-143" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-144"><a href="#cb42-144" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-145"><a href="#cb42-145" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-146"><a href="#cb42-146" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb42-147"><a href="#cb42-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-148"><a href="#cb42-148" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb42-149"><a href="#cb42-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-150"><a href="#cb42-150" aria-hidden="true" tabindex="-1"></a>H, W <span class="op">=</span> <span class="dv">2</span>, <span class="dv">3</span></span>
<span id="cb42-151"><a href="#cb42-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-152"><a href="#cb42-152" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.tensor(a, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb42-153"><a href="#cb42-153" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.tensor(b, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb42-154"><a href="#cb42-154" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> torch.tensor(c, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb42-155"><a href="#cb42-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-156"><a href="#cb42-156" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb42-157"><a href="#cb42-157" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb42-158"><a href="#cb42-158" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e.<span class="bu">sum</span>()</span>
<span id="cb42-159"><a href="#cb42-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-160"><a href="#cb42-160" aria-hidden="true" tabindex="-1"></a>f.backward()</span>
<span id="cb42-161"><a href="#cb42-161" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a.grad)</span>
<span id="cb42-162"><a href="#cb42-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-163"><a href="#cb42-163" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-164"><a href="#cb42-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-165"><a href="#cb42-165" aria-hidden="true" tabindex="-1"></a>Here are the nodes of the computational graph.</span>
<span id="cb42-166"><a href="#cb42-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-167"><a href="#cb42-167" aria-hidden="true" tabindex="-1"></a>::: {.content-hidden unless-format="html"}</span>
<span id="cb42-170"><a href="#cb42-170" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-171"><a href="#cb42-171" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-172"><a href="#cb42-172" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-173"><a href="#cb42-173" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchviz <span class="im">import</span> make_dot</span>
<span id="cb42-174"><a href="#cb42-174" aria-hidden="true" tabindex="-1"></a>make_dot(f, params<span class="op">=</span>{<span class="st">'a'</span>: a, <span class="st">'b'</span>: b, <span class="st">'c'</span>: c, <span class="st">'f'</span>:f , <span class="st">'d'</span>: d, <span class="st">'e'</span>:e })</span>
<span id="cb42-175"><a href="#cb42-175" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-176"><a href="#cb42-176" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-177"><a href="#cb42-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-178"><a href="#cb42-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-179"><a href="#cb42-179" aria-hidden="true" tabindex="-1"></a>To perform the computation on a GPU, a simple instruction is enough:</span>
<span id="cb42-180"><a href="#cb42-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-183"><a href="#cb42-183" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-184"><a href="#cb42-184" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-185"><a href="#cb42-185" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-186"><a href="#cb42-186" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb42-187"><a href="#cb42-187" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss"> device"</span>)</span>
<span id="cb42-188"><a href="#cb42-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-189"><a href="#cb42-189" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> a.to(device<span class="op">=</span>device)</span>
<span id="cb42-190"><a href="#cb42-190" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> b.to(device<span class="op">=</span>device)</span>
<span id="cb42-191"><a href="#cb42-191" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> c.to(device<span class="op">=</span>device)</span>
<span id="cb42-192"><a href="#cb42-192" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-193"><a href="#cb42-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-194"><a href="#cb42-194" aria-hidden="true" tabindex="-1"></a><span class="fu"># PyTorch</span></span>
<span id="cb42-195"><a href="#cb42-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-196"><a href="#cb42-196" aria-hidden="true" tabindex="-1"></a>In this class, we use PyTorch. PyTorch has gained enormous popularity in recent years and stands out for its high flexibility, a clean API, and many open-source resources.</span>
<span id="cb42-197"><a href="#cb42-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-198"><a href="#cb42-198" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Why PyTorch?" collapse="true"}</span>
<span id="cb42-199"><a href="#cb42-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-200"><a href="#cb42-200" aria-hidden="true" tabindex="-1"></a>**Key Advantages:**</span>
<span id="cb42-201"><a href="#cb42-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-202"><a href="#cb42-202" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Pythonic API**: Feels natural to Python developers, easy to debug</span>
<span id="cb42-203"><a href="#cb42-203" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Dynamic computation graphs**: Build graphs on-the-fly, great for research</span>
<span id="cb42-204"><a href="#cb42-204" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Strong ecosystem**: torchvision (CV), torchaudio (audio), transformers library integration</span>
<span id="cb42-205"><a href="#cb42-205" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Industry &amp; research adoption**: Used by Meta, <span class="co">[</span><span class="ot">Tesla</span><span class="co">](https://youtu.be/oBklltKXtDE?si=arGXjt3JX6NbpStj&amp;t=116)</span>, OpenAI, and top ML research labs (<span class="co">[</span><span class="ot">Source</span><span class="co">](https://pytorch.org/blog/pytorch-the-open-language-of-ai/)</span>)</span>
<span id="cb42-206"><a href="#cb42-206" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Excellent documentation**: Comprehensive tutorials and active community</span>
<span id="cb42-207"><a href="#cb42-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-208"><a href="#cb42-208" aria-hidden="true" tabindex="-1"></a>**When to use PyTorch:**</span>
<span id="cb42-209"><a href="#cb42-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-210"><a href="#cb42-210" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Research projects requiring flexibility</span>
<span id="cb42-211"><a href="#cb42-211" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Computer vision and NLP applications</span>
<span id="cb42-212"><a href="#cb42-212" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>When you need fine-grained control over training loops</span>
<span id="cb42-213"><a href="#cb42-213" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Prototyping new architectures or training procedures</span>
<span id="cb42-214"><a href="#cb42-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-215"><a href="#cb42-215" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-216"><a href="#cb42-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-217"><a href="#cb42-217" aria-hidden="true" tabindex="-1"></a><span class="fu">## Fundamental Concepts</span></span>
<span id="cb42-218"><a href="#cb42-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-219"><a href="#cb42-219" aria-hidden="true" tabindex="-1"></a>PyTorch is built around three core concepts:</span>
<span id="cb42-220"><a href="#cb42-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-221"><a href="#cb42-221" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Tensor**: N-dimensional array, similar to <span class="co">[</span><span class="ot">`numpy.array`</span><span class="co">](https://numpy.org/doc/stable/reference/generated/numpy.array.html)</span> but with GPU acceleration</span>
<span id="cb42-222"><a href="#cb42-222" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Autograd**: Automatic differentiation to create computational graphs and compute gradients</span>
<span id="cb42-223"><a href="#cb42-223" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Module**: Base class (<span class="in">`nn.Module`</span>) to define components of neural networks with learnable parameters</span>
<span id="cb42-224"><a href="#cb42-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-225"><a href="#cb42-225" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tensors</span></span>
<span id="cb42-226"><a href="#cb42-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-227"><a href="#cb42-227" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">`torch.Tensor`</span><span class="co">](https://pytorch.org/docs/stable/tensors.html)</span> is the central data structure in PyTorch. Essentially very similar to <span class="in">`numpy.array`</span>, it can be easily loaded onto GPUs.</span>
<span id="cb42-228"><a href="#cb42-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-229"><a href="#cb42-229" aria-hidden="true" tabindex="-1"></a>Tensors can be created in various ways. For example, from lists:</span>
<span id="cb42-230"><a href="#cb42-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-233"><a href="#cb42-233" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-234"><a href="#cb42-234" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-235"><a href="#cb42-235" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-236"><a href="#cb42-236" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>],[<span class="dv">3</span>, <span class="dv">4</span>]]</span>
<span id="cb42-237"><a href="#cb42-237" aria-hidden="true" tabindex="-1"></a>x_data <span class="op">=</span> torch.tensor(data)</span>
<span id="cb42-238"><a href="#cb42-238" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_data)</span>
<span id="cb42-239"><a href="#cb42-239" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-240"><a href="#cb42-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-241"><a href="#cb42-241" aria-hidden="true" tabindex="-1"></a>Or from numpy.ndarray:</span>
<span id="cb42-242"><a href="#cb42-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-245"><a href="#cb42-245" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-246"><a href="#cb42-246" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-247"><a href="#cb42-247" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-248"><a href="#cb42-248" aria-hidden="true" tabindex="-1"></a>np_array <span class="op">=</span> np.array(data)</span>
<span id="cb42-249"><a href="#cb42-249" aria-hidden="true" tabindex="-1"></a>x_np <span class="op">=</span> torch.from_numpy(np_array)</span>
<span id="cb42-250"><a href="#cb42-250" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_np)</span>
<span id="cb42-251"><a href="#cb42-251" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-252"><a href="#cb42-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-253"><a href="#cb42-253" aria-hidden="true" tabindex="-1"></a>Or from other tensors:</span>
<span id="cb42-254"><a href="#cb42-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-257"><a href="#cb42-257" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-258"><a href="#cb42-258" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-259"><a href="#cb42-259" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-260"><a href="#cb42-260" aria-hidden="true" tabindex="-1"></a>x_ones <span class="op">=</span> torch.ones_like(x_data) <span class="co"># retains the properties of x_data</span></span>
<span id="cb42-261"><a href="#cb42-261" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Ones Tensor: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>x_ones<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb42-262"><a href="#cb42-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-263"><a href="#cb42-263" aria-hidden="true" tabindex="-1"></a>x_rand <span class="op">=</span> torch.rand_like(x_data, dtype<span class="op">=</span>torch.<span class="bu">float</span>) <span class="co"># overrides the datatype of x_data</span></span>
<span id="cb42-264"><a href="#cb42-264" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Random Tensor: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>x_rand<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb42-265"><a href="#cb42-265" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-266"><a href="#cb42-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-267"><a href="#cb42-267" aria-hidden="true" tabindex="-1"></a>Or with randomly generated numbers or constants:</span>
<span id="cb42-268"><a href="#cb42-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-271"><a href="#cb42-271" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-272"><a href="#cb42-272" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-273"><a href="#cb42-273" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-274"><a href="#cb42-274" aria-hidden="true" tabindex="-1"></a>shape <span class="op">=</span> (<span class="dv">2</span>,<span class="dv">3</span>,)</span>
<span id="cb42-275"><a href="#cb42-275" aria-hidden="true" tabindex="-1"></a>rand_tensor <span class="op">=</span> torch.rand(shape)</span>
<span id="cb42-276"><a href="#cb42-276" aria-hidden="true" tabindex="-1"></a>ones_tensor <span class="op">=</span> torch.ones(shape)</span>
<span id="cb42-277"><a href="#cb42-277" aria-hidden="true" tabindex="-1"></a>zeros_tensor <span class="op">=</span> torch.zeros(shape)</span>
<span id="cb42-278"><a href="#cb42-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-279"><a href="#cb42-279" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Random Tensor: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>rand_tensor<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb42-280"><a href="#cb42-280" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Ones Tensor: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>ones_tensor<span class="sc">}</span><span class="ss"> </span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb42-281"><a href="#cb42-281" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Zeros Tensor: </span><span class="ch">\n</span><span class="ss"> </span><span class="sc">{</span>zeros_tensor<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-282"><a href="#cb42-282" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-283"><a href="#cb42-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-284"><a href="#cb42-284" aria-hidden="true" tabindex="-1"></a>Tensor attributes:</span>
<span id="cb42-285"><a href="#cb42-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-288"><a href="#cb42-288" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-289"><a href="#cb42-289" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-290"><a href="#cb42-290" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-291"><a href="#cb42-291" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb42-292"><a href="#cb42-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-293"><a href="#cb42-293" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Shape of tensor: </span><span class="sc">{</span>tensor<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-294"><a href="#cb42-294" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Datatype of tensor: </span><span class="sc">{</span>tensor<span class="sc">.</span>dtype<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-295"><a href="#cb42-295" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Device tensor is stored on: </span><span class="sc">{</span>tensor<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-296"><a href="#cb42-296" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-297"><a href="#cb42-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-298"><a href="#cb42-298" aria-hidden="true" tabindex="-1"></a>There are over 100 operations that can be performed on a tensor. The full list is available <span class="co">[</span><span class="ot">here</span><span class="co">](https://pytorch.org/docs/stable/torch.html)</span>.</span>
<span id="cb42-299"><a href="#cb42-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-300"><a href="#cb42-300" aria-hidden="true" tabindex="-1"></a>Indexing and Slicing:</span>
<span id="cb42-301"><a href="#cb42-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-304"><a href="#cb42-304" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-305"><a href="#cb42-305" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-306"><a href="#cb42-306" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-307"><a href="#cb42-307" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.ones(<span class="dv">4</span>, <span class="dv">4</span>)</span>
<span id="cb42-308"><a href="#cb42-308" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First row: </span><span class="sc">{</span>tensor[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-309"><a href="#cb42-309" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First column: </span><span class="sc">{</span>tensor[:, <span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-310"><a href="#cb42-310" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Last column: </span><span class="sc">{</span>tensor[:, <span class="op">-</span><span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-311"><a href="#cb42-311" aria-hidden="true" tabindex="-1"></a>tensor[:,<span class="dv">1</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb42-312"><a href="#cb42-312" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor)</span>
<span id="cb42-313"><a href="#cb42-313" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-314"><a href="#cb42-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-315"><a href="#cb42-315" aria-hidden="true" tabindex="-1"></a>Joining tensors:</span>
<span id="cb42-316"><a href="#cb42-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-319"><a href="#cb42-319" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-320"><a href="#cb42-320" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-321"><a href="#cb42-321" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-322"><a href="#cb42-322" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> torch.cat([tensor, tensor, tensor], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb42-323"><a href="#cb42-323" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t1)</span>
<span id="cb42-324"><a href="#cb42-324" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-325"><a href="#cb42-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-326"><a href="#cb42-326" aria-hidden="true" tabindex="-1"></a>Arithmetic operations:</span>
<span id="cb42-327"><a href="#cb42-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-330"><a href="#cb42-330" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-331"><a href="#cb42-331" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-332"><a href="#cb42-332" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-333"><a href="#cb42-333" aria-hidden="true" tabindex="-1"></a><span class="co"># This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value</span></span>
<span id="cb42-334"><a href="#cb42-334" aria-hidden="true" tabindex="-1"></a>y1 <span class="op">=</span> tensor <span class="op">@</span> tensor.T</span>
<span id="cb42-335"><a href="#cb42-335" aria-hidden="true" tabindex="-1"></a>y2 <span class="op">=</span> tensor.matmul(tensor.T)</span>
<span id="cb42-336"><a href="#cb42-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-337"><a href="#cb42-337" aria-hidden="true" tabindex="-1"></a>y3 <span class="op">=</span> torch.rand_like(y1)</span>
<span id="cb42-338"><a href="#cb42-338" aria-hidden="true" tabindex="-1"></a>torch.matmul(tensor, tensor.T, out<span class="op">=</span>y3)</span>
<span id="cb42-339"><a href="#cb42-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-340"><a href="#cb42-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-341"><a href="#cb42-341" aria-hidden="true" tabindex="-1"></a><span class="co"># This computes the element-wise product. z1, z2, z3 will have the same value</span></span>
<span id="cb42-342"><a href="#cb42-342" aria-hidden="true" tabindex="-1"></a>z1 <span class="op">=</span> tensor <span class="op">*</span> tensor</span>
<span id="cb42-343"><a href="#cb42-343" aria-hidden="true" tabindex="-1"></a>z2 <span class="op">=</span> tensor.mul(tensor)</span>
<span id="cb42-344"><a href="#cb42-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-345"><a href="#cb42-345" aria-hidden="true" tabindex="-1"></a>z3 <span class="op">=</span> torch.rand_like(tensor)</span>
<span id="cb42-346"><a href="#cb42-346" aria-hidden="true" tabindex="-1"></a>torch.mul(tensor, tensor, out<span class="op">=</span>z3)</span>
<span id="cb42-347"><a href="#cb42-347" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-348"><a href="#cb42-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-349"><a href="#cb42-349" aria-hidden="true" tabindex="-1"></a><span class="fu">## Autograd</span></span>
<span id="cb42-350"><a href="#cb42-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-351"><a href="#cb42-351" aria-hidden="true" tabindex="-1"></a>To train neural networks, backpropagation is typically used. This calculates the gradient of the loss function with respect to the model parameters. To compute these gradients, PyTorch provides an _auto-diff_ functionality:</span>
<span id="cb42-352"><a href="#cb42-352" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">`torch.autograd`</span><span class="co">](https://pytorch.org/docs/stable/autograd.html)</span>. This can automatically compute gradients for a _computational graph_.</span>
<span id="cb42-353"><a href="#cb42-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-354"><a href="#cb42-354" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="Autograd Key Points"}</span>
<span id="cb42-355"><a href="#cb42-355" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Set <span class="in">`requires_grad=True`</span> on tensors you want to track for gradient computation</span>
<span id="cb42-356"><a href="#cb42-356" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Call <span class="in">`.backward()`</span> on a scalar loss to compute all gradients</span>
<span id="cb42-357"><a href="#cb42-357" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Access gradients via <span class="in">`.grad`</span> attribute of tensors</span>
<span id="cb42-358"><a href="#cb42-358" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use <span class="in">`torch.no_grad()`</span> context for inference to save memory and speed up computation</span>
<span id="cb42-359"><a href="#cb42-359" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-360"><a href="#cb42-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-361"><a href="#cb42-361" aria-hidden="true" tabindex="-1"></a>The following is an example using a 1-layer neural network (see @fig-infrastructure-comp-graph ):</span>
<span id="cb42-362"><a href="#cb42-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-363"><a href="#cb42-363" aria-hidden="true" tabindex="-1"></a>::: {#fig-infrastructure-comp-graph}</span>
<span id="cb42-364"><a href="#cb42-364" aria-hidden="true" tabindex="-1"></a><span class="al">![]({{&lt; meta params.images_path &gt;}}comp-graph.jpg)</span>{width=600}</span>
<span id="cb42-365"><a href="#cb42-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-366"><a href="#cb42-366" aria-hidden="true" tabindex="-1"></a>Source: <span class="co">[</span><span class="ot">PyTorch</span><span class="co">](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html)</span></span>
<span id="cb42-367"><a href="#cb42-367" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-368"><a href="#cb42-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-369"><a href="#cb42-369" aria-hidden="true" tabindex="-1"></a>Here is the definition of the network in PyTorch:</span>
<span id="cb42-370"><a href="#cb42-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-373"><a href="#cb42-373" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-374"><a href="#cb42-374" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-375"><a href="#cb42-375" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-376"><a href="#cb42-376" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb42-377"><a href="#cb42-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-378"><a href="#cb42-378" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.ones(<span class="dv">5</span>)  <span class="co"># input tensor</span></span>
<span id="cb42-379"><a href="#cb42-379" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.zeros(<span class="dv">3</span>)  <span class="co"># expected output</span></span>
<span id="cb42-380"><a href="#cb42-380" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.randn(<span class="dv">5</span>, <span class="dv">3</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb42-381"><a href="#cb42-381" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.randn(<span class="dv">3</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb42-382"><a href="#cb42-382" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.matmul(x, w)<span class="op">+</span>b</span>
<span id="cb42-383"><a href="#cb42-383" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> torch.nn.functional.binary_cross_entropy_with_logits(z, y)</span>
<span id="cb42-384"><a href="#cb42-384" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-385"><a href="#cb42-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-386"><a href="#cb42-386" aria-hidden="true" tabindex="-1"></a>We can now use Autograd to compute the gradient:</span>
<span id="cb42-387"><a href="#cb42-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-390"><a href="#cb42-390" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-391"><a href="#cb42-391" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-392"><a href="#cb42-392" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-393"><a href="#cb42-393" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="cb42-394"><a href="#cb42-394" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(w.grad)</span>
<span id="cb42-395"><a href="#cb42-395" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(b.grad)</span>
<span id="cb42-396"><a href="#cb42-396" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-397"><a href="#cb42-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-398"><a href="#cb42-398" aria-hidden="true" tabindex="-1"></a><span class="fu">## torch.nn</span></span>
<span id="cb42-399"><a href="#cb42-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-400"><a href="#cb42-400" aria-hidden="true" tabindex="-1"></a>PyTorch provides various building blocks for creating neural networks. These are available in <span class="co">[</span><span class="ot">`torch.nn`</span><span class="co">](https://pytorch.org/docs/stable/nn.html)</span>. Additionally, you can define any compositions of such building blocks that inherit from <span class="co">[</span><span class="ot">`torch.nn.Module`</span><span class="co">](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module)</span>. A neural network is typically a <span class="in">`torch.nn.Module`</span>. Each module implements the <span class="in">`forward()`</span> method to define how data is processed.</span>
<span id="cb42-401"><a href="#cb42-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-402"><a href="#cb42-402" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="Building Blocks in torch.nn"}</span>
<span id="cb42-403"><a href="#cb42-403" aria-hidden="true" tabindex="-1"></a>**Common layers:**</span>
<span id="cb42-404"><a href="#cb42-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-405"><a href="#cb42-405" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`nn.Linear`</span>: Fully connected layer</span>
<span id="cb42-406"><a href="#cb42-406" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`nn.Conv2d`</span>: 2D convolutional layer</span>
<span id="cb42-407"><a href="#cb42-407" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`nn.MaxPool2d`</span>: Max pooling layer</span>
<span id="cb42-408"><a href="#cb42-408" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`nn.Dropout`</span>: Regularization via random dropout</span>
<span id="cb42-409"><a href="#cb42-409" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`nn.BatchNorm2d`</span>: Batch normalization</span>
<span id="cb42-410"><a href="#cb42-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-411"><a href="#cb42-411" aria-hidden="true" tabindex="-1"></a>**Common activations:**</span>
<span id="cb42-412"><a href="#cb42-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-413"><a href="#cb42-413" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`nn.ReLU()`</span>, <span class="in">`nn.LeakyReLU()`</span>, <span class="in">`nn.GELU()`</span></span>
<span id="cb42-414"><a href="#cb42-414" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`nn.Sigmoid()`</span>, <span class="in">`nn.Softmax()`</span></span>
<span id="cb42-415"><a href="#cb42-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-416"><a href="#cb42-416" aria-hidden="true" tabindex="-1"></a>**Loss functions:**</span>
<span id="cb42-417"><a href="#cb42-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-418"><a href="#cb42-418" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`nn.CrossEntropyLoss()`</span>: Classification</span>
<span id="cb42-419"><a href="#cb42-419" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`nn.BCEWithLogitsLoss()`</span>: Binary classification</span>
<span id="cb42-420"><a href="#cb42-420" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`nn.MSELoss()`</span>: Regression</span>
<span id="cb42-421"><a href="#cb42-421" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-422"><a href="#cb42-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-423"><a href="#cb42-423" aria-hidden="true" tabindex="-1"></a>Here is an example:</span>
<span id="cb42-424"><a href="#cb42-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-427"><a href="#cb42-427" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-428"><a href="#cb42-428" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-429"><a href="#cb42-429" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-430"><a href="#cb42-430" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb42-431"><a href="#cb42-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-432"><a href="#cb42-432" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NeuralNetwork(nn.Module):</span>
<span id="cb42-433"><a href="#cb42-433" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb42-434"><a href="#cb42-434" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(NeuralNetwork, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb42-435"><a href="#cb42-435" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flatten <span class="op">=</span> nn.Flatten()</span>
<span id="cb42-436"><a href="#cb42-436" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear_relu_stack <span class="op">=</span> nn.Sequential(</span>
<span id="cb42-437"><a href="#cb42-437" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">28</span><span class="op">*</span><span class="dv">28</span>, <span class="dv">512</span>),</span>
<span id="cb42-438"><a href="#cb42-438" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb42-439"><a href="#cb42-439" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">512</span>),</span>
<span id="cb42-440"><a href="#cb42-440" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb42-441"><a href="#cb42-441" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">512</span>, <span class="dv">10</span>),</span>
<span id="cb42-442"><a href="#cb42-442" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb42-443"><a href="#cb42-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-444"><a href="#cb42-444" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb42-445"><a href="#cb42-445" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.flatten(x)</span>
<span id="cb42-446"><a href="#cb42-446" aria-hidden="true" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.linear_relu_stack(x)</span>
<span id="cb42-447"><a href="#cb42-447" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> logits</span>
<span id="cb42-448"><a href="#cb42-448" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-449"><a href="#cb42-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-450"><a href="#cb42-450" aria-hidden="true" tabindex="-1"></a>You can also visualize the model:</span>
<span id="cb42-451"><a href="#cb42-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-454"><a href="#cb42-454" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-455"><a href="#cb42-455" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-456"><a href="#cb42-456" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-457"><a href="#cb42-457" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> NeuralNetwork()</span>
<span id="cb42-458"><a href="#cb42-458" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model)</span>
<span id="cb42-459"><a href="#cb42-459" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-460"><a href="#cb42-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-461"><a href="#cb42-461" aria-hidden="true" tabindex="-1"></a>To use the model, you can pass input data. This will execute the <span class="in">`forward()`</span> method, along with background operations.</span>
<span id="cb42-462"><a href="#cb42-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-465"><a href="#cb42-465" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-466"><a href="#cb42-466" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-467"><a href="#cb42-467" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-468"><a href="#cb42-468" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.rand(<span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb42-469"><a href="#cb42-469" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> model(X)</span>
<span id="cb42-470"><a href="#cb42-470" aria-hidden="true" tabindex="-1"></a>pred_probab <span class="op">=</span> nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>)(logits)</span>
<span id="cb42-471"><a href="#cb42-471" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> pred_probab.argmax(<span class="dv">1</span>)</span>
<span id="cb42-472"><a href="#cb42-472" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Predicted class: </span><span class="sc">{</span>y_pred<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-473"><a href="#cb42-473" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-474"><a href="#cb42-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-475"><a href="#cb42-475" aria-hidden="true" tabindex="-1"></a>The executed operations will look like this:</span>
<span id="cb42-476"><a href="#cb42-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-477"><a href="#cb42-477" aria-hidden="true" tabindex="-1"></a>::: {.content-hidden unless-format="html"}</span>
<span id="cb42-480"><a href="#cb42-480" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-481"><a href="#cb42-481" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-482"><a href="#cb42-482" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-483"><a href="#cb42-483" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchviz <span class="im">import</span> make_dot</span>
<span id="cb42-484"><a href="#cb42-484" aria-hidden="true" tabindex="-1"></a>make_dot(logits)</span>
<span id="cb42-485"><a href="#cb42-485" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-486"><a href="#cb42-486" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-487"><a href="#cb42-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-488"><a href="#cb42-488" aria-hidden="true" tabindex="-1"></a><span class="fu">## torch.optim</span></span>
<span id="cb42-489"><a href="#cb42-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-490"><a href="#cb42-490" aria-hidden="true" tabindex="-1"></a>To optimize the parameters of a model, you need an optimization algorithm. <span class="co">[</span><span class="ot">`torch.optim`</span><span class="co">](https://pytorch.org/docs/stable/optim.html)</span> implements various algorithms, such as _Stochastic Gradient Descent_ or the often used _Adam Optimizer_.</span>
<span id="cb42-491"><a href="#cb42-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-492"><a href="#cb42-492" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- </span><span class="al">TODO</span><span class="co">: validate rule of thumb -&gt; better use adamw alaways --&gt;</span></span>
<span id="cb42-493"><a href="#cb42-493" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="Common Optimizers"}</span>
<span id="cb42-494"><a href="#cb42-494" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**SGD**: Basic stochastic gradient descent (with optional momentum)</span>
<span id="cb42-495"><a href="#cb42-495" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Adam**: Adaptive learning rates, good default choice</span>
<span id="cb42-496"><a href="#cb42-496" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**AdamW**: Adam with weight decay, often better for transformers (see @loshchilov_decoupled_2019)</span>
<span id="cb42-497"><a href="#cb42-497" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**RMSprop**: Adaptive learning rates, good for RNNs</span>
<span id="cb42-498"><a href="#cb42-498" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Learning rate schedulers**: Adjust learning rate during training (e.g., <span class="in">`torch.optim.lr_scheduler`</span>)</span>
<span id="cb42-499"><a href="#cb42-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-500"><a href="#cb42-500" aria-hidden="true" tabindex="-1"></a>**Rule of thumb**: Start with Adam, then try SGD with momentum if you need better generalization.</span>
<span id="cb42-501"><a href="#cb42-501" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-502"><a href="#cb42-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-505"><a href="#cb42-505" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-506"><a href="#cb42-506" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-507"><a href="#cb42-507" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-508"><a href="#cb42-508" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> optim</span>
<span id="cb42-509"><a href="#cb42-509" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>, momentum<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb42-510"><a href="#cb42-510" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-511"><a href="#cb42-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-512"><a href="#cb42-512" aria-hidden="true" tabindex="-1"></a>You can then use the optimizer to adjust the parameters, you just need to define a loss function:</span>
<span id="cb42-513"><a href="#cb42-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-516"><a href="#cb42-516" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-517"><a href="#cb42-517" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: true</span></span>
<span id="cb42-518"><a href="#cb42-518" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-519"><a href="#cb42-519" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb42-520"><a href="#cb42-520" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">3</span>):</span>
<span id="cb42-521"><a href="#cb42-521" aria-hidden="true" tabindex="-1"></a>    <span class="bu">input</span>, target <span class="op">=</span> torch.rand(<span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>), torch.randint(low<span class="op">=</span><span class="dv">0</span>, high<span class="op">=</span><span class="dv">10</span>, size<span class="op">=</span>(<span class="dv">1</span>, ))</span>
<span id="cb42-522"><a href="#cb42-522" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb42-523"><a href="#cb42-523" aria-hidden="true" tabindex="-1"></a>    output <span class="op">=</span> model(<span class="bu">input</span>)</span>
<span id="cb42-524"><a href="#cb42-524" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss_fn(output, target)</span>
<span id="cb42-525"><a href="#cb42-525" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb42-526"><a href="#cb42-526" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb42-527"><a href="#cb42-527" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-528"><a href="#cb42-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-529"><a href="#cb42-529" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="Common Pitfalls &amp; Solutions"}</span>
<span id="cb42-530"><a href="#cb42-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-531"><a href="#cb42-531" aria-hidden="true" tabindex="-1"></a>**Pitfall 1: Forgetting zero_grad()**</span>
<span id="cb42-532"><a href="#cb42-532" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb42-533"><a href="#cb42-533" aria-hidden="true" tabindex="-1"></a><span class="co"># ❌ Wrong - gradients accumulate</span></span>
<span id="cb42-534"><a href="#cb42-534" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch <span class="kw">in</span> dataloader:</span>
<span id="cb42-535"><a href="#cb42-535" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> compute_loss(batch)</span>
<span id="cb42-536"><a href="#cb42-536" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb42-537"><a href="#cb42-537" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb42-538"><a href="#cb42-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-539"><a href="#cb42-539" aria-hidden="true" tabindex="-1"></a><span class="co"># ✅ Correct</span></span>
<span id="cb42-540"><a href="#cb42-540" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch <span class="kw">in</span> dataloader:</span>
<span id="cb42-541"><a href="#cb42-541" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()  <span class="co"># Clear previous gradients</span></span>
<span id="cb42-542"><a href="#cb42-542" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> compute_loss(batch)</span>
<span id="cb42-543"><a href="#cb42-543" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb42-544"><a href="#cb42-544" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb42-545"><a href="#cb42-545" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-546"><a href="#cb42-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-547"><a href="#cb42-547" aria-hidden="true" tabindex="-1"></a>**Pitfall 2: Device mismatch**</span>
<span id="cb42-548"><a href="#cb42-548" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb42-549"><a href="#cb42-549" aria-hidden="true" tabindex="-1"></a><span class="co"># ❌ Wrong - model on GPU, data on CPU</span></span>
<span id="cb42-550"><a href="#cb42-550" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.cuda()</span>
<span id="cb42-551"><a href="#cb42-551" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch_x, batch_y <span class="kw">in</span> dataloader:</span>
<span id="cb42-552"><a href="#cb42-552" aria-hidden="true" tabindex="-1"></a>    pred <span class="op">=</span> model(batch_x)  <span class="co"># Error!</span></span>
<span id="cb42-553"><a href="#cb42-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-554"><a href="#cb42-554" aria-hidden="true" tabindex="-1"></a><span class="co"># ✅ Correct</span></span>
<span id="cb42-555"><a href="#cb42-555" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.cuda()</span>
<span id="cb42-556"><a href="#cb42-556" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch_x, batch_y <span class="kw">in</span> dataloader:</span>
<span id="cb42-557"><a href="#cb42-557" aria-hidden="true" tabindex="-1"></a>    batch_x <span class="op">=</span> batch_x.cuda()</span>
<span id="cb42-558"><a href="#cb42-558" aria-hidden="true" tabindex="-1"></a>    batch_y <span class="op">=</span> batch_y.cuda()</span>
<span id="cb42-559"><a href="#cb42-559" aria-hidden="true" tabindex="-1"></a>    pred <span class="op">=</span> model(batch_x)</span>
<span id="cb42-560"><a href="#cb42-560" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-561"><a href="#cb42-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-562"><a href="#cb42-562" aria-hidden="true" tabindex="-1"></a>**Pitfall 3: Not using eval() mode for inference**</span>
<span id="cb42-563"><a href="#cb42-563" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb42-564"><a href="#cb42-564" aria-hidden="true" tabindex="-1"></a><span class="co"># ❌ Wrong - dropout and batchnorm active during inference</span></span>
<span id="cb42-565"><a href="#cb42-565" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> model(test_data)</span>
<span id="cb42-566"><a href="#cb42-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-567"><a href="#cb42-567" aria-hidden="true" tabindex="-1"></a><span class="co"># ✅ Correct</span></span>
<span id="cb42-568"><a href="#cb42-568" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb42-569"><a href="#cb42-569" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb42-570"><a href="#cb42-570" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> model(test_data)</span>
<span id="cb42-571"><a href="#cb42-571" aria-hidden="true" tabindex="-1"></a>model.train()  <span class="co"># Switch back to training mode</span></span>
<span id="cb42-572"><a href="#cb42-572" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-573"><a href="#cb42-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-574"><a href="#cb42-574" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-575"><a href="#cb42-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-576"><a href="#cb42-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-577"><a href="#cb42-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-578"><a href="#cb42-578" aria-hidden="true" tabindex="-1"></a><span class="fu">## Training Loops</span></span>
<span id="cb42-579"><a href="#cb42-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-580"><a href="#cb42-580" aria-hidden="true" tabindex="-1"></a>Typically, you put together a training loop to train a model. A training loop iterates over batches of data and optimizes the model parameters with each iteration.</span>
<span id="cb42-581"><a href="#cb42-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-584"><a href="#cb42-584" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-585"><a href="#cb42-585" aria-hidden="true" tabindex="-1"></a><span class="co"># | eval: true</span></span>
<span id="cb42-586"><a href="#cb42-586" aria-hidden="true" tabindex="-1"></a><span class="co"># | echo: true</span></span>
<span id="cb42-587"><a href="#cb42-587" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_loop(dataloader, model, loss_fn, optimizer):</span>
<span id="cb42-588"><a href="#cb42-588" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">len</span>(dataloader.dataset)</span>
<span id="cb42-589"><a href="#cb42-589" aria-hidden="true" tabindex="-1"></a>    model.train()  <span class="co"># &lt;-- important!</span></span>
<span id="cb42-590"><a href="#cb42-590" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch, (X, y) <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</span>
<span id="cb42-591"><a href="#cb42-591" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute prediction and loss</span></span>
<span id="cb42-592"><a href="#cb42-592" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> model(X)</span>
<span id="cb42-593"><a href="#cb42-593" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(pred, y)</span>
<span id="cb42-594"><a href="#cb42-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-595"><a href="#cb42-595" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Backpropagation</span></span>
<span id="cb42-596"><a href="#cb42-596" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb42-597"><a href="#cb42-597" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb42-598"><a href="#cb42-598" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb42-599"><a href="#cb42-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-600"><a href="#cb42-600" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> batch <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb42-601"><a href="#cb42-601" aria-hidden="true" tabindex="-1"></a>            loss, current <span class="op">=</span> loss.item(), batch <span class="op">*</span> <span class="bu">len</span>(X)</span>
<span id="cb42-602"><a href="#cb42-602" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"loss: </span><span class="sc">{</span>loss<span class="sc">:&gt;7f}</span><span class="ss">  [</span><span class="sc">{</span>current<span class="sc">:&gt;5d}</span><span class="ss">/</span><span class="sc">{</span>size<span class="sc">:&gt;5d}</span><span class="ss">]"</span>)</span>
<span id="cb42-603"><a href="#cb42-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-604"><a href="#cb42-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-605"><a href="#cb42-605" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_loop(dataloader, model, loss_fn):</span>
<span id="cb42-606"><a href="#cb42-606" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()  <span class="co"># &lt;-- important!</span></span>
<span id="cb42-607"><a href="#cb42-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-608"><a href="#cb42-608" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">len</span>(dataloader.dataset)</span>
<span id="cb42-609"><a href="#cb42-609" aria-hidden="true" tabindex="-1"></a>    num_batches <span class="op">=</span> <span class="bu">len</span>(dataloader)</span>
<span id="cb42-610"><a href="#cb42-610" aria-hidden="true" tabindex="-1"></a>    test_loss, correct <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb42-611"><a href="#cb42-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-612"><a href="#cb42-612" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():  <span class="co"># disables gradient tracking for efficiency</span></span>
<span id="cb42-613"><a href="#cb42-613" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> X, y <span class="kw">in</span> dataloader:</span>
<span id="cb42-614"><a href="#cb42-614" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> model(X)</span>
<span id="cb42-615"><a href="#cb42-615" aria-hidden="true" tabindex="-1"></a>            test_loss <span class="op">+=</span> loss_fn(pred, y).item()</span>
<span id="cb42-616"><a href="#cb42-616" aria-hidden="true" tabindex="-1"></a>            correct <span class="op">+=</span> (pred.argmax(<span class="dv">1</span>) <span class="op">==</span> y).<span class="bu">type</span>(torch.<span class="bu">float</span>).<span class="bu">sum</span>().item()</span>
<span id="cb42-617"><a href="#cb42-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-618"><a href="#cb42-618" aria-hidden="true" tabindex="-1"></a>    test_loss <span class="op">/=</span> num_batches</span>
<span id="cb42-619"><a href="#cb42-619" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">/=</span> size</span>
<span id="cb42-620"><a href="#cb42-620" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb42-621"><a href="#cb42-621" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"Test Error:</span><span class="ch">\n</span><span class="ss"> Accuracy: </span><span class="sc">{</span>(<span class="dv">100</span> <span class="op">*</span> correct)<span class="sc">:&gt;0.1f}</span><span class="ss">%, Avg loss: </span><span class="sc">{</span>test_loss<span class="sc">:&gt;8f}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb42-622"><a href="#cb42-622" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb42-623"><a href="#cb42-623" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-624"><a href="#cb42-624" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-627"><a href="#cb42-627" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-628"><a href="#cb42-628" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb42-629"><a href="#cb42-629" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-630"><a href="#cb42-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-631"><a href="#cb42-631" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb42-632"><a href="#cb42-632" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb42-633"><a href="#cb42-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-634"><a href="#cb42-634" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb42-635"><a href="#cb42-635" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb42-636"><a href="#cb42-636" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>t<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ch">\n</span><span class="ss">-------------------------------"</span>)</span>
<span id="cb42-637"><a href="#cb42-637" aria-hidden="true" tabindex="-1"></a>    train_loop(train_dataloader, model, loss_fn, optimizer)</span>
<span id="cb42-638"><a href="#cb42-638" aria-hidden="true" tabindex="-1"></a>    test_loop(test_dataloader, model, loss_fn)</span>
<span id="cb42-639"><a href="#cb42-639" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Done!"</span>)</span>
<span id="cb42-640"><a href="#cb42-640" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-641"><a href="#cb42-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-642"><a href="#cb42-642" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb42-643"><a href="#cb42-643" aria-hidden="true" tabindex="-1"></a>High-level APIs such as <span class="co">[</span><span class="ot">Lightning</span><span class="co">](https://lightning.ai/)</span> and <span class="co">[</span><span class="ot">Keras</span><span class="co">](https://keras.io/)</span> provide many functionalities to simplify managing training loops. It is highly recommended to use such libraries to reduce boiler-plate code. However, it depends on the individual complexity of a project to what degree such libraries are useful.</span>
<span id="cb42-644"><a href="#cb42-644" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-645"><a href="#cb42-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-646"><a href="#cb42-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-647"><a href="#cb42-647" aria-hidden="true" tabindex="-1"></a><span class="fu">## Pre-trained models</span></span>
<span id="cb42-648"><a href="#cb42-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-649"><a href="#cb42-649" aria-hidden="true" tabindex="-1"></a>Since training models can be time-consuming and expensive, pre-trained models are often used. They allow models to be adapted to a specific task more quickly and cost-effectively. In many areas, particularly NLP and computer vision, using pre-trained models is standard. PyTorch provides <span class="co">[</span><span class="ot">`torchvision`</span><span class="co">](https://pytorch.org/vision/stable/index.html)</span> for computer vision applications. <span class="in">`torchvision`</span> provides functionalities useful for modeling image data. Pre-trained models can also be easily integrated, as shown in the following example:</span>
<span id="cb42-650"><a href="#cb42-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-653"><a href="#cb42-653" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb42-654"><a href="#cb42-654" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: False</span></span>
<span id="cb42-655"><a href="#cb42-655" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-656"><a href="#cb42-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-657"><a href="#cb42-657" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models <span class="im">import</span> resnet50, ResNet50_Weights</span>
<span id="cb42-658"><a href="#cb42-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-659"><a href="#cb42-659" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> ResNet50_Weights.IMAGENET1K_V2</span>
<span id="cb42-660"><a href="#cb42-660" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> resnet50(weights<span class="op">=</span>weights)</span>
<span id="cb42-661"><a href="#cb42-661" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-662"><a href="#cb42-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-663"><a href="#cb42-663" aria-hidden="true" tabindex="-1"></a><span class="fu"># Other Frameworks</span></span>
<span id="cb42-664"><a href="#cb42-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-665"><a href="#cb42-665" aria-hidden="true" tabindex="-1"></a>Other important frameworks are listed below (not exhaustive).</span>
<span id="cb42-666"><a href="#cb42-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-667"><a href="#cb42-667" aria-hidden="true" tabindex="-1"></a><span class="fu">## TensorFlow</span></span>
<span id="cb42-668"><a href="#cb42-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-669"><a href="#cb42-669" aria-hidden="true" tabindex="-1"></a>For a long time, PyTorch and TensorFlow have been the two dominant deep learning frameworks.</span>
<span id="cb42-670"><a href="#cb42-670" aria-hidden="true" tabindex="-1"></a>TensorFlow, developed by Google, is known for its production-readiness, ecosystem integration (e.g., <span class="co">[</span><span class="ot">TensorFlow Extended (TFX)</span><span class="co">](https://www.tensorflow.org/tfx)</span> for MLOps pipelines, <span class="co">[</span><span class="ot">LiteRT</span><span class="co">](https://ai.google.dev/edge/litert)</span> for mobile, and <span class="co">[</span><span class="ot">TensorFlow.js</span><span class="co">](https://www.tensorflow.org/js)</span> for web), and its scalability across distributed hardware.</span>
<span id="cb42-671"><a href="#cb42-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-672"><a href="#cb42-672" aria-hidden="true" tabindex="-1"></a>In recent years, however, TensorFlow’s low-level API has become less popular in research compared to PyTorch, which offers more flexibility and Pythonic design. Today, most TensorFlow users rely almost exclusively on Keras, its high-level API, to define and train models, while the TensorFlow backend provides performance, device management, and deployment capabilities.</span>
<span id="cb42-673"><a href="#cb42-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-674"><a href="#cb42-674" aria-hidden="true" tabindex="-1"></a><span class="fu">## Keras</span></span>
<span id="cb42-675"><a href="#cb42-675" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Keras</span><span class="co">](https://keras.io/)</span> started as an independent high-level deep learning API designed to simplify model creation with a clean and intuitive syntax.</span>
<span id="cb42-676"><a href="#cb42-676" aria-hidden="true" tabindex="-1"></a>Since 2017, it has been tightly integrated into TensorFlow as its official front-end (tf.keras), and in 2023, Keras Core was introduced, a framework-agnostic version that can run on multiple backends such as TensorFlow, JAX, and PyTorch.</span>
<span id="cb42-677"><a href="#cb42-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-678"><a href="#cb42-678" aria-hidden="true" tabindex="-1"></a>Keras focuses on ease of use, modularity, and rapid prototyping, making it an excellent choice for teaching, applied machine learning, and fast experimentation, while still being production-ready through TensorFlow’s ecosystem.</span>
<span id="cb42-679"><a href="#cb42-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-680"><a href="#cb42-680" aria-hidden="true" tabindex="-1"></a><span class="fu">## Jax</span></span>
<span id="cb42-681"><a href="#cb42-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-682"><a href="#cb42-682" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Jax</span><span class="co">](https://jax.readthedocs.io/en/latest/)</span> has gained significant popularity in recent years. Developed by researchers at Google, it is primarily used in research and foundation-model development. Jax provides a NumPy-like API with automatic differentiation (autodiff) and function transformations such as jit (for compilation) and vmap (for vectorization). It enables high-performance, composable numerical computing, and serves as the foundation for frameworks such as <span class="co">[</span><span class="ot">Flax (Neural Networks)</span><span class="co">](https://flax.readthedocs.io/en/stable/)</span> and <span class="co">[</span><span class="ot">Haiku (ML Research)</span><span class="co">](https://dm-haiku.readthedocs.io/en/latest/)</span>.</span>
<span id="cb42-683"><a href="#cb42-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-684"><a href="#cb42-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-685"><a href="#cb42-685" aria-hidden="true" tabindex="-1"></a><span class="fu">## Scikit-Learn</span></span>
<span id="cb42-686"><a href="#cb42-686" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-687"><a href="#cb42-687" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">`Scikit-Learn`</span><span class="co">](https://scikit-learn.org/stable/)</span> is THE machine learning framework in Python. However, Scikit-Learn never covered the area of neural networks and lacks auto-diff functionality. Therefore, Scikit-Learn is irrelevant when training neural networks. However, Scikit-Learn functionalities are often used to carry out the machine learning process, such as splitting datasets into train, validation, and test sets. Also, visualizations, such as the confusion matrix or calculating metrics, can be done via Scikit-Learn.</span>
<span id="cb42-688"><a href="#cb42-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-689"><a href="#cb42-689" aria-hidden="true" tabindex="-1"></a><span class="fu">## ONNX</span></span>
<span id="cb42-690"><a href="#cb42-690" aria-hidden="true" tabindex="-1"></a>y§</span>
<span id="cb42-691"><a href="#cb42-691" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">ONNX</span><span class="co">](https://onnx.ai/)</span> (Open Neural Network Exchange) is an open format to represent machine learning models. It allows models trained in one framework to be transferred to another. Trained models can also be deployed on various platforms.</span>
<span id="cb42-692"><a href="#cb42-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-693"><a href="#cb42-693" aria-hidden="true" tabindex="-1"></a><span class="fu">## Monitoring</span></span>
<span id="cb42-694"><a href="#cb42-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-695"><a href="#cb42-695" aria-hidden="true" tabindex="-1"></a>When training models, monitoring the training process, debugging, and logging hyperparameters, metrics, etc., is very important. Various tools enable these functionalities. Well-known examples are <span class="co">[</span><span class="ot">`TensorBoard`</span><span class="co">](https://www.tensorflow.org/tensorboard)</span> and <span class="co">[</span><span class="ot">`Weights &amp; Biases`</span><span class="co">](https://wandb.ai/site)</span>.</span>
<span id="cb42-696"><a href="#cb42-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-697"><a href="#cb42-697" aria-hidden="true" tabindex="-1"></a><span class="fu"># Hardware</span></span>
<span id="cb42-698"><a href="#cb42-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-699"><a href="#cb42-699" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tensor Operations</span></span>
<span id="cb42-700"><a href="#cb42-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-701"><a href="#cb42-701" aria-hidden="true" tabindex="-1"></a>In neural networks, there are many tensor operations. Tensors are essentially multi-dimensional arrays, such as a scalar $x$, a vector $\mathbf{x}$, or a matrix $\mathbf{X}$.</span>
<span id="cb42-702"><a href="#cb42-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-703"><a href="#cb42-703" aria-hidden="true" tabindex="-1"></a>@fig-infrastructure-matrix-mult illustrates a matrix multiplication, a typical representative of a tensor operation. As you can see, the calculations (entries of the matrix $\mathbf{A}\mathbf{C}$) are independent of each other and can be fully parallelized.</span>
<span id="cb42-704"><a href="#cb42-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-705"><a href="#cb42-705" aria-hidden="true" tabindex="-1"></a>::: {#fig-infrastructure-matrix-mult}</span>
<span id="cb42-706"><a href="#cb42-706" aria-hidden="true" tabindex="-1"></a><span class="al">![]({{&lt; meta params.images_path &gt;}}matrix_mult.png)</span>{width=600}</span>
<span id="cb42-707"><a href="#cb42-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-708"><a href="#cb42-708" aria-hidden="true" tabindex="-1"></a>Matrix Multiplication (from @li_cs231n_2022).</span>
<span id="cb42-709"><a href="#cb42-709" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-710"><a href="#cb42-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-711"><a href="#cb42-711" aria-hidden="true" tabindex="-1"></a><span class="fu">## Graphics Processing Units (GPUs)</span></span>
<span id="cb42-712"><a href="#cb42-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-713"><a href="#cb42-713" aria-hidden="true" tabindex="-1"></a>GPUs have made deep learning possible in the first place. With their parallel structure, they can efficiently compute parallelizable tasks such as tensor operations.</span>
<span id="cb42-714"><a href="#cb42-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-715"><a href="#cb42-715" aria-hidden="true" tabindex="-1"></a>CPUs have far fewer cores than GPUs, but they are faster and can handle more complex tasks. CPUs are therefore ideal for sequential tasks. GPUs have many more cores, which are less complex and slower. Therefore, GPUs are excellent for parallel tasks. @fig-infrastructure-cpu-vs-gpu illustrates the differences.</span>
<span id="cb42-716"><a href="#cb42-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-717"><a href="#cb42-717" aria-hidden="true" tabindex="-1"></a>::: {#fig-infrastructure-cpu-vs-gpu}</span>
<span id="cb42-718"><a href="#cb42-718" aria-hidden="true" tabindex="-1"></a><span class="al">![]({{&lt; meta params.images_path &gt;}}cpu_vs_gpu.png)</span>{width=600}</span>
<span id="cb42-719"><a href="#cb42-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-720"><a href="#cb42-720" aria-hidden="true" tabindex="-1"></a>CPU vs GPU example (from @li_cs231n_2022).</span>
<span id="cb42-721"><a href="#cb42-721" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-722"><a href="#cb42-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-723"><a href="#cb42-723" aria-hidden="true" tabindex="-1"></a><span class="fu">## CUDA &amp; cuDNN</span></span>
<span id="cb42-724"><a href="#cb42-724" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-725"><a href="#cb42-725" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">CUDA</span><span class="co">](https://developer.nvidia.com/cuda-toolkit)</span> is an API by Nvidia to perform computations on the GPU. It allows parallelizable tasks to be implemented efficiently. <span class="co">[</span><span class="ot">cuDNN</span><span class="co">](https://developer.nvidia.com/cudnn)</span> is a library that efficiently executes certain operations, such as convolutions, in neural networks on the GPU. cuDNN is based on CUDA and significantly accelerates the training of neural networks. @fig-infrastructure-speed-gpu-cpu illustrates speed differences when training various neural networks with CPU, GPU, and optimized cuDNN.</span>
<span id="cb42-726"><a href="#cb42-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-727"><a href="#cb42-727" aria-hidden="true" tabindex="-1"></a>::: {#fig-infrastructure-speed-gpu-cpu}</span>
<span id="cb42-728"><a href="#cb42-728" aria-hidden="true" tabindex="-1"></a><span class="al">![]({{&lt; meta params.images_path &gt;}}speed_gpu_cpu.png)</span>{width=600}</span>
<span id="cb42-729"><a href="#cb42-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-730"><a href="#cb42-730" aria-hidden="true" tabindex="-1"></a>Speed comparison (from @li_cs231n_2022, data from <span class="co">[</span><span class="ot">Link</span><span class="co">](https://github.com/jcjohnson/cnn-benchmarks)</span>)</span>
<span id="cb42-731"><a href="#cb42-731" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-732"><a href="#cb42-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-733"><a href="#cb42-733" aria-hidden="true" tabindex="-1"></a><span class="fu">## Data Loading</span></span>
<span id="cb42-734"><a href="#cb42-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-735"><a href="#cb42-735" aria-hidden="true" tabindex="-1"></a>A crucial bottleneck in practice is the transfer of data (such as images) from the disk to the GPU. If this transfer is not fast enough, it is referred to as _GPU starvation_. There are several approaches to solve this problem:</span>
<span id="cb42-736"><a href="#cb42-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-737"><a href="#cb42-737" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Read the data into RAM (not feasible for larger datasets)</span>
<span id="cb42-738"><a href="#cb42-738" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use fast disks, such as SSDs</span>
<span id="cb42-739"><a href="#cb42-739" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Utilize multiple CPU threads to read data in parallel and keep it in RAM (_pre-fetching_)</span>
<span id="cb42-740"><a href="#cb42-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-741"><a href="#cb42-741" aria-hidden="true" tabindex="-1"></a>@fig-infrastructure-computer shows the various components.</span>
<span id="cb42-742"><a href="#cb42-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-743"><a href="#cb42-743" aria-hidden="true" tabindex="-1"></a>::: {#fig-infrastructure-computer}</span>
<span id="cb42-744"><a href="#cb42-744" aria-hidden="true" tabindex="-1"></a><span class="al">![]({{&lt; meta params.images_path &gt;}}computer.jpg)</span>{width=600}</span>
<span id="cb42-745"><a href="#cb42-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-746"><a href="#cb42-746" aria-hidden="true" tabindex="-1"></a>Source: @li_cs231n_2022</span>
<span id="cb42-747"><a href="#cb42-747" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-748"><a href="#cb42-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-749"><a href="#cb42-749" aria-hidden="true" tabindex="-1"></a>Deep learning frameworks like PyTorch implement special classes that allow data to be prepared in multiple threads. Sometimes a certain number of CPU cores is needed to supply a GPU with enough data. @fig-infrastructure-gpu-starvation shows a starved GPU: You can clearly see that the utilization repeatedly drops to 0 because the GPU has to wait for data.</span>
<span id="cb42-750"><a href="#cb42-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-751"><a href="#cb42-751" aria-hidden="true" tabindex="-1"></a>::: {#fig-infrastructure-gpu-starvation}</span>
<span id="cb42-752"><a href="#cb42-752" aria-hidden="true" tabindex="-1"></a><span class="al">![]({{&lt; meta params.images_path &gt;}}gpu_starvation.png)</span>{width=600}</span>
<span id="cb42-753"><a href="#cb42-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-754"><a href="#cb42-754" aria-hidden="true" tabindex="-1"></a>The Y-axis shows the GPU utilization in percentage, while the X-axis represents time. <span class="co">[</span><span class="ot">Source</span><span class="co">](https://stackoverflow.com/questions/44598246/tensorflow-data-starved-gpu)</span></span>
<span id="cb42-755"><a href="#cb42-755" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-756"><a href="#cb42-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-757"><a href="#cb42-757" aria-hidden="true" tabindex="-1"></a><span class="fu">## GPU Parallelism</span></span>
<span id="cb42-758"><a href="#cb42-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-759"><a href="#cb42-759" aria-hidden="true" tabindex="-1"></a>Models can also be trained on multiple GPUs. There are two main paradigms: _data parallelism_ and _model parallelism_ (see @fig-infrastructure-parallelism ). With _data parallelism_, each GPU has a copy of the model, and each GPU is trained on different data batches. With _model parallelism_, the model is split across multiple GPUs. Models can be trained on a server with multiple GPUs or even over the network (_distributed_). ML frameworks provide functionalities to handle these.</span>
<span id="cb42-760"><a href="#cb42-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-761"><a href="#cb42-761" aria-hidden="true" tabindex="-1"></a>::: {#fig-infrastructure-parallelism}</span>
<span id="cb42-762"><a href="#cb42-762" aria-hidden="true" tabindex="-1"></a><span class="al">![]({{&lt; meta params.images_path &gt;}}parallelism.jpg)</span>{width=600}</span>
<span id="cb42-763"><a href="#cb42-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-764"><a href="#cb42-764" aria-hidden="true" tabindex="-1"></a>Data and Model Parallelism (from @li_cs231n_2022).</span>
<span id="cb42-765"><a href="#cb42-765" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-766"><a href="#cb42-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-767"><a href="#cb42-767" aria-hidden="true" tabindex="-1"></a><span class="fu"># References</span></span>
<span id="cb42-768"><a href="#cb42-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-769"><a href="#cb42-769" aria-hidden="true" tabindex="-1"></a>::: {#refs}</span>
<span id="cb42-770"><a href="#cb42-770" aria-hidden="true" tabindex="-1"></a>:::</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2025, Marco Willi</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/marco-willi/cas-dl-compvis-lectures-hs2025/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>