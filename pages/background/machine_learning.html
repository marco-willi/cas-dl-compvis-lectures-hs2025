<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Marco Willi">

<title>1 - Machine Learning Basics – CAS Deep Learning - Computer Vision</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../pages/background/neural_networks.html" rel="next">
<link href="../../index.html" rel="prev">
<link href="../..//assets/cv_logo_small.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-065a5179aebd64318d7ea99d77b64a9e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-159896a7fbbc1299bfd73fe3af9cd852.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-97BR3FTSN1"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-97BR3FTSN1', { 'anonymize_ip': true});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../pages/background/machine_learning.html">Background &amp; Preparation</a></li><li class="breadcrumb-item"><a href="../../pages/background/machine_learning.html">1 - Machine Learning Basics</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      <img src="../../assets/cv_logo_small.png" alt="" class="sidebar-logo light-content py-0 d-lg-inline d-none">
      <img src="../../assets/cv_logo_small.png" alt="" class="sidebar-logo dark-content py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main">
    <a href="https://github.com/marco-willi/cas-dl-compvis-lectures-hs2025" title="GitHub organization" class="quarto-navigation-tool px-1" aria-label="GitHub organization"><i class="bi bi-github"></i></a>
    <a href="" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-code-square"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Background &amp; Preparation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/background/machine_learning.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">1 - Machine Learning Basics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/background/neural_networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2 - Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/background/frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3 - Software &amp; Hardware for Deep Learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Lectures</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/lectures/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 - Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/lectures/cnns.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2 - Convolutional Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/lectures/classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3 - Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/lectures/representation_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 - Representation Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/lectures/practical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5 - Practical</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/lectures/recent_advances.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6 - Recent Advances</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Slides</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/slides/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/slides/cnns.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Convolutional Neural Networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/slides/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/slides/representation_learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Representation Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/slides/practical.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Practical Considerations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/slides/recent_advances.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Recent Advances</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/misc/exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/misc/literature.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Books</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/misc/links.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Helpful Links &amp; Resources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/misc/notation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Mathematical Notation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/misc/student_projects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project Ideas</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-data-driven-approach" id="toc-the-data-driven-approach" class="nav-link active" data-scroll-target="#the-data-driven-approach"><span class="header-section-number">1</span> The Data-Driven Approach</a></li>
  <li><a href="#machine-learning-process" id="toc-machine-learning-process" class="nav-link" data-scroll-target="#machine-learning-process"><span class="header-section-number">2</span> Machine Learning Process</a></li>
  <li><a href="#models" id="toc-models" class="nav-link" data-scroll-target="#models"><span class="header-section-number">3</span> Models</a></li>
  <li><a href="#optimization" id="toc-optimization" class="nav-link" data-scroll-target="#optimization"><span class="header-section-number">4</span> Optimization</a></li>
  <li><a href="#model-selection" id="toc-model-selection" class="nav-link" data-scroll-target="#model-selection"><span class="header-section-number">5</span> Model Selection</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">6</span> References</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/marco-willi/cas-dl-compvis-lectures-hs2025/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../pages/background/machine_learning.html">Background &amp; Preparation</a></li><li class="breadcrumb-item"><a href="../../pages/background/machine_learning.html">1 - Machine Learning Basics</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">1 - Machine Learning Basics</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Marco Willi </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Institute for Data Science I4DS, FHNW
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-tip callout-titled" title="Learning Objectives">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Learning Objectives
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>After reviewing this material you should be able to:</p>
<ul>
<li>Describe the data-driven approach to machine learning and its core workflow (collect, train, evaluate).</li>
<li>Define what a model is mathematically and distinguish between parameters and hyperparameters.</li>
<li>Explain the role of optimization in fitting models and identify common cost/loss functions.</li>
<li>Justify why train/validation/test splits are necessary for unbiased model evaluation.</li>
<li>Interpret the machine learning pipeline from data acquisition through deployment.</li>
<li>Apply model selection principles to choose between competing models.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="TLDR Recap">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>TLDR Recap
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>The Data-Driven Approach:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(images, labels):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model  <span class="co"># Fit model to data</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(test_images, model):</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model(test_images)  <span class="co"># Make predictions</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Core Concepts:</strong></p>
<ul>
<li><strong>Model</strong>: Function <span class="math inline">\(f_{\theta}(\mathbf{x}) = \hat{y}\)</span> mapping inputs to outputs via learned parameters <span class="math inline">\(\theta\)</span></li>
<li><strong>Optimization</strong>: Find parameters that minimize loss: <span class="math inline">\(\mathsf{argmin}_{\theta} J(f_{\theta}(\mathbf{X}), \mathbf{y})\)</span></li>
<li><strong>Hyperparameters</strong>: Settings that control learning (learning rate, regularization) but aren’t learned from data</li>
<li><strong>Loss Functions</strong>: Measure prediction error (MSE for regression, cross-entropy for classification)</li>
</ul>
<p><strong>The ML Pipeline:</strong></p>
<ol type="1">
<li><strong>Data Acquisition</strong> → Collect and prepare labeled dataset</li>
<li><strong>Preprocessing</strong> → Normalize, encode features, reduce dimensionality</li>
<li><strong>Model Training</strong> → Optimize parameters on training set</li>
<li><strong>Model Selection</strong> → Compare models on validation set</li>
<li><strong>Evaluation</strong> → Assess final model on held-out test set</li>
<li><strong>Deployment</strong> → Integrate into production systems</li>
</ol>
<p><strong>Train/Validation/Test Splits:</strong></p>
<ul>
<li><strong>Train set</strong>: Used to optimize model parameters</li>
<li><strong>Validation set</strong>: Used to compare models and tune hyperparameters</li>
<li><strong>Test set</strong>: Final evaluation to estimate real-world performance (use only once!)</li>
<li><strong>Why?</strong> Training metrics are too optimistic; need unbiased performance estimates</li>
</ul>
<p><strong>Key Insight:</strong> The test set represents “future unseen data” - touching it during development leads to overfitting and unreliable performance estimates.</p>
<p><strong>Example Application:</strong> Image super-resolution (shown in <a href="#fig-super-resolution-demo" class="quarto-xref">Figure&nbsp;1</a>):</p>
<ul>
<li><strong>Training data</strong>: Low-res/high-res image pairs</li>
<li><strong>Model</strong>: CNN that learns to add high-frequency details</li>
<li><strong>Loss</strong>: Pixel-wise difference between predicted and true high-res</li>
<li><strong>Evaluation</strong>: PSNR, SSIM, perceptual similarity metrics</li>
</ul>
</div>
</div>
</div>
<section id="the-data-driven-approach" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="the-data-driven-approach"><span class="header-section-number">1</span> The Data-Driven Approach</h2>
<p>We follow a data-driven approach in machine learning to solve various tasks. Typically, the process involves:</p>
<ul>
<li>Collecting a dataset of observations (e.g.&nbsp;images) and their labels.</li>
<li>Using a machine learning algorithm to train a model that learns to associate observations with labels.</li>
<li>Evaluating/applying the model on new data.</li>
</ul>
<div id="4c435604" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(observations, labels):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Train a Model"""</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit Model here</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(test_observations, model):</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Predict"""</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> model(test_observations)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> predictions</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Now let’s see this data-driven approach applied to a concrete computer vision task: <strong>image super-resolution</strong>. This example demonstrates how the same <code>train()</code> and <code>predict()</code> framework works for complex image processing problems.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<div id="fig-super-resolution-demo" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-super-resolution-demo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../assets/images/machine_learning/super_resolution_demo.png" class="img-fluid figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-super-resolution-demo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Image super-resolution demonstration: Converting a low-resolution (100×100 pixels) image to high-resolution (400×400 pixels). The middle panel shows why naive upscaling fails—it remains pixelated. Machine learning models learn to add realistic high-frequency details.
</figcaption>
</figure>
</div>
<p><strong>🤔 Think About It</strong></p>
<p>How would you train a model for image super-resolution? The task is to upscale low-resolution images to high-resolution with the best possible quality.</p>
<details>
<summary>
Key considerations
</summary>
<ul>
<li><strong>Training data</strong>: Pairs of low-res and high-res images (can be created by downsampling high-res images)</li>
<li><strong>Loss function</strong>: Measure difference between predicted high-res and actual high-res</li>
<li><strong>Architecture</strong>: CNN that learns to add high-frequency details</li>
<li><strong>Evaluation</strong>: Visual quality metrics (PSNR, SSIM) and perceptual similarity</li>
</ul>
</details>
</div>
</div>
</div>
</section>
<section id="machine-learning-process" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="machine-learning-process"><span class="header-section-number">2</span> Machine Learning Process</h2>
<p>When modeling data, one often follows certain process steps: acquiring data, preparing it, training multiple models, selecting the most suitable model, estimating its future performance, and finally deploying it in production. <a href="#fig-ml-pipeline" class="quarto-xref">Figure&nbsp;2</a> illustrates this process graphically.</p>
<div id="fig-ml-pipeline" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ml-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../assets/images/machine_learning/python_ml.png" class="img-fluid figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ml-pipeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Machine Learning Pipeline (Source: <span class="citation" data-cites="raschka_python_2020">Raschka and Mirjalili (<a href="#ref-raschka_python_2020" role="doc-biblioref">2020</a>)</span>)
</figcaption>
</figure>
</div>
<p>At the core of a machine learning application is typically a mathematical model, which is fitted to a dataset so that it can then be used for prediction (in supervised learning). We often refer to ‘models’, meaning the mathematical description of the dataset.</p>
</section>
<section id="models" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="models"><span class="header-section-number">3</span> Models</h2>
<p>A model is typically described as a function of a data point, generating an output <span class="math inline">\(\hat{y}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
f(\mathbf{x}^{(i)}) = \hat{y}^{(i)}
\end{align*}\]</span></p>
<p>Most models have parameters or coefficients that describe the model. The entirety of all parameters is denoted by <span class="math inline">\(\theta\)</span>.</p>
<p><span class="math display">\[\begin{align*}
f_{\theta}(\mathbf{x}^{(i)}) \text{ or } f(\theta, \mathbf{x}^{(i)})
\end{align*}\]</span></p>
<p>For simplicity, we often omit <span class="math inline">\(\theta\)</span>: <span class="math inline">\(f(\mathbf{x}^{(i)})\)</span></p>
<div class="callout callout-style-default callout-note callout-titled" title="Linear Regression Example">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Linear Regression Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>To make this concrete, consider <strong>linear regression</strong>, one of the simplest models. It learns a straight line through data:</p>
<p><span class="math display">\[f_\theta(x) = \theta_0 + \theta_1 x\]</span></p>
<p>Where the <strong>parameters</strong> are:</p>
<ul>
<li><span class="math inline">\(\theta_0\)</span> (intercept): Where the line crosses the y-axis</li>
<li><span class="math inline">\(\theta_1\)</span> (slope): How steep the line is</li>
</ul>
<div id="fceb2acc" class="cell" width="500" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Callable</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_linear_model_string(lr, feature_names<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Create string representation of linear model"""</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    intercept <span class="op">=</span> lr.intercept_.flatten()</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    coefficients <span class="op">=</span> lr.coef_.flatten()</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> np.concatenate([intercept, coefficients])</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> feature_names:</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        feature_names <span class="op">=</span> [<span class="ss">f"x_</span><span class="sc">{</span>i <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">^</span><span class="ch">{{</span><span class="ss">(i)</span><span class="ch">}}</span><span class="ss">"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(coefficients))]</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    param_strings <span class="op">=</span> [</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"</span><span class="sc">{</span>value<span class="sc">:.4f}</span><span class="ss"> * </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, value <span class="kw">in</span> <span class="bu">zip</span>([<span class="st">"1"</span>] <span class="op">+</span> <span class="bu">list</span>(feature_names), params)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    formula <span class="op">=</span> <span class="st">" + "</span>.join(param_strings)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="ss">f"$y^</span><span class="ch">{{</span><span class="ss">(i)</span><span class="ch">}}</span><span class="ss"> = </span><span class="sc">{</span>formula<span class="sc">}</span><span class="ss"> + </span><span class="ch">\\</span><span class="ss">epsilon^</span><span class="ch">{{</span><span class="ss">(i)</span><span class="ch">}}</span><span class="ss">$"</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_grid_1d(X: np.ndarray, model, step_size: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.02</span>):</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculates Model Predictions on a Grid over the Space of X"""</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> X.ndim <span class="op">==</span> <span class="dv">1</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    x_grid <span class="op">=</span> np.arange(X.<span class="bu">min</span>(), X.<span class="bu">max</span>(), step_size)</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> model.predict(x_grid.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_grid, p.ravel()</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_noise(x: np.ndarray, scale: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.5</span>, seed: <span class="bu">int</span> <span class="op">=</span> <span class="dv">123</span>):</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Add random noise to inputs"""</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    rng <span class="op">=</span> np.random.default_rng(seed)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x <span class="op">+</span> rng.normal(loc<span class="op">=</span><span class="fl">0.0</span>, scale<span class="op">=</span>scale, size<span class="op">=</span>x.shape)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_dataset(</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    fun: Callable <span class="op">=</span> <span class="kw">lambda</span> x: x,</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>    n_samples: <span class="bu">int</span> <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>    x_min: <span class="bu">int</span> <span class="op">=</span> <span class="dv">0</span>,</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>    x_max: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>    noise_scale: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.3</span>,</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>    seed: <span class="bu">int</span> <span class="op">=</span> <span class="dv">0</span>,</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Sample Data from True Function."""</span></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.linspace(<span class="dv">0</span>, x_max, n_samples).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> fun(x)</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># prevent negative values</span></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>    y_noise <span class="op">=</span> np.clip(add_noise(y, scale<span class="op">=</span>noise_scale, seed<span class="op">=</span>seed), <span class="dv">0</span>, np.inf)</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x, y, y_noise</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Create synthetic dataset (from lecture 2)</span></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>X, y, y_noise <span class="op">=</span> create_dataset(n_samples<span class="op">=</span><span class="dv">40</span>, noise_scale<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear regression model</span></span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LinearRegression()</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> lr.fit(X, y_noise)</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> lr.predict(X)</span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>x_grid, y_grid <span class="op">=</span> calculate_grid_1d(X.ravel(), lr)</span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a>form <span class="op">=</span> create_linear_model_string(lr)</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>title <span class="op">=</span> <span class="st">"Linear Model 1-D</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> form</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> sns.scatterplot(x<span class="op">=</span>X.ravel(), y<span class="op">=</span>y_noise.ravel(), ax<span class="op">=</span>ax).<span class="bu">set</span>(</span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span>title, xlabel<span class="op">=</span><span class="st">"x"</span>, ylabel<span class="op">=</span><span class="st">"y"</span></span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> sns.lineplot(x<span class="op">=</span>x_grid, y<span class="op">=</span>y_grid, color<span class="op">=</span><span class="st">"red"</span>)</span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> ax.vlines(</span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a>    X.ravel(), y_pred, y_noise, color<span class="op">=</span><span class="st">"black"</span>, linestyles<span class="op">=</span><span class="st">"dashed"</span>, linewidths<span class="op">=</span><span class="fl">0.5</span></span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"θ₀ (intercept): </span><span class="sc">{</span>lr<span class="sc">.</span>intercept_[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"θ₁ (slope): </span><span class="sc">{</span>lr<span class="sc">.</span>coef_[<span class="dv">0</span>][<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="machine_learning_files/figure-html/cell-3-output-1.png" width="659" height="473" class="figure-img"></p>
<figcaption>Linear regression fitted to synthetic 1D dataset. The red line shows the learned model, and dashed lines show residuals (errors) for each data point.</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>θ₀ (intercept): -0.215
θ₁ (slope): 1.031</code></pre>
</div>
</div>
<p><strong>Key insight</strong>: The model <span class="math inline">\(f_\theta(x)\)</span> transforms any input <span class="math inline">\(x\)</span> into a prediction <span class="math inline">\(\hat{y}\)</span> using the learned parameters <span class="math inline">\(\theta_0, \theta_1\)</span>.</p>
</div>
</div>
</div>
</section>
<section id="optimization" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="optimization"><span class="header-section-number">4</span> Optimization</h2>
<p>The coefficients are fitted to a training dataset through an optimization procedure.</p>
<p>The optimization procedure can often be influenced by additional factors, called hyperparameters (<span class="math inline">\(\alpha, \lambda, \dots\)</span>). These cannot be directly optimized.</p>
<p>The function/quantity to be optimized is usually called the cost function, i.e., cost function (other terms include objective function, loss function, etc.). We use <span class="math inline">\(J(\cdot)\)</span> to denote the cost function. Often, the cost function is also referred to as the loss function <span class="math inline">\(L(\cdot)\)</span>. We use <span class="math inline">\(l(\cdot)\)</span> for the per-sample loss, i.e., the computation of the cost function on a single sample.</p>
<p>Our goal is to find a model (and its parameters) that minimizes the cost function:</p>
<p><span class="math display">\[\begin{equation*}
\mathsf{argmin}_{\theta, \lambda} J\Big(f_{\theta, \lambda}(\mathbf{X}), \mathbf{y}\Big)
\end{equation*}\]</span></p>
<div class="callout callout-style-default callout-note callout-titled" title="Linear Regression Loss Function">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Linear Regression Loss Function
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For linear regression, we measure prediction errors using <strong>Mean Squared Error (MSE)</strong> or the <strong>Least Squares</strong> approach:</p>
<p><span class="math display">\[J(\theta) = \frac{1}{n}\sum_{i=1}^n (y^{(i)} - f_\theta(x^{(i)}))^2\]</span></p>
<p>Often a factor <span class="math inline">\(\frac{1}{2n}\)</span> is used to make the derivative computation more elegant:</p>
<p><span class="math display">\[J(\theta) = \frac{1}{2n}\sum_{i=1}^n (y^{(i)} - f_\theta(x^{(i)}))^2\]</span></p>
<p><strong>Intuition</strong>:</p>
<ul>
<li><span class="math inline">\((y^{(i)} - f_\theta(x^{(i)}))\)</span> is the <strong>residual</strong> (error) for data point <span class="math inline">\(i\)</span></li>
<li>Squaring penalizes large errors more than small ones</li>
<li>We average over all <span class="math inline">\(n\)</span> training points</li>
</ul>
<p><strong>Optimization goal</strong>: Find parameters <span class="math inline">\(\theta^* = [\theta_0^*, \theta_1^*]\)</span> that minimize MSE:</p>
<p><span class="math display">\[\theta^* = \mathsf{argmin}_{\theta} J(\theta)\]</span></p>
<div id="568e3310" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_x_y_coordinates_of_normal(x, y, std):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the x and y coordinates of a vertically drawn normal distr</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">    at location x and y</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    width_of_distr <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    rv_norm <span class="op">=</span> norm(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span>std)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    y_values_norm <span class="op">=</span> np.arange(<span class="dv">0</span> <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> std, <span class="dv">0</span> <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> std, <span class="op">-</span><span class="fl">0.1</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    x_values_norm <span class="op">=</span> rv_norm.pdf(y_values_norm)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    x_values_norm <span class="op">=</span> (</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        np.<span class="bu">abs</span>(x_values_norm <span class="op">*</span> width_of_distr)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        <span class="op">-</span> np.<span class="bu">min</span>(np.<span class="bu">abs</span>(x_values_norm) <span class="op">*</span> width_of_distr)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> x</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    y_values_norm <span class="op">+=</span> y</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_values_norm, y_values_norm</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the same dataset from Models section</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>std <span class="op">=</span> np.std(y_noise <span class="op">-</span> y_pred)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>form <span class="op">=</span> <span class="st">"$p(y|x) = </span><span class="ch">\\</span><span class="st">mathcal</span><span class="sc">{N}</span><span class="st">(wx, </span><span class="ch">\\</span><span class="st">sigma^2) = </span><span class="ch">\\</span><span class="st">mathcal</span><span class="sc">{N}</span><span class="st">(</span><span class="ch">\\</span><span class="st">hat</span><span class="sc">{y}</span><span class="st">, </span><span class="ch">\\</span><span class="st">sigma^2)$"</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>title <span class="op">=</span> <span class="st">"Lineare Regression 1-D</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> form</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> sns.scatterplot(x<span class="op">=</span>X.ravel(), y<span class="op">=</span>y_noise.ravel(), ax<span class="op">=</span>ax).<span class="bu">set</span>(</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span>title, xlabel<span class="op">=</span><span class="st">"x"</span>, ylabel<span class="op">=</span><span class="st">"y"</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> sns.lineplot(x<span class="op">=</span>x_grid, y<span class="op">=</span>y_grid, color<span class="op">=</span><span class="st">"red"</span>)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x_loc <span class="kw">in</span> np.arange(<span class="dv">1</span>, <span class="dv">9</span>, <span class="fl">2.0</span>):</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    y_loc <span class="op">=</span> lr.predict(np.array([x_loc]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    x_values_norm, y_values_norm <span class="op">=</span> calculate_x_y_coordinates_of_normal(</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span>x_loc, y<span class="op">=</span>y_loc.ravel(), std<span class="op">=</span>std</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> ax.plot(x_values_norm, y_values_norm, color<span class="op">=</span><span class="st">"green"</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> ax.vlines(</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span>x_loc,</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>        ymin<span class="op">=</span>np.<span class="bu">min</span>(y_values_norm),</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>        ymax<span class="op">=</span>np.<span class="bu">max</span>(y_values_norm),</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>        colors<span class="op">=</span><span class="st">"green"</span>,</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>        ls<span class="op">=</span><span class="st">"--"</span>,</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        lw<span class="op">=</span><span class="fl">1.5</span>,</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute and display the MSE</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_noise, y_pred)</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training MSE: </span><span class="sc">{</span>mse<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Standard deviation of residuals: </span><span class="sc">{</span>std<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The optimization found: θ₀*=</span><span class="sc">{</span>lr<span class="sc">.</span>intercept_[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, θ₁*=</span><span class="sc">{</span>lr<span class="sc">.</span>coef_[<span class="dv">0</span>][<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="machine_learning_files/figure-html/cell-4-output-1.png" width="659" height="472" class="figure-img"></p>
<figcaption>Probabilistic view of linear regression. The red line shows the expected value E[y|x], and green curves show the modeled normal distributions p(y|x) at different x locations.</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training MSE: 0.611
Standard deviation of residuals: 0.782
The optimization found: θ₀*=-0.215, θ₁*=1.031</code></pre>
</div>
</div>
<p><strong>Geometric interpretation</strong>: Among all possible lines, we found the one with the smallest average squared distance to the data points.</p>
</div>
</div>
</div>
<p>Usually, preprocessing of variables precedes the learning of the coefficients. Forms of preprocessing include standardizing, normalizing, feature encoding, dimensionality reduction, and more. This preprocessing also affects the optimization procedure and can be considered hyperparameters.</p>
</section>
<section id="model-selection" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="model-selection"><span class="header-section-number">5</span> Model Selection</h2>
<p>Model selection is one of the most important and complex components of the machine learning process. This step involves comparing multiple models and selecting the “best” model for the task to be modeled. Which model is the “best” must be defined based on a metric that measures the model’s performance.</p>
<p><strong>Evaluation Metrics</strong> are crucial for quantifying model performance and vary depending on the problem type. For <strong>regression tasks</strong>, common metrics include:</p>
<ul>
<li><strong>Mean Squared Error (MSE)</strong>: <span class="math inline">\(\text{MSE} = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2\)</span>, which penalizes large errors heavily</li>
<li><strong>Mean Absolute Error (MAE)</strong>: <span class="math inline">\(\text{MAE} = \frac{1}{n}\sum_{i=1}^n |y_i - \hat{y}_i|\)</span>, which treats all errors equally</li>
</ul>
<p>For <strong>classification tasks</strong>, key metrics include:</p>
<ul>
<li><strong>Accuracy</strong>: How often is the model correct (fraction of correct predictions).</li>
<li><strong>Precision</strong>: If it predicts a specific class, how often is it correct (true positives / predicted positives).</li>
<li><strong>Recall</strong>: How many of the target class does the model identify correctly (true positives / actual positives).</li>
<li><strong>F1-Score</strong>: Precision can be traded against Recall, to balance both we can report F1 (harmonic mean of precision and recall).</li>
</ul>
<p>The choice of metric depends on the specific application—for example, in medical diagnosis, recall might be more important than precision to avoid missing positive cases. Different ML-frameworks will implement these and many other evaluation metrics.</p>
<p>If we calculate the value of the metric on the training dataset, our model is usually too optimistic about its general performance. This is because the data points in the training dataset were directly used to optimize the cost function, and the model coefficients are thus optimally adjusted to them. New data points, for which predictions are to be made, could not have been used for optimization. Therefore, a dataset is usually divided into a training set and a test set. The model is trained with the training set and its performance is measured on the test set. When comparing many models, it is advisable to compare them on a separate validation set (see <a href="#fig-train-test-split" class="quarto-xref">Figure&nbsp;3</a>) and evaluate only the best model on the test set. This makes the estimate on the test set more accurate.</p>
<div id="fig-train-test-split" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-train-test-split-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../assets/images/machine_learning/train_test_split.png" class="img-fluid figure-img" width="600">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-train-test-split-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Train-Test Split to select and evaluate models.
</figcaption>
</figure>
</div>
</section>
<section id="references" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="references"><span class="header-section-number">6</span> References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-raschka_python_2020" class="csl-entry" role="listitem">
Raschka, Sebastian, and Vahid Mirjalili. 2020. <em>Python Machine Learning: Machine Learning and Deep Learning with <span>Python</span>, Scikit-Learn, and <span>TensorFlow</span></em>. Second edition, fourth release,[fully revised and updated]. Expert Insight. Birmingham Mumbai: Packt Publishing.
</div>
</div>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/marco-willi\.github\.io\/cas-dl-compvis-lectures-hs2025\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../index.html" class="pagination-link" aria-label="Home">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Home</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../pages/background/neural_networks.html" class="pagination-link" aria-label="2 - Neural Networks">
        <span class="nav-page-text">2 - Neural Networks</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "1 - Machine Learning Basics"</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="an">params:</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">  images_path: "/assets/images/machine_learning/"</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="Learning Objectives" collapse="true"}</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>After reviewing this material you should be able to:</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Describe the data-driven approach to machine learning and its core workflow (collect, train, evaluate).</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Define what a model is mathematically and distinguish between parameters and hyperparameters.</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Explain the role of optimization in fitting models and identify common cost/loss functions.</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Justify why train/validation/test splits are necessary for unbiased model evaluation.</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Interpret the machine learning pipeline from data acquisition through deployment.</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Apply model selection principles to choose between competing models.</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip title="TLDR Recap" collapse="true"}</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>**The Data-Driven Approach:**</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(images, labels):</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model  <span class="co"># Fit model to data</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(test_images, model):</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model(test_images)  <span class="co"># Make predictions</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>**Core Concepts:**</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Model**: Function $f_{\theta}(\mathbf{x}) = \hat{y}$ mapping inputs to outputs via learned parameters $\theta$</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Optimization**: Find parameters that minimize loss: $\mathsf{argmin}_{\theta} J(f_{\theta}(\mathbf{X}), \mathbf{y})$</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Hyperparameters**: Settings that control learning (learning rate, regularization) but aren't learned from data</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Loss Functions**: Measure prediction error (MSE for regression, cross-entropy for classification)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>**The ML Pipeline:**</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Data Acquisition** → Collect and prepare labeled dataset</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Preprocessing** → Normalize, encode features, reduce dimensionality</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Model Training** → Optimize parameters on training set</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Model Selection** → Compare models on validation set</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Evaluation** → Assess final model on held-out test set</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**Deployment** → Integrate into production systems</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>**Train/Validation/Test Splits:**</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Train set**: Used to optimize model parameters</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Validation set**: Used to compare models and tune hyperparameters</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Test set**: Final evaluation to estimate real-world performance (use only once!)</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Why?** Training metrics are too optimistic; need unbiased performance estimates</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>**Key Insight:** The test set represents "future unseen data" - touching it during development leads to overfitting and unreliable performance estimates.</span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>**Example Application:** Image super-resolution (shown in @fig-super-resolution-demo):</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Training data**: Low-res/high-res image pairs</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Model**: CNN that learns to add high-frequency details</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Loss**: Pixel-wise difference between predicted and true high-res</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Evaluation**: PSNR, SSIM, perceptual similarity metrics</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>::: {.content-hidden}</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>{{&lt; include /assets/_macros.tex &gt;}}</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Data-Driven Approach</span></span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>We follow a data-driven approach in machine learning to solve various tasks. Typically, the process involves:</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Collecting a dataset of observations (e.g. images) and their labels.</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Using a machine learning algorithm to train a model that learns to associate observations with labels.</span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Evaluating/applying the model on new data.</span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a><span class="co"># | eval: false</span></span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a><span class="co"># | echo: true</span></span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(observations, labels):</span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Train a Model"""</span></span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Fit Model here</span></span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(test_observations, model):</span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Predict"""</span></span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> model(test_observations)</span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> predictions</span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a>Now let's see this data-driven approach applied to a concrete computer vision task: **image super-resolution**. This example demonstrates how the same <span class="in">`train()`</span> and <span class="in">`predict()`</span> framework works for complex image processing problems.</span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a>::: {.callout-note appearance="simple"}</span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a>::: {#fig-super-resolution-demo}</span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a><span class="al">![]({{&lt; meta params.images_path &gt;}}super_resolution_demo.png)</span>{width=100%}</span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a>Image super-resolution demonstration: Converting a low-resolution (100×100 pixels) image to high-resolution (400×400 pixels). The middle panel shows why naive upscaling fails—it remains pixelated. Machine learning models learn to add realistic high-frequency details.</span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a>**🤔 Think About It**</span>
<span id="cb7-112"><a href="#cb7-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-113"><a href="#cb7-113" aria-hidden="true" tabindex="-1"></a>How would you train a model for image super-resolution? The task is to upscale low-resolution images to high-resolution with the best possible quality.</span>
<span id="cb7-114"><a href="#cb7-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-115"><a href="#cb7-115" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb7-116"><a href="#cb7-116" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">summary</span><span class="dt">&gt;</span>Key considerations<span class="dt">&lt;/</span><span class="kw">summary</span><span class="dt">&gt;</span></span>
<span id="cb7-117"><a href="#cb7-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-118"><a href="#cb7-118" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Training data**: Pairs of low-res and high-res images (can be created by downsampling high-res images)</span>
<span id="cb7-119"><a href="#cb7-119" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Loss function**: Measure difference between predicted high-res and actual high-res</span>
<span id="cb7-120"><a href="#cb7-120" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Architecture**: CNN that learns to add high-frequency details</span>
<span id="cb7-121"><a href="#cb7-121" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Evaluation**: Visual quality metrics (PSNR, SSIM) and perceptual similarity</span>
<span id="cb7-122"><a href="#cb7-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-123"><a href="#cb7-123" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">details</span><span class="dt">&gt;</span></span>
<span id="cb7-124"><a href="#cb7-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-125"><a href="#cb7-125" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-126"><a href="#cb7-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-127"><a href="#cb7-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-128"><a href="#cb7-128" aria-hidden="true" tabindex="-1"></a><span class="fu">## Machine Learning Process</span></span>
<span id="cb7-129"><a href="#cb7-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-130"><a href="#cb7-130" aria-hidden="true" tabindex="-1"></a>When modeling data, one often follows certain process steps: acquiring data, preparing it, training multiple models, selecting the most suitable model, estimating its future performance, and finally deploying it in production. @fig-ml-pipeline illustrates this process graphically.</span>
<span id="cb7-131"><a href="#cb7-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-132"><a href="#cb7-132" aria-hidden="true" tabindex="-1"></a>::: {#fig-ml-pipeline}</span>
<span id="cb7-133"><a href="#cb7-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-134"><a href="#cb7-134" aria-hidden="true" tabindex="-1"></a><span class="al">![]({{&lt; meta params.images_path &gt;}}python_ml.png)</span>{width=600}</span>
<span id="cb7-135"><a href="#cb7-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-136"><a href="#cb7-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-137"><a href="#cb7-137" aria-hidden="true" tabindex="-1"></a>Machine Learning Pipeline (Source: @raschka_python_2020)</span>
<span id="cb7-138"><a href="#cb7-138" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-139"><a href="#cb7-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-140"><a href="#cb7-140" aria-hidden="true" tabindex="-1"></a>At the core of a machine learning application is typically a mathematical model, which is fitted to a dataset so that it can then be used for prediction (in supervised learning). We often refer to 'models', meaning the mathematical description of the dataset.</span>
<span id="cb7-141"><a href="#cb7-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-142"><a href="#cb7-142" aria-hidden="true" tabindex="-1"></a><span class="fu">## Models</span></span>
<span id="cb7-143"><a href="#cb7-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-144"><a href="#cb7-144" aria-hidden="true" tabindex="-1"></a>A model is typically described as a function of a data point, generating an output $\hat{y}$:</span>
<span id="cb7-145"><a href="#cb7-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-146"><a href="#cb7-146" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb7-147"><a href="#cb7-147" aria-hidden="true" tabindex="-1"></a>f(\mathbf{x}^{(i)}) = \hat{y}^{(i)}</span>
<span id="cb7-148"><a href="#cb7-148" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb7-149"><a href="#cb7-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-150"><a href="#cb7-150" aria-hidden="true" tabindex="-1"></a>Most models have parameters or coefficients that describe the model. The entirety of all parameters is denoted by $\theta$.</span>
<span id="cb7-151"><a href="#cb7-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-152"><a href="#cb7-152" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb7-153"><a href="#cb7-153" aria-hidden="true" tabindex="-1"></a>f_{\theta}(\mathbf{x}^{(i)}) \text{ or } f(\theta, \mathbf{x}^{(i)})</span>
<span id="cb7-154"><a href="#cb7-154" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb7-155"><a href="#cb7-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-156"><a href="#cb7-156" aria-hidden="true" tabindex="-1"></a>For simplicity, we often omit $\theta$: $f(\mathbf{x}^{(i)})$</span>
<span id="cb7-157"><a href="#cb7-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-158"><a href="#cb7-158" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Linear Regression Example" collapse="true"}</span>
<span id="cb7-159"><a href="#cb7-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-160"><a href="#cb7-160" aria-hidden="true" tabindex="-1"></a>To make this concrete, consider **linear regression**, one of the simplest models. It learns a straight line through data:</span>
<span id="cb7-161"><a href="#cb7-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-162"><a href="#cb7-162" aria-hidden="true" tabindex="-1"></a>$$f_\theta(x) = \theta_0 + \theta_1 x$$</span>
<span id="cb7-163"><a href="#cb7-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-164"><a href="#cb7-164" aria-hidden="true" tabindex="-1"></a>Where the **parameters** are:</span>
<span id="cb7-165"><a href="#cb7-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-166"><a href="#cb7-166" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\theta_0$ (intercept): Where the line crosses the y-axis</span>
<span id="cb7-167"><a href="#cb7-167" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$\theta_1$ (slope): How steep the line is</span>
<span id="cb7-168"><a href="#cb7-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-171"><a href="#cb7-171" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-172"><a href="#cb7-172" aria-hidden="true" tabindex="-1"></a><span class="co"># | echo: true</span></span>
<span id="cb7-173"><a href="#cb7-173" aria-hidden="true" tabindex="-1"></a><span class="co"># | code-fold: true</span></span>
<span id="cb7-174"><a href="#cb7-174" aria-hidden="true" tabindex="-1"></a><span class="co"># | width: 500</span></span>
<span id="cb7-175"><a href="#cb7-175" aria-hidden="true" tabindex="-1"></a><span class="co"># | fig-cap: "Linear regression fitted to synthetic 1D dataset. The red line shows the learned model, and dashed lines show residuals (errors) for each data point."</span></span>
<span id="cb7-176"><a href="#cb7-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-177"><a href="#cb7-177" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-178"><a href="#cb7-178" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-179"><a href="#cb7-179" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb7-180"><a href="#cb7-180" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb7-181"><a href="#cb7-181" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Callable</span>
<span id="cb7-182"><a href="#cb7-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-183"><a href="#cb7-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-184"><a href="#cb7-184" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_linear_model_string(lr, feature_names<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb7-185"><a href="#cb7-185" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Create string representation of linear model"""</span></span>
<span id="cb7-186"><a href="#cb7-186" aria-hidden="true" tabindex="-1"></a>    intercept <span class="op">=</span> lr.intercept_.flatten()</span>
<span id="cb7-187"><a href="#cb7-187" aria-hidden="true" tabindex="-1"></a>    coefficients <span class="op">=</span> lr.coef_.flatten()</span>
<span id="cb7-188"><a href="#cb7-188" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> np.concatenate([intercept, coefficients])</span>
<span id="cb7-189"><a href="#cb7-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-190"><a href="#cb7-190" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> feature_names:</span>
<span id="cb7-191"><a href="#cb7-191" aria-hidden="true" tabindex="-1"></a>        feature_names <span class="op">=</span> [<span class="ss">f"x_</span><span class="sc">{</span>i <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">^</span><span class="ch">{{</span><span class="ss">(i)</span><span class="ch">}}</span><span class="ss">"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(coefficients))]</span>
<span id="cb7-192"><a href="#cb7-192" aria-hidden="true" tabindex="-1"></a>    param_strings <span class="op">=</span> [</span>
<span id="cb7-193"><a href="#cb7-193" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"</span><span class="sc">{</span>value<span class="sc">:.4f}</span><span class="ss"> * </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb7-194"><a href="#cb7-194" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, value <span class="kw">in</span> <span class="bu">zip</span>([<span class="st">"1"</span>] <span class="op">+</span> <span class="bu">list</span>(feature_names), params)</span>
<span id="cb7-195"><a href="#cb7-195" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb7-196"><a href="#cb7-196" aria-hidden="true" tabindex="-1"></a>    formula <span class="op">=</span> <span class="st">" + "</span>.join(param_strings)</span>
<span id="cb7-197"><a href="#cb7-197" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="ss">f"$y^</span><span class="ch">{{</span><span class="ss">(i)</span><span class="ch">}}</span><span class="ss"> = </span><span class="sc">{</span>formula<span class="sc">}</span><span class="ss"> + </span><span class="ch">\\</span><span class="ss">epsilon^</span><span class="ch">{{</span><span class="ss">(i)</span><span class="ch">}}</span><span class="ss">$"</span></span>
<span id="cb7-198"><a href="#cb7-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-199"><a href="#cb7-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-200"><a href="#cb7-200" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_grid_1d(X: np.ndarray, model, step_size: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.02</span>):</span>
<span id="cb7-201"><a href="#cb7-201" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculates Model Predictions on a Grid over the Space of X"""</span></span>
<span id="cb7-202"><a href="#cb7-202" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> X.ndim <span class="op">==</span> <span class="dv">1</span></span>
<span id="cb7-203"><a href="#cb7-203" aria-hidden="true" tabindex="-1"></a>    x_grid <span class="op">=</span> np.arange(X.<span class="bu">min</span>(), X.<span class="bu">max</span>(), step_size)</span>
<span id="cb7-204"><a href="#cb7-204" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> model.predict(x_grid.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb7-205"><a href="#cb7-205" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_grid, p.ravel()</span>
<span id="cb7-206"><a href="#cb7-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-207"><a href="#cb7-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-208"><a href="#cb7-208" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> add_noise(x: np.ndarray, scale: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.5</span>, seed: <span class="bu">int</span> <span class="op">=</span> <span class="dv">123</span>):</span>
<span id="cb7-209"><a href="#cb7-209" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Add random noise to inputs"""</span></span>
<span id="cb7-210"><a href="#cb7-210" aria-hidden="true" tabindex="-1"></a>    rng <span class="op">=</span> np.random.default_rng(seed)</span>
<span id="cb7-211"><a href="#cb7-211" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x <span class="op">+</span> rng.normal(loc<span class="op">=</span><span class="fl">0.0</span>, scale<span class="op">=</span>scale, size<span class="op">=</span>x.shape)</span>
<span id="cb7-212"><a href="#cb7-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-213"><a href="#cb7-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-214"><a href="#cb7-214" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_dataset(</span>
<span id="cb7-215"><a href="#cb7-215" aria-hidden="true" tabindex="-1"></a>    fun: Callable <span class="op">=</span> <span class="kw">lambda</span> x: x,</span>
<span id="cb7-216"><a href="#cb7-216" aria-hidden="true" tabindex="-1"></a>    n_samples: <span class="bu">int</span> <span class="op">=</span> <span class="dv">20</span>,</span>
<span id="cb7-217"><a href="#cb7-217" aria-hidden="true" tabindex="-1"></a>    x_min: <span class="bu">int</span> <span class="op">=</span> <span class="dv">0</span>,</span>
<span id="cb7-218"><a href="#cb7-218" aria-hidden="true" tabindex="-1"></a>    x_max: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb7-219"><a href="#cb7-219" aria-hidden="true" tabindex="-1"></a>    noise_scale: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.3</span>,</span>
<span id="cb7-220"><a href="#cb7-220" aria-hidden="true" tabindex="-1"></a>    seed: <span class="bu">int</span> <span class="op">=</span> <span class="dv">0</span>,</span>
<span id="cb7-221"><a href="#cb7-221" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb7-222"><a href="#cb7-222" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Sample Data from True Function."""</span></span>
<span id="cb7-223"><a href="#cb7-223" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> np.linspace(<span class="dv">0</span>, x_max, n_samples).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb7-224"><a href="#cb7-224" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> fun(x)</span>
<span id="cb7-225"><a href="#cb7-225" aria-hidden="true" tabindex="-1"></a>    <span class="co"># prevent negative values</span></span>
<span id="cb7-226"><a href="#cb7-226" aria-hidden="true" tabindex="-1"></a>    y_noise <span class="op">=</span> np.clip(add_noise(y, scale<span class="op">=</span>noise_scale, seed<span class="op">=</span>seed), <span class="dv">0</span>, np.inf)</span>
<span id="cb7-227"><a href="#cb7-227" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x, y, y_noise</span>
<span id="cb7-228"><a href="#cb7-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-229"><a href="#cb7-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-230"><a href="#cb7-230" aria-hidden="true" tabindex="-1"></a><span class="co"># Create synthetic dataset (from lecture 2)</span></span>
<span id="cb7-231"><a href="#cb7-231" aria-hidden="true" tabindex="-1"></a>X, y, y_noise <span class="op">=</span> create_dataset(n_samples<span class="op">=</span><span class="dv">40</span>, noise_scale<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb7-232"><a href="#cb7-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-233"><a href="#cb7-233" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear regression model</span></span>
<span id="cb7-234"><a href="#cb7-234" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LinearRegression()</span>
<span id="cb7-235"><a href="#cb7-235" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> lr.fit(X, y_noise)</span>
<span id="cb7-236"><a href="#cb7-236" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> lr.predict(X)</span>
<span id="cb7-237"><a href="#cb7-237" aria-hidden="true" tabindex="-1"></a>x_grid, y_grid <span class="op">=</span> calculate_grid_1d(X.ravel(), lr)</span>
<span id="cb7-238"><a href="#cb7-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-239"><a href="#cb7-239" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb7-240"><a href="#cb7-240" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb7-241"><a href="#cb7-241" aria-hidden="true" tabindex="-1"></a>form <span class="op">=</span> create_linear_model_string(lr)</span>
<span id="cb7-242"><a href="#cb7-242" aria-hidden="true" tabindex="-1"></a>title <span class="op">=</span> <span class="st">"Linear Model 1-D</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> form</span>
<span id="cb7-243"><a href="#cb7-243" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> sns.scatterplot(x<span class="op">=</span>X.ravel(), y<span class="op">=</span>y_noise.ravel(), ax<span class="op">=</span>ax).<span class="bu">set</span>(</span>
<span id="cb7-244"><a href="#cb7-244" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span>title, xlabel<span class="op">=</span><span class="st">"x"</span>, ylabel<span class="op">=</span><span class="st">"y"</span></span>
<span id="cb7-245"><a href="#cb7-245" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-246"><a href="#cb7-246" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> sns.lineplot(x<span class="op">=</span>x_grid, y<span class="op">=</span>y_grid, color<span class="op">=</span><span class="st">"red"</span>)</span>
<span id="cb7-247"><a href="#cb7-247" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> ax.vlines(</span>
<span id="cb7-248"><a href="#cb7-248" aria-hidden="true" tabindex="-1"></a>    X.ravel(), y_pred, y_noise, color<span class="op">=</span><span class="st">"black"</span>, linestyles<span class="op">=</span><span class="st">"dashed"</span>, linewidths<span class="op">=</span><span class="fl">0.5</span></span>
<span id="cb7-249"><a href="#cb7-249" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-250"><a href="#cb7-250" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-251"><a href="#cb7-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-252"><a href="#cb7-252" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"θ₀ (intercept): </span><span class="sc">{</span>lr<span class="sc">.</span>intercept_[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb7-253"><a href="#cb7-253" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"θ₁ (slope): </span><span class="sc">{</span>lr<span class="sc">.</span>coef_[<span class="dv">0</span>][<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb7-254"><a href="#cb7-254" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-255"><a href="#cb7-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-256"><a href="#cb7-256" aria-hidden="true" tabindex="-1"></a>**Key insight**: The model $f_\theta(x)$ transforms any input $x$ into a prediction $\hat{y}$ using the learned parameters $\theta_0, \theta_1$.</span>
<span id="cb7-257"><a href="#cb7-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-258"><a href="#cb7-258" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-259"><a href="#cb7-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-260"><a href="#cb7-260" aria-hidden="true" tabindex="-1"></a><span class="fu">## Optimization</span></span>
<span id="cb7-261"><a href="#cb7-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-262"><a href="#cb7-262" aria-hidden="true" tabindex="-1"></a>The coefficients are fitted to a training dataset through an optimization procedure.</span>
<span id="cb7-263"><a href="#cb7-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-264"><a href="#cb7-264" aria-hidden="true" tabindex="-1"></a>The optimization procedure can often be influenced by additional factors, called hyperparameters ($\alpha, \lambda, \dots$). These cannot be directly optimized.</span>
<span id="cb7-265"><a href="#cb7-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-266"><a href="#cb7-266" aria-hidden="true" tabindex="-1"></a>The function/quantity to be optimized is usually called the cost function, i.e., cost function (other terms include objective function, loss function, etc.). We use $J(\cdot)$ to denote the cost function. Often, the cost function is also referred to as the loss function $L(\cdot)$. We use $l(\cdot)$ for the per-sample loss, i.e., the computation of the cost function on a single sample.</span>
<span id="cb7-267"><a href="#cb7-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-268"><a href="#cb7-268" aria-hidden="true" tabindex="-1"></a>Our goal is to find a model (and its parameters) that minimizes the cost function:</span>
<span id="cb7-269"><a href="#cb7-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-270"><a href="#cb7-270" aria-hidden="true" tabindex="-1"></a>\begin{equation*}</span>
<span id="cb7-271"><a href="#cb7-271" aria-hidden="true" tabindex="-1"></a>\mathsf{argmin}_{\theta, \lambda} J\Big(f_{\theta, \lambda}(\mathbf{X}), \mathbf{y}\Big)</span>
<span id="cb7-272"><a href="#cb7-272" aria-hidden="true" tabindex="-1"></a>\end{equation*}</span>
<span id="cb7-273"><a href="#cb7-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-274"><a href="#cb7-274" aria-hidden="true" tabindex="-1"></a>::: {.callout-note title="Linear Regression Loss Function" collapse="true"}</span>
<span id="cb7-275"><a href="#cb7-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-276"><a href="#cb7-276" aria-hidden="true" tabindex="-1"></a>For linear regression, we measure prediction errors using **Mean Squared Error (MSE)** or the **Least Squares** approach:</span>
<span id="cb7-277"><a href="#cb7-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-278"><a href="#cb7-278" aria-hidden="true" tabindex="-1"></a>$$J(\theta) = \frac{1}{n}\sum_{i=1}^n (y^{(i)} - f_\theta(x^{(i)}))^2$$</span>
<span id="cb7-279"><a href="#cb7-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-280"><a href="#cb7-280" aria-hidden="true" tabindex="-1"></a>Often a factor $\frac{1}{2n}$ is used to make the derivative computation more elegant:</span>
<span id="cb7-281"><a href="#cb7-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-282"><a href="#cb7-282" aria-hidden="true" tabindex="-1"></a>$$J(\theta) = \frac{1}{2n}\sum_{i=1}^n (y^{(i)} - f_\theta(x^{(i)}))^2$$</span>
<span id="cb7-283"><a href="#cb7-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-284"><a href="#cb7-284" aria-hidden="true" tabindex="-1"></a>**Intuition**:</span>
<span id="cb7-285"><a href="#cb7-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-286"><a href="#cb7-286" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>$(y^{(i)} - f_\theta(x^{(i)}))$ is the **residual** (error) for data point $i$</span>
<span id="cb7-287"><a href="#cb7-287" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Squaring penalizes large errors more than small ones</span>
<span id="cb7-288"><a href="#cb7-288" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We average over all $n$ training points</span>
<span id="cb7-289"><a href="#cb7-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-290"><a href="#cb7-290" aria-hidden="true" tabindex="-1"></a>**Optimization goal**: Find parameters $\theta^* = <span class="co">[</span><span class="ot">\theta_0^*, \theta_1^*</span><span class="co">]</span>$ that minimize MSE:</span>
<span id="cb7-291"><a href="#cb7-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-292"><a href="#cb7-292" aria-hidden="true" tabindex="-1"></a>$$\theta^* = \mathsf{argmin}_{\theta} J(\theta)$$</span>
<span id="cb7-293"><a href="#cb7-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-296"><a href="#cb7-296" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb7-297"><a href="#cb7-297" aria-hidden="true" tabindex="-1"></a><span class="co"># | echo: true</span></span>
<span id="cb7-298"><a href="#cb7-298" aria-hidden="true" tabindex="-1"></a><span class="co"># | code-fold: true</span></span>
<span id="cb7-299"><a href="#cb7-299" aria-hidden="true" tabindex="-1"></a><span class="co"># | fig-cap: "Probabilistic view of linear regression. The red line shows the expected value E[y|x], and green curves show the modeled normal distributions p(y|x) at different x locations."</span></span>
<span id="cb7-300"><a href="#cb7-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-301"><a href="#cb7-301" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb7-302"><a href="#cb7-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-303"><a href="#cb7-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-304"><a href="#cb7-304" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_x_y_coordinates_of_normal(x, y, std):</span>
<span id="cb7-305"><a href="#cb7-305" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Calculate the x and y coordinates of a vertically drawn normal distr</span></span>
<span id="cb7-306"><a href="#cb7-306" aria-hidden="true" tabindex="-1"></a><span class="co">    at location x and y</span></span>
<span id="cb7-307"><a href="#cb7-307" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-308"><a href="#cb7-308" aria-hidden="true" tabindex="-1"></a>    width_of_distr <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb7-309"><a href="#cb7-309" aria-hidden="true" tabindex="-1"></a>    rv_norm <span class="op">=</span> norm(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span>std)</span>
<span id="cb7-310"><a href="#cb7-310" aria-hidden="true" tabindex="-1"></a>    y_values_norm <span class="op">=</span> np.arange(<span class="dv">0</span> <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> std, <span class="dv">0</span> <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> std, <span class="op">-</span><span class="fl">0.1</span>)</span>
<span id="cb7-311"><a href="#cb7-311" aria-hidden="true" tabindex="-1"></a>    x_values_norm <span class="op">=</span> rv_norm.pdf(y_values_norm)</span>
<span id="cb7-312"><a href="#cb7-312" aria-hidden="true" tabindex="-1"></a>    x_values_norm <span class="op">=</span> (</span>
<span id="cb7-313"><a href="#cb7-313" aria-hidden="true" tabindex="-1"></a>        np.<span class="bu">abs</span>(x_values_norm <span class="op">*</span> width_of_distr)</span>
<span id="cb7-314"><a href="#cb7-314" aria-hidden="true" tabindex="-1"></a>        <span class="op">-</span> np.<span class="bu">min</span>(np.<span class="bu">abs</span>(x_values_norm) <span class="op">*</span> width_of_distr)</span>
<span id="cb7-315"><a href="#cb7-315" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> x</span>
<span id="cb7-316"><a href="#cb7-316" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-317"><a href="#cb7-317" aria-hidden="true" tabindex="-1"></a>    y_values_norm <span class="op">+=</span> y</span>
<span id="cb7-318"><a href="#cb7-318" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_values_norm, y_values_norm</span>
<span id="cb7-319"><a href="#cb7-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-320"><a href="#cb7-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-321"><a href="#cb7-321" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the same dataset from Models section</span></span>
<span id="cb7-322"><a href="#cb7-322" aria-hidden="true" tabindex="-1"></a>std <span class="op">=</span> np.std(y_noise <span class="op">-</span> y_pred)</span>
<span id="cb7-323"><a href="#cb7-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-324"><a href="#cb7-324" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb7-325"><a href="#cb7-325" aria-hidden="true" tabindex="-1"></a>form <span class="op">=</span> <span class="st">"$p(y|x) = </span><span class="ch">\\</span><span class="st">mathcal</span><span class="sc">{N}</span><span class="st">(wx, </span><span class="ch">\\</span><span class="st">sigma^2) = </span><span class="ch">\\</span><span class="st">mathcal</span><span class="sc">{N}</span><span class="st">(</span><span class="ch">\\</span><span class="st">hat</span><span class="sc">{y}</span><span class="st">, </span><span class="ch">\\</span><span class="st">sigma^2)$"</span></span>
<span id="cb7-326"><a href="#cb7-326" aria-hidden="true" tabindex="-1"></a>title <span class="op">=</span> <span class="st">"Lineare Regression 1-D</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> form</span>
<span id="cb7-327"><a href="#cb7-327" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> sns.scatterplot(x<span class="op">=</span>X.ravel(), y<span class="op">=</span>y_noise.ravel(), ax<span class="op">=</span>ax).<span class="bu">set</span>(</span>
<span id="cb7-328"><a href="#cb7-328" aria-hidden="true" tabindex="-1"></a>    title<span class="op">=</span>title, xlabel<span class="op">=</span><span class="st">"x"</span>, ylabel<span class="op">=</span><span class="st">"y"</span></span>
<span id="cb7-329"><a href="#cb7-329" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-330"><a href="#cb7-330" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> sns.lineplot(x<span class="op">=</span>x_grid, y<span class="op">=</span>y_grid, color<span class="op">=</span><span class="st">"red"</span>)</span>
<span id="cb7-331"><a href="#cb7-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-332"><a href="#cb7-332" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x_loc <span class="kw">in</span> np.arange(<span class="dv">1</span>, <span class="dv">9</span>, <span class="fl">2.0</span>):</span>
<span id="cb7-333"><a href="#cb7-333" aria-hidden="true" tabindex="-1"></a>    y_loc <span class="op">=</span> lr.predict(np.array([x_loc]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb7-334"><a href="#cb7-334" aria-hidden="true" tabindex="-1"></a>    x_values_norm, y_values_norm <span class="op">=</span> calculate_x_y_coordinates_of_normal(</span>
<span id="cb7-335"><a href="#cb7-335" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span>x_loc, y<span class="op">=</span>y_loc.ravel(), std<span class="op">=</span>std</span>
<span id="cb7-336"><a href="#cb7-336" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-337"><a href="#cb7-337" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> ax.plot(x_values_norm, y_values_norm, color<span class="op">=</span><span class="st">"green"</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb7-338"><a href="#cb7-338" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> ax.vlines(</span>
<span id="cb7-339"><a href="#cb7-339" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span>x_loc,</span>
<span id="cb7-340"><a href="#cb7-340" aria-hidden="true" tabindex="-1"></a>        ymin<span class="op">=</span>np.<span class="bu">min</span>(y_values_norm),</span>
<span id="cb7-341"><a href="#cb7-341" aria-hidden="true" tabindex="-1"></a>        ymax<span class="op">=</span>np.<span class="bu">max</span>(y_values_norm),</span>
<span id="cb7-342"><a href="#cb7-342" aria-hidden="true" tabindex="-1"></a>        colors<span class="op">=</span><span class="st">"green"</span>,</span>
<span id="cb7-343"><a href="#cb7-343" aria-hidden="true" tabindex="-1"></a>        ls<span class="op">=</span><span class="st">"--"</span>,</span>
<span id="cb7-344"><a href="#cb7-344" aria-hidden="true" tabindex="-1"></a>        lw<span class="op">=</span><span class="fl">1.5</span>,</span>
<span id="cb7-345"><a href="#cb7-345" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-346"><a href="#cb7-346" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-347"><a href="#cb7-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-348"><a href="#cb7-348" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute and display the MSE</span></span>
<span id="cb7-349"><a href="#cb7-349" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb7-350"><a href="#cb7-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-351"><a href="#cb7-351" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_noise, y_pred)</span>
<span id="cb7-352"><a href="#cb7-352" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training MSE: </span><span class="sc">{</span>mse<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb7-353"><a href="#cb7-353" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Standard deviation of residuals: </span><span class="sc">{</span>std<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb7-354"><a href="#cb7-354" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The optimization found: θ₀*=</span><span class="sc">{</span>lr<span class="sc">.</span>intercept_[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, θ₁*=</span><span class="sc">{</span>lr<span class="sc">.</span>coef_[<span class="dv">0</span>][<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb7-355"><a href="#cb7-355" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-356"><a href="#cb7-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-357"><a href="#cb7-357" aria-hidden="true" tabindex="-1"></a>**Geometric interpretation**: Among all possible lines, we found the one with the smallest average squared distance to the data points.</span>
<span id="cb7-358"><a href="#cb7-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-359"><a href="#cb7-359" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-360"><a href="#cb7-360" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-361"><a href="#cb7-361" aria-hidden="true" tabindex="-1"></a>Usually, preprocessing of variables precedes the learning of the coefficients. Forms of preprocessing include standardizing, normalizing, feature encoding, dimensionality reduction, and more. This preprocessing also affects the optimization procedure and can be considered hyperparameters.</span>
<span id="cb7-362"><a href="#cb7-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-363"><a href="#cb7-363" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model Selection</span></span>
<span id="cb7-364"><a href="#cb7-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-365"><a href="#cb7-365" aria-hidden="true" tabindex="-1"></a>Model selection is one of the most important and complex components of the machine learning process. This step involves comparing multiple models and selecting the "best" model for the task to be modeled. Which model is the "best" must be defined based on a metric that measures the model's performance.</span>
<span id="cb7-366"><a href="#cb7-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-367"><a href="#cb7-367" aria-hidden="true" tabindex="-1"></a>**Evaluation Metrics** are crucial for quantifying model performance and vary depending on the problem type. For **regression tasks**, common metrics include:</span>
<span id="cb7-368"><a href="#cb7-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-369"><a href="#cb7-369" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Mean Squared Error (MSE)**: $\text{MSE} = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2$, which penalizes large errors heavily</span>
<span id="cb7-370"><a href="#cb7-370" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Mean Absolute Error (MAE)**: $\text{MAE} = \frac{1}{n}\sum_{i=1}^n |y_i - \hat{y}_i|$, which treats all errors equally</span>
<span id="cb7-371"><a href="#cb7-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-372"><a href="#cb7-372" aria-hidden="true" tabindex="-1"></a>For **classification tasks**, key metrics include:</span>
<span id="cb7-373"><a href="#cb7-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-374"><a href="#cb7-374" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Accuracy**: How often is the model correct (fraction of correct predictions).</span>
<span id="cb7-375"><a href="#cb7-375" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Precision**: If it predicts a specific class, how often is it correct (true positives / predicted positives).</span>
<span id="cb7-376"><a href="#cb7-376" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Recall**: How many of the target class does the model identify correctly (true positives / actual positives).</span>
<span id="cb7-377"><a href="#cb7-377" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**F1-Score**: Precision can be traded against Recall, to balance both we can report F1 (harmonic mean of precision and recall).</span>
<span id="cb7-378"><a href="#cb7-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-379"><a href="#cb7-379" aria-hidden="true" tabindex="-1"></a>The choice of metric depends on the specific application—for example, in medical diagnosis, recall might be more important than precision to avoid missing positive cases. Different ML-frameworks will implement these and many other evaluation metrics.</span>
<span id="cb7-380"><a href="#cb7-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-381"><a href="#cb7-381" aria-hidden="true" tabindex="-1"></a>If we calculate the value of the metric on the training dataset, our model is usually too optimistic about its general performance. This is because the data points in the training dataset were directly used to optimize the cost function, and the model coefficients are thus optimally adjusted to them. New data points, for which predictions are to be made, could not have been used for optimization. Therefore, a dataset is usually divided into a training set and a test set. The model is trained with the training set and its performance is measured on the test set. When comparing many models, it is advisable to compare them on a separate validation set (see @fig-train-test-split) and evaluate only the best model on the test set. This makes the estimate on the test set more accurate.</span>
<span id="cb7-382"><a href="#cb7-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-383"><a href="#cb7-383" aria-hidden="true" tabindex="-1"></a>::: {#fig-train-test-split}</span>
<span id="cb7-384"><a href="#cb7-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-385"><a href="#cb7-385" aria-hidden="true" tabindex="-1"></a><span class="al">![]({{&lt; meta params.images_path &gt;}}train_test_split.png)</span>{width=600}</span>
<span id="cb7-386"><a href="#cb7-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-387"><a href="#cb7-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-388"><a href="#cb7-388" aria-hidden="true" tabindex="-1"></a>Train-Test Split to select and evaluate models.</span>
<span id="cb7-389"><a href="#cb7-389" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-390"><a href="#cb7-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-391"><a href="#cb7-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-392"><a href="#cb7-392" aria-hidden="true" tabindex="-1"></a><span class="fu">## References</span></span>
<span id="cb7-393"><a href="#cb7-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-394"><a href="#cb7-394" aria-hidden="true" tabindex="-1"></a>::: {#refs}</span>
<span id="cb7-395"><a href="#cb7-395" aria-hidden="true" tabindex="-1"></a>:::</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2025, Marco Willi</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/marco-willi/cas-dl-compvis-lectures-hs2025/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>